{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# All oscillation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.environ[\"SPECTRAL_CONNECTIVITY_ENABLE_GPU\"] = \"true\"\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spectral_connectivity import Multitaper, Connectivity\n",
    "import spectral_connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FONTSIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "font = {'weight' : 'medium',\n",
    "        'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_pairs(lst):\n",
    "    \"\"\"\n",
    "    Generates all unique pairs from a list.\n",
    "\n",
    "    Parameters:\n",
    "    - lst (list): The list to generate pairs from.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of tuples, each containing a unique pair from the input list.\n",
    "    \"\"\"\n",
    "    n = len(lst)\n",
    "    return [(lst[i], lst[j]) for i in range(n) for j in range(i+1, n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TIME_HALFBANDWIDTH_PRODUCT = 2\n",
    "TIME_WINDOW_DURATION = 1\n",
    "TIME_WINDOW_STEP = 0.5\n",
    "RESAMPLE_RATE=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_TRACES_DF = pd.read_pickle(\"/blue/npadillacoreano/ryoi360/reward_competition_extention/final_proc/rce_pilot_2_01_lfp_traces_and_frames.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort</th>\n",
       "      <th>session_dir</th>\n",
       "      <th>original_file</th>\n",
       "      <th>tone_frames</th>\n",
       "      <th>box_1_port_entry_frames</th>\n",
       "      <th>box_2_port_entry_frames</th>\n",
       "      <th>video_name</th>\n",
       "      <th>session_path</th>\n",
       "      <th>recording</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>...</th>\n",
       "      <th>video_timestamps</th>\n",
       "      <th>tone_timestamps</th>\n",
       "      <th>box_1_port_entry_timestamps</th>\n",
       "      <th>box_2_port_entry_timestamps</th>\n",
       "      <th>lfp_timestamps</th>\n",
       "      <th>mPFC_lfp_trace</th>\n",
       "      <th>MD_lfp_trace</th>\n",
       "      <th>LH_lfp_trace</th>\n",
       "      <th>BLA_lfp_trace</th>\n",
       "      <th>vHPC_lfp_trace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>[[980, 1180], [3376, 3575], [5672, 5871], [746...</td>\n",
       "      <td>[[490, 514], [518, 558], [558, 637], [638, 640...</td>\n",
       "      <td>[[33021, 33027], [33502, 33503], [33504, 33506...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>[-2, 1384, 2770, 4156, 4156, 5542, 6928, 6928,...</td>\n",
       "      <td>[[982229, 1182226], [3382227, 3582224], [56822...</td>\n",
       "      <td>[[491029, 515227], [519426, 558629], [559427, ...</td>\n",
       "      <td>[[33082200, 33090003], [33565003, 33567000], [...</td>\n",
       "      <td>[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...</td>\n",
       "      <td>[0.933348, 0.8057418, 0.9461086, 1.2687699, 1....</td>\n",
       "      <td>[0.44765243, 0.479771, 0.7427417, 0.97560126, ...</td>\n",
       "      <td>[0.89443207, 0.96188104, 1.1935536, 1.3225864,...</td>\n",
       "      <td>[0.6654362, 0.6609094, 0.87366796, 1.0230516, ...</td>\n",
       "      <td>[0.2327341, 0.3381231, 0.5568053, 0.74650556, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>[[980, 1180], [3376, 3575], [5672, 5871], [746...</td>\n",
       "      <td>[[490, 514], [518, 558], [558, 637], [638, 640...</td>\n",
       "      <td>[[33021, 33027], [33502, 33503], [33504, 33506...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>[-2, 1384, 2770, 4156, 4156, 5542, 6928, 6928,...</td>\n",
       "      <td>[[982229, 1182226], [3382227, 3582224], [56822...</td>\n",
       "      <td>[[491029, 515227], [519426, 558629], [559427, ...</td>\n",
       "      <td>[[33082200, 33090003], [33565003, 33567000], [...</td>\n",
       "      <td>[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...</td>\n",
       "      <td>[0.27034205, 0.4041477, 0.45876226, 0.52429974...</td>\n",
       "      <td>[0.8194214, 0.80269855, 0.71908414, 0.64104396...</td>\n",
       "      <td>[0.8116741, 0.7202179, 0.6230456, 0.64590967, ...</td>\n",
       "      <td>[0.7982271, 1.0675378, 1.1112098, 0.8346204, 1...</td>\n",
       "      <td>[0.882244, 1.2294496, 1.485585, 1.2322956, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>[[1125, 1324], [3519, 3720], [5815, 6014], [76...</td>\n",
       "      <td>[[192, 248], [389, 405], [916, 929], [929, 948...</td>\n",
       "      <td>[[33019, 33020], [33246, 33251], [33253, 33255...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>[1384, 2444, 2769, 4155, 5541, 6708, 6927, 831...</td>\n",
       "      <td>[[1126742, 1326741], [3526740, 3726740], [5826...</td>\n",
       "      <td>[[192745, 249350], [389747, 407142], [917544, ...</td>\n",
       "      <td>[[33037711, 33038706], [33264908, 33270313], [...</td>\n",
       "      <td>[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...</td>\n",
       "      <td>[-0.058899105, 0.19379705, 0.72198904, 1.09058...</td>\n",
       "      <td>[0.052017204, 0.2566182, 0.409202, 0.2288757, ...</td>\n",
       "      <td>[0.0039443844, 0.2524406, 0.48910367, 0.408243...</td>\n",
       "      <td>[0.0017428675, 0.040085953, 0.1289722, 0.19345...</td>\n",
       "      <td>[0.24099746, 0.36528546, 0.31526712, -0.039408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>[[1125, 1324], [3519, 3720], [5815, 6014], [76...</td>\n",
       "      <td>[[192, 248], [389, 405], [916, 929], [929, 948...</td>\n",
       "      <td>[[33019, 33020], [33246, 33251], [33253, 33255...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>[1384, 2444, 2769, 4155, 5541, 6708, 6927, 831...</td>\n",
       "      <td>[[1126742, 1326741], [3526740, 3726740], [5826...</td>\n",
       "      <td>[[192745, 249350], [389747, 407142], [917544, ...</td>\n",
       "      <td>[[33037711, 33038706], [33264908, 33270313], [...</td>\n",
       "      <td>[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...</td>\n",
       "      <td>[-0.5686467, -0.88410044, -0.7741067, -0.08716...</td>\n",
       "      <td>[-0.7133093, -1.0918, -0.88557106, -0.07278667...</td>\n",
       "      <td>[-0.38970518, -0.8093877, -0.46165076, 0.39570...</td>\n",
       "      <td>[0.22564748, -0.09320222, 0.16678292, 0.760333...</td>\n",
       "      <td>[1.2494063, 1.0194397, 0.9779509, 1.0810802, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>[[916, 1117], [3312, 3513], [5608, 5808], [740...</td>\n",
       "      <td>[[49, 67], [70, 79], [360, 366], [460, 469], [...</td>\n",
       "      <td>[[33601, 33798], [34108, 34165], [34166, 34179...</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>[1384, 1384, 2770, 4156, 4156, 5541, 6927, 831...</td>\n",
       "      <td>[[918755, 1118758], [3318755, 3518757], [56187...</td>\n",
       "      <td>[[49358, 67558], [70155, 79355], [360955, 3671...</td>\n",
       "      <td>[[33624333, 33822933], [34132932, 34190535], [...</td>\n",
       "      <td>[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...</td>\n",
       "      <td>[-0.6503345, -0.6020239, -0.89374536, -1.10928...</td>\n",
       "      <td>[-0.99070936, -0.8981983, -1.0546261, -1.26992...</td>\n",
       "      <td>[-0.94037557, -0.9188701, -1.2414521, -1.48778...</td>\n",
       "      <td>[-1.0461473, -0.8379503, -0.76224226, -0.69685...</td>\n",
       "      <td>[-0.9619772, -0.89879316, -1.0425369, -1.38846...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort                                        session_dir  \\\n",
       "0       2  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "1       2  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "2       2  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "3       2  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "4       2  20230613_105657_standard_comp_to_training_D2_s...   \n",
       "\n",
       "                                       original_file  \\\n",
       "0  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "1  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "2  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "3  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "4  20230613_105657_standard_comp_to_training_D2_s...   \n",
       "\n",
       "                                         tone_frames  \\\n",
       "0  [[980, 1180], [3376, 3575], [5672, 5871], [746...   \n",
       "1  [[980, 1180], [3376, 3575], [5672, 5871], [746...   \n",
       "2  [[1125, 1324], [3519, 3720], [5815, 6014], [76...   \n",
       "3  [[1125, 1324], [3519, 3720], [5815, 6014], [76...   \n",
       "4  [[916, 1117], [3312, 3513], [5608, 5808], [740...   \n",
       "\n",
       "                             box_1_port_entry_frames  \\\n",
       "0  [[490, 514], [518, 558], [558, 637], [638, 640...   \n",
       "1  [[490, 514], [518, 558], [558, 637], [638, 640...   \n",
       "2  [[192, 248], [389, 405], [916, 929], [929, 948...   \n",
       "3  [[192, 248], [389, 405], [916, 929], [929, 948...   \n",
       "4  [[49, 67], [70, 79], [360, 366], [460, 469], [...   \n",
       "\n",
       "                             box_2_port_entry_frames  \\\n",
       "0  [[33021, 33027], [33502, 33503], [33504, 33506...   \n",
       "1  [[33021, 33027], [33502, 33503], [33504, 33506...   \n",
       "2  [[33019, 33020], [33246, 33251], [33253, 33255...   \n",
       "3  [[33019, 33020], [33246, 33251], [33253, 33255...   \n",
       "4  [[33601, 33798], [34108, 34165], [34166, 34179...   \n",
       "\n",
       "                                          video_name  \\\n",
       "0  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "1  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "2  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "3  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "4  20230613_105657_standard_comp_to_training_D2_s...   \n",
       "\n",
       "                                        session_path  \\\n",
       "0  /scratch/back_up/reward_competition_extention/...   \n",
       "1  /scratch/back_up/reward_competition_extention/...   \n",
       "2  /scratch/back_up/reward_competition_extention/...   \n",
       "3  /scratch/back_up/reward_competition_extention/...   \n",
       "4  /scratch/back_up/reward_competition_extention/...   \n",
       "\n",
       "                                           recording current_subject  ...  \\\n",
       "0  20230612_101430_standard_comp_to_training_D1_s...             1.3  ...   \n",
       "1  20230612_101430_standard_comp_to_training_D1_s...             1.4  ...   \n",
       "2  20230612_112630_standard_comp_to_training_D1_s...             1.1  ...   \n",
       "3  20230612_112630_standard_comp_to_training_D1_s...             1.2  ...   \n",
       "4  20230613_105657_standard_comp_to_training_D2_s...             1.1  ...   \n",
       "\n",
       "                                    video_timestamps  \\\n",
       "0  [-2, 1384, 2770, 4156, 4156, 5542, 6928, 6928,...   \n",
       "1  [-2, 1384, 2770, 4156, 4156, 5542, 6928, 6928,...   \n",
       "2  [1384, 2444, 2769, 4155, 5541, 6708, 6927, 831...   \n",
       "3  [1384, 2444, 2769, 4155, 5541, 6708, 6927, 831...   \n",
       "4  [1384, 1384, 2770, 4156, 4156, 5541, 6927, 831...   \n",
       "\n",
       "                                     tone_timestamps  \\\n",
       "0  [[982229, 1182226], [3382227, 3582224], [56822...   \n",
       "1  [[982229, 1182226], [3382227, 3582224], [56822...   \n",
       "2  [[1126742, 1326741], [3526740, 3726740], [5826...   \n",
       "3  [[1126742, 1326741], [3526740, 3726740], [5826...   \n",
       "4  [[918755, 1118758], [3318755, 3518757], [56187...   \n",
       "\n",
       "                         box_1_port_entry_timestamps  \\\n",
       "0  [[491029, 515227], [519426, 558629], [559427, ...   \n",
       "1  [[491029, 515227], [519426, 558629], [559427, ...   \n",
       "2  [[192745, 249350], [389747, 407142], [917544, ...   \n",
       "3  [[192745, 249350], [389747, 407142], [917544, ...   \n",
       "4  [[49358, 67558], [70155, 79355], [360955, 3671...   \n",
       "\n",
       "                         box_2_port_entry_timestamps  \\\n",
       "0  [[33082200, 33090003], [33565003, 33567000], [...   \n",
       "1  [[33082200, 33090003], [33565003, 33567000], [...   \n",
       "2  [[33037711, 33038706], [33264908, 33270313], [...   \n",
       "3  [[33037711, 33038706], [33264908, 33270313], [...   \n",
       "4  [[33624333, 33822933], [34132932, 34190535], [...   \n",
       "\n",
       "                                      lfp_timestamps  \\\n",
       "0  [0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...   \n",
       "1  [0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...   \n",
       "2  [0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...   \n",
       "3  [0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...   \n",
       "4  [0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...   \n",
       "\n",
       "                                      mPFC_lfp_trace  \\\n",
       "0  [0.933348, 0.8057418, 0.9461086, 1.2687699, 1....   \n",
       "1  [0.27034205, 0.4041477, 0.45876226, 0.52429974...   \n",
       "2  [-0.058899105, 0.19379705, 0.72198904, 1.09058...   \n",
       "3  [-0.5686467, -0.88410044, -0.7741067, -0.08716...   \n",
       "4  [-0.6503345, -0.6020239, -0.89374536, -1.10928...   \n",
       "\n",
       "                                        MD_lfp_trace  \\\n",
       "0  [0.44765243, 0.479771, 0.7427417, 0.97560126, ...   \n",
       "1  [0.8194214, 0.80269855, 0.71908414, 0.64104396...   \n",
       "2  [0.052017204, 0.2566182, 0.409202, 0.2288757, ...   \n",
       "3  [-0.7133093, -1.0918, -0.88557106, -0.07278667...   \n",
       "4  [-0.99070936, -0.8981983, -1.0546261, -1.26992...   \n",
       "\n",
       "                                        LH_lfp_trace  \\\n",
       "0  [0.89443207, 0.96188104, 1.1935536, 1.3225864,...   \n",
       "1  [0.8116741, 0.7202179, 0.6230456, 0.64590967, ...   \n",
       "2  [0.0039443844, 0.2524406, 0.48910367, 0.408243...   \n",
       "3  [-0.38970518, -0.8093877, -0.46165076, 0.39570...   \n",
       "4  [-0.94037557, -0.9188701, -1.2414521, -1.48778...   \n",
       "\n",
       "                                       BLA_lfp_trace  \\\n",
       "0  [0.6654362, 0.6609094, 0.87366796, 1.0230516, ...   \n",
       "1  [0.7982271, 1.0675378, 1.1112098, 0.8346204, 1...   \n",
       "2  [0.0017428675, 0.040085953, 0.1289722, 0.19345...   \n",
       "3  [0.22564748, -0.09320222, 0.16678292, 0.760333...   \n",
       "4  [-1.0461473, -0.8379503, -0.76224226, -0.69685...   \n",
       "\n",
       "                                      vHPC_lfp_trace  \n",
       "0  [0.2327341, 0.3381231, 0.5568053, 0.74650556, ...  \n",
       "1  [0.882244, 1.2294496, 1.485585, 1.2322956, 1.0...  \n",
       "2  [0.24099746, 0.36528546, 0.31526712, -0.039408...  \n",
       "3  [1.2494063, 1.0194397, 0.9779509, 1.0810802, 0...  \n",
       "4  [-0.9619772, -0.89879316, -1.0425369, -1.38846...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFP_TRACES_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Power Calcuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the column name of all the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace_columns = [col for col in LFP_TRACES_DF.columns if \"lfp_trace\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mPFC_lfp_trace',\n",
       " 'MD_lfp_trace',\n",
       " 'LH_lfp_trace',\n",
       " 'BLA_lfp_trace',\n",
       " 'vHPC_lfp_trace']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calcuating the power at each frequency band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mPFC\n",
      "MD\n",
      "LH\n",
      "BLA\n",
      "vHPC\n"
     ]
    }
   ],
   "source": [
    "for col in trace_columns:\n",
    "    brain_region = col.split(\"_\")[0]\n",
    "    print(brain_region)\n",
    "\n",
    "    # Define column names\n",
    "    lfp_trace_col = f\"{brain_region}_lfp_trace\"\n",
    "    multitaper_col = f\"{brain_region}_power_multitaper\"\n",
    "    connectivity_col = f\"{brain_region}_power_connectivity\"\n",
    "    frequencies_col = f\"{brain_region}_power_calculation_frequencies\"\n",
    "    power_col = f\"{brain_region}_power_all_frequencies_all_windows\"\n",
    "    \n",
    "    # Apply Multitaper function to the lfp_trace column\n",
    "    LFP_TRACES_DF[multitaper_col] = LFP_TRACES_DF[lfp_trace_col].apply(\n",
    "        lambda x: Multitaper(\n",
    "            time_series=x, \n",
    "            sampling_frequency=RESAMPLE_RATE, \n",
    "            time_halfbandwidth_product=TIME_HALFBANDWIDTH_PRODUCT,\n",
    "            time_window_duration=TIME_WINDOW_DURATION, \n",
    "            time_window_step=TIME_WINDOW_STEP\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Apply Connectivity function to the multitaper column\n",
    "    LFP_TRACES_DF[connectivity_col] = LFP_TRACES_DF[multitaper_col].apply(\n",
    "        lambda x: Connectivity.from_multitaper(x)\n",
    "    )\n",
    "\n",
    "    # Apply frequencies and power functions to the connectivity column\n",
    "    LFP_TRACES_DF[frequencies_col] = LFP_TRACES_DF[connectivity_col].apply(\n",
    "        lambda x: x.frequencies\n",
    "    )\n",
    "    LFP_TRACES_DF[power_col] = LFP_TRACES_DF[connectivity_col].apply(\n",
    "        lambda x: x.power().squeeze()\n",
    "    )\n",
    "    \n",
    "    # Removing unnecessary columns\n",
    "    LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[multitaper_col, connectivity_col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "for col in trace_columns:\n",
    "    brain_region = col.split(\"_\")[0]\n",
    "    print(brain_region)\n",
    "    LFP_TRACES_DF[\"{}_multitaper\".format(brain_region)] = LFP_TRACES_DF[\"{}_lfp_trace\".format(brain_region)].apply(lambda x: Multitaper(time_series=x, sampling_frequency=RESAMPLE_RATE, time_halfbandwidth_product=TIME_HALFBANDWIDTH_PRODUCT,                                                                              time_window_duration=TIME_WINDOW_DURATION, time_window_step=TIME_WINDOW_STEP                                                                                                                                         ))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "for col in trace_columns:\n",
    "    print(col)\n",
    "    brain_region = col.split(\"_\")[0]\n",
    "    LFP_TRACES_DF[\"{}_connectivity\".format(brain_region)] = LFP_TRACES_DF[\"{}_multitaper\".format(brain_region)].apply(lambda x: Connectivity.from_multitaper(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "for col in trace_columns:\n",
    "    brain_region = col.split(\"_\")[0]\n",
    "    LFP_TRACES_DF[\"{}_frequencies\".format(brain_region)] = LFP_TRACES_DF[\"{}_connectivity\".format(brain_region)].apply(lambda x: x.frequencies)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "for col in trace_columns:\n",
    "    brain_region = col.split(\"_\")[0]\n",
    "    print(brain_region)\n",
    "    LFP_TRACES_DF[\"{}_power_all-window\".format(brain_region)] = LFP_TRACES_DF[\"{}_connectivity\".format(brain_region)].apply(lambda x: x.power().squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the timestamps of the power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_TRACES_DF[\"power_timestamps\"] = LFP_TRACES_DF[\"lfp_timestamps\"].apply(lambda x: x[(RESAMPLE_RATE//2):(-RESAMPLE_RATE//2):(RESAMPLE_RATE//2)])\n",
    "# .iloc[0][500:-500:500].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making sure that the timestamps for power makes sense with shape and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (6828,)\n",
       "1    (6828,)\n",
       "2    (6833,)\n",
       "3    (6833,)\n",
       "4    (6840,)\n",
       "Name: power_timestamps, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFP_TRACES_DF[\"power_timestamps\"].head().apply(lambda x: x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6828, 500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFP_TRACES_DF[[col for col in LFP_TRACES_DF.columns if \"power_all_frequencies_all_windows\" in col][0]].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,       20,       40, ..., 68293300, 68293320, 68293340],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFP_TRACES_DF[[col for col in LFP_TRACES_DF.columns if \"lfp_timestamps\" in col][0]].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   10000,    20000,    30000, ..., 68260000, 68270000, 68280000],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFP_TRACES_DF[[col for col in LFP_TRACES_DF.columns if \"power_timestamps\" in col][0]].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking if the right frequencies are being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mPFC_power_calculation_frequencies</th>\n",
       "      <th>MD_power_calculation_frequencies</th>\n",
       "      <th>LH_power_calculation_frequencies</th>\n",
       "      <th>BLA_power_calculation_frequencies</th>\n",
       "      <th>vHPC_power_calculation_frequencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mPFC_power_calculation_frequencies  \\\n",
       "0  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "1  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "2  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "3  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "4  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "\n",
       "                    MD_power_calculation_frequencies  \\\n",
       "0  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "1  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "2  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "3  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "4  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "\n",
       "                    LH_power_calculation_frequencies  \\\n",
       "0  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "1  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "2  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "3  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "4  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "\n",
       "                   BLA_power_calculation_frequencies  \\\n",
       "0  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "1  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "2  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "3  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "4  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "\n",
       "                  vHPC_power_calculation_frequencies  \n",
       "0  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...  \n",
       "1  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...  \n",
       "2  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...  \n",
       "3  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...  \n",
       "4  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFP_TRACES_DF[[col for col in LFP_TRACES_DF.columns if \"power_calculation_frequencies\" in col]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF.columns if \"power_calculation_frequencies\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort</th>\n",
       "      <th>session_dir</th>\n",
       "      <th>original_file</th>\n",
       "      <th>tone_frames</th>\n",
       "      <th>box_1_port_entry_frames</th>\n",
       "      <th>box_2_port_entry_frames</th>\n",
       "      <th>video_name</th>\n",
       "      <th>session_path</th>\n",
       "      <th>recording</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>...</th>\n",
       "      <th>MD_lfp_trace</th>\n",
       "      <th>LH_lfp_trace</th>\n",
       "      <th>BLA_lfp_trace</th>\n",
       "      <th>vHPC_lfp_trace</th>\n",
       "      <th>mPFC_power_all_frequencies_all_windows</th>\n",
       "      <th>MD_power_all_frequencies_all_windows</th>\n",
       "      <th>LH_power_all_frequencies_all_windows</th>\n",
       "      <th>BLA_power_all_frequencies_all_windows</th>\n",
       "      <th>vHPC_power_all_frequencies_all_windows</th>\n",
       "      <th>power_timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>[[980, 1180], [3376, 3575], [5672, 5871], [746...</td>\n",
       "      <td>[[490, 514], [518, 558], [558, 637], [638, 640...</td>\n",
       "      <td>[[33021, 33027], [33502, 33503], [33504, 33506...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.44765243, 0.479771, 0.7427417, 0.97560126, ...</td>\n",
       "      <td>[0.89443207, 0.96188104, 1.1935536, 1.3225864,...</td>\n",
       "      <td>[0.6654362, 0.6609094, 0.87366796, 1.0230516, ...</td>\n",
       "      <td>[0.2327341, 0.3381231, 0.5568053, 0.74650556, ...</td>\n",
       "      <td>[[0.04169420203133221, 0.0802730627855665, 0.0...</td>\n",
       "      <td>[[0.00632302042850671, 0.01745955943866885, 0....</td>\n",
       "      <td>[[0.01958979591078521, 0.04858419484241715, 0....</td>\n",
       "      <td>[[0.037601236825227174, 0.024253116170145916, ...</td>\n",
       "      <td>[[0.00963684644472439, 0.005739311937810972, 0...</td>\n",
       "      <td>[10000, 20000, 30000, 40000, 50000, 60000, 700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>[[980, 1180], [3376, 3575], [5672, 5871], [746...</td>\n",
       "      <td>[[490, 514], [518, 558], [558, 637], [638, 640...</td>\n",
       "      <td>[[33021, 33027], [33502, 33503], [33504, 33506...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.8194214, 0.80269855, 0.71908414, 0.64104396...</td>\n",
       "      <td>[0.8116741, 0.7202179, 0.6230456, 0.64590967, ...</td>\n",
       "      <td>[0.7982271, 1.0675378, 1.1112098, 0.8346204, 1...</td>\n",
       "      <td>[0.882244, 1.2294496, 1.485585, 1.2322956, 1.0...</td>\n",
       "      <td>[[0.00025558452388879546, 0.000589764980425109...</td>\n",
       "      <td>[[0.012226195470614404, 0.012737730544356085, ...</td>\n",
       "      <td>[[0.01642187126767235, 0.017656380769446853, 0...</td>\n",
       "      <td>[[0.0004749562250888264, 0.00213518215904488, ...</td>\n",
       "      <td>[[0.0012590738531862485, 0.0018918990992088727...</td>\n",
       "      <td>[10000, 20000, 30000, 40000, 50000, 60000, 700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>[[1125, 1324], [3519, 3720], [5815, 6014], [76...</td>\n",
       "      <td>[[192, 248], [389, 405], [916, 929], [929, 948...</td>\n",
       "      <td>[[33019, 33020], [33246, 33251], [33253, 33255...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.052017204, 0.2566182, 0.409202, 0.2288757, ...</td>\n",
       "      <td>[0.0039443844, 0.2524406, 0.48910367, 0.408243...</td>\n",
       "      <td>[0.0017428675, 0.040085953, 0.1289722, 0.19345...</td>\n",
       "      <td>[0.24099746, 0.36528546, 0.31526712, -0.039408...</td>\n",
       "      <td>[[0.021781332050411613, 0.009884830970954838, ...</td>\n",
       "      <td>[[0.009157902832466413, 0.0061483973893087214,...</td>\n",
       "      <td>[[0.016855146879814254, 0.011329709006153408, ...</td>\n",
       "      <td>[[0.00823432178047688, 0.005799925057989854, 0...</td>\n",
       "      <td>[[0.001064310349200692, 0.00697524514144805, 0...</td>\n",
       "      <td>[10000, 20000, 30000, 40000, 50000, 60000, 700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>[[1125, 1324], [3519, 3720], [5815, 6014], [76...</td>\n",
       "      <td>[[192, 248], [389, 405], [916, 929], [929, 948...</td>\n",
       "      <td>[[33019, 33020], [33246, 33251], [33253, 33255...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.7133093, -1.0918, -0.88557106, -0.07278667...</td>\n",
       "      <td>[-0.38970518, -0.8093877, -0.46165076, 0.39570...</td>\n",
       "      <td>[0.22564748, -0.09320222, 0.16678292, 0.760333...</td>\n",
       "      <td>[1.2494063, 1.0194397, 0.9779509, 1.0810802, 0...</td>\n",
       "      <td>[[0.18145923216443083, 0.2057156756448491, 0.2...</td>\n",
       "      <td>[[0.2328621757265994, 0.23294940155800348, 0.3...</td>\n",
       "      <td>[[0.3685718278926778, 0.36854706998129544, 0.4...</td>\n",
       "      <td>[[0.3391210999913441, 0.2897891034771225, 0.37...</td>\n",
       "      <td>[[0.23286783552444634, 0.17396429117361695, 0....</td>\n",
       "      <td>[10000, 20000, 30000, 40000, 50000, 60000, 700...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>[[916, 1117], [3312, 3513], [5608, 5808], [740...</td>\n",
       "      <td>[[49, 67], [70, 79], [360, 366], [460, 469], [...</td>\n",
       "      <td>[[33601, 33798], [34108, 34165], [34166, 34179...</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.99070936, -0.8981983, -1.0546261, -1.26992...</td>\n",
       "      <td>[-0.94037557, -0.9188701, -1.2414521, -1.48778...</td>\n",
       "      <td>[-1.0461473, -0.8379503, -0.76224226, -0.69685...</td>\n",
       "      <td>[-0.9619772, -0.89879316, -1.0425369, -1.38846...</td>\n",
       "      <td>[[0.03205044002405316, 0.023584636883166452, 0...</td>\n",
       "      <td>[[0.07614841881452278, 0.049348754656105644, 0...</td>\n",
       "      <td>[[0.048744325828076675, 0.031626995161513904, ...</td>\n",
       "      <td>[[0.09511804801095025, 0.06073760225092326, 0....</td>\n",
       "      <td>[[0.03449033639067145, 0.020391753288298446, 0...</td>\n",
       "      <td>[10000, 20000, 30000, 40000, 50000, 60000, 700...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort                                        session_dir  \\\n",
       "0       2  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "1       2  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "2       2  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "3       2  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "4       2  20230613_105657_standard_comp_to_training_D2_s...   \n",
       "\n",
       "                                       original_file  \\\n",
       "0  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "1  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "2  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "3  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "4  20230613_105657_standard_comp_to_training_D2_s...   \n",
       "\n",
       "                                         tone_frames  \\\n",
       "0  [[980, 1180], [3376, 3575], [5672, 5871], [746...   \n",
       "1  [[980, 1180], [3376, 3575], [5672, 5871], [746...   \n",
       "2  [[1125, 1324], [3519, 3720], [5815, 6014], [76...   \n",
       "3  [[1125, 1324], [3519, 3720], [5815, 6014], [76...   \n",
       "4  [[916, 1117], [3312, 3513], [5608, 5808], [740...   \n",
       "\n",
       "                             box_1_port_entry_frames  \\\n",
       "0  [[490, 514], [518, 558], [558, 637], [638, 640...   \n",
       "1  [[490, 514], [518, 558], [558, 637], [638, 640...   \n",
       "2  [[192, 248], [389, 405], [916, 929], [929, 948...   \n",
       "3  [[192, 248], [389, 405], [916, 929], [929, 948...   \n",
       "4  [[49, 67], [70, 79], [360, 366], [460, 469], [...   \n",
       "\n",
       "                             box_2_port_entry_frames  \\\n",
       "0  [[33021, 33027], [33502, 33503], [33504, 33506...   \n",
       "1  [[33021, 33027], [33502, 33503], [33504, 33506...   \n",
       "2  [[33019, 33020], [33246, 33251], [33253, 33255...   \n",
       "3  [[33019, 33020], [33246, 33251], [33253, 33255...   \n",
       "4  [[33601, 33798], [34108, 34165], [34166, 34179...   \n",
       "\n",
       "                                          video_name  \\\n",
       "0  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "1  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "2  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "3  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "4  20230613_105657_standard_comp_to_training_D2_s...   \n",
       "\n",
       "                                        session_path  \\\n",
       "0  /scratch/back_up/reward_competition_extention/...   \n",
       "1  /scratch/back_up/reward_competition_extention/...   \n",
       "2  /scratch/back_up/reward_competition_extention/...   \n",
       "3  /scratch/back_up/reward_competition_extention/...   \n",
       "4  /scratch/back_up/reward_competition_extention/...   \n",
       "\n",
       "                                           recording current_subject  ...  \\\n",
       "0  20230612_101430_standard_comp_to_training_D1_s...             1.3  ...   \n",
       "1  20230612_101430_standard_comp_to_training_D1_s...             1.4  ...   \n",
       "2  20230612_112630_standard_comp_to_training_D1_s...             1.1  ...   \n",
       "3  20230612_112630_standard_comp_to_training_D1_s...             1.2  ...   \n",
       "4  20230613_105657_standard_comp_to_training_D2_s...             1.1  ...   \n",
       "\n",
       "                                        MD_lfp_trace  \\\n",
       "0  [0.44765243, 0.479771, 0.7427417, 0.97560126, ...   \n",
       "1  [0.8194214, 0.80269855, 0.71908414, 0.64104396...   \n",
       "2  [0.052017204, 0.2566182, 0.409202, 0.2288757, ...   \n",
       "3  [-0.7133093, -1.0918, -0.88557106, -0.07278667...   \n",
       "4  [-0.99070936, -0.8981983, -1.0546261, -1.26992...   \n",
       "\n",
       "                                        LH_lfp_trace  \\\n",
       "0  [0.89443207, 0.96188104, 1.1935536, 1.3225864,...   \n",
       "1  [0.8116741, 0.7202179, 0.6230456, 0.64590967, ...   \n",
       "2  [0.0039443844, 0.2524406, 0.48910367, 0.408243...   \n",
       "3  [-0.38970518, -0.8093877, -0.46165076, 0.39570...   \n",
       "4  [-0.94037557, -0.9188701, -1.2414521, -1.48778...   \n",
       "\n",
       "                                       BLA_lfp_trace  \\\n",
       "0  [0.6654362, 0.6609094, 0.87366796, 1.0230516, ...   \n",
       "1  [0.7982271, 1.0675378, 1.1112098, 0.8346204, 1...   \n",
       "2  [0.0017428675, 0.040085953, 0.1289722, 0.19345...   \n",
       "3  [0.22564748, -0.09320222, 0.16678292, 0.760333...   \n",
       "4  [-1.0461473, -0.8379503, -0.76224226, -0.69685...   \n",
       "\n",
       "                                      vHPC_lfp_trace  \\\n",
       "0  [0.2327341, 0.3381231, 0.5568053, 0.74650556, ...   \n",
       "1  [0.882244, 1.2294496, 1.485585, 1.2322956, 1.0...   \n",
       "2  [0.24099746, 0.36528546, 0.31526712, -0.039408...   \n",
       "3  [1.2494063, 1.0194397, 0.9779509, 1.0810802, 0...   \n",
       "4  [-0.9619772, -0.89879316, -1.0425369, -1.38846...   \n",
       "\n",
       "              mPFC_power_all_frequencies_all_windows  \\\n",
       "0  [[0.04169420203133221, 0.0802730627855665, 0.0...   \n",
       "1  [[0.00025558452388879546, 0.000589764980425109...   \n",
       "2  [[0.021781332050411613, 0.009884830970954838, ...   \n",
       "3  [[0.18145923216443083, 0.2057156756448491, 0.2...   \n",
       "4  [[0.03205044002405316, 0.023584636883166452, 0...   \n",
       "\n",
       "                MD_power_all_frequencies_all_windows  \\\n",
       "0  [[0.00632302042850671, 0.01745955943866885, 0....   \n",
       "1  [[0.012226195470614404, 0.012737730544356085, ...   \n",
       "2  [[0.009157902832466413, 0.0061483973893087214,...   \n",
       "3  [[0.2328621757265994, 0.23294940155800348, 0.3...   \n",
       "4  [[0.07614841881452278, 0.049348754656105644, 0...   \n",
       "\n",
       "                LH_power_all_frequencies_all_windows  \\\n",
       "0  [[0.01958979591078521, 0.04858419484241715, 0....   \n",
       "1  [[0.01642187126767235, 0.017656380769446853, 0...   \n",
       "2  [[0.016855146879814254, 0.011329709006153408, ...   \n",
       "3  [[0.3685718278926778, 0.36854706998129544, 0.4...   \n",
       "4  [[0.048744325828076675, 0.031626995161513904, ...   \n",
       "\n",
       "               BLA_power_all_frequencies_all_windows  \\\n",
       "0  [[0.037601236825227174, 0.024253116170145916, ...   \n",
       "1  [[0.0004749562250888264, 0.00213518215904488, ...   \n",
       "2  [[0.00823432178047688, 0.005799925057989854, 0...   \n",
       "3  [[0.3391210999913441, 0.2897891034771225, 0.37...   \n",
       "4  [[0.09511804801095025, 0.06073760225092326, 0....   \n",
       "\n",
       "              vHPC_power_all_frequencies_all_windows  \\\n",
       "0  [[0.00963684644472439, 0.005739311937810972, 0...   \n",
       "1  [[0.0012590738531862485, 0.0018918990992088727...   \n",
       "2  [[0.001064310349200692, 0.00697524514144805, 0...   \n",
       "3  [[0.23286783552444634, 0.17396429117361695, 0....   \n",
       "4  [[0.03449033639067145, 0.020391753288298446, 0...   \n",
       "\n",
       "                                    power_timestamps  \n",
       "0  [10000, 20000, 30000, 40000, 50000, 60000, 700...  \n",
       "1  [10000, 20000, 30000, 40000, 50000, 60000, 700...  \n",
       "2  [10000, 20000, 30000, 40000, 50000, 60000, 700...  \n",
       "3  [10000, 20000, 30000, 40000, 50000, 60000, 700...  \n",
       "4  [10000, 20000, 30000, 40000, 50000, 60000, 700...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFP_TRACES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the trace column pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain_region_pairs = generate_pairs(sorted(trace_columns))\n",
    "brain_region_pairs = sorted(brain_region_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain_region_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting just the region names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pair_base_name = []\n",
    "for region_1, region_2 in brain_region_pairs:\n",
    "    all_pair_base_name.append(\"{}_{}\".format(region_1.split(\"_\")[0], region_2.split(\"_\")[0]))\n",
    "all_pair_base_name = sorted(all_pair_base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_pair_base_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherece Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculating the coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_TRACES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for region_1, region_2 in brain_region_pairs:\n",
    "    pair_base_name = \"{}_{}\".format(region_1.split(\"_\")[0], region_2.split(\"_\")[0])\n",
    "    print(pair_base_name)\n",
    "    \n",
    "    try:\n",
    "        multitaper_col = \"{}_multitaper\".format(pair_base_name)\n",
    "        LFP_TRACES_DF[multitaper_col] = LFP_TRACES_DF.apply(lambda x: Multitaper(time_series=np.array([x[region_1],x[region_2]]).T, sampling_frequency=RESAMPLE_RATE, time_halfbandwidth_product=TIME_HALFBANDWIDTH_PRODUCT, time_window_step=TIME_WINDOW_STEP, time_window_duration=TIME_WINDOW_DURATION), axis=1)\n",
    "    \n",
    "        connectivity_col = \"{}_connectivity\".format(pair_base_name)\n",
    "        LFP_TRACES_DF[connectivity_col] = LFP_TRACES_DF[multitaper_col].apply(lambda x: Connectivity.from_multitaper(x))\n",
    "        \n",
    "        LFP_TRACES_DF[\"{}_frequencies\".format(pair_base_name)] = LFP_TRACES_DF[connectivity_col].apply(lambda x: x.frequencies)\n",
    "    \n",
    "        LFP_TRACES_DF[\"{}_all_window_coherence\".format(pair_base_name)] = LFP_TRACES_DF[connectivity_col].apply(lambda x: x.coherence_magnitude()[:,:,0,1])\n",
    "\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[multitaper_col, connectivity_col], errors=\"ignore\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_TRACES_DF.head()\n",
    "# [\"BLA_LH_all_window_coherence\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_TRACES_DF[\"lfp_timestamps\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "68293340 / 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "68280000/20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAP_AND_ALL_TRIALS_DF = pd.read_pickle(\"./proc/full_baseline_and_trial_lfp_traces.pkl\")\n",
    "MERGED_TRIALS_AND_VIDEO = pd.read_pickle(\"./proc/trial_SLEAP_and_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME_TO_COLOR = {'lose': \"red\",\n",
    " 'omission': \"orange\",\n",
    " 'rewarded': \"green\",\n",
    " 'win': \"blue\"}\n",
    "\n",
    "OUTCOME_TO_COLOR = {'lose': \"#951a1d\",\n",
    " 'omission': \"#af780d\",\n",
    " 'rewarded': \"#0499af\",\n",
    " 'win': \"#3853a3\",\n",
    "'lose_comp': \"#951a1d\",\n",
    " 'win_comp': \"#3853a3\",\n",
    "'lose_non_comp': \"#e67073\",\n",
    " 'win_non_comp': \"#93a5da\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME_COMPARISONS = {\"win_lose\": (\"win\", \"lose\"), \"lose_omission\": (\"lose\", \"omission\"), \"win_rewarded\": (\"win\", \"rewarded\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_OR_BASELINE_TO_STYLE = {'baseline': \"--\", \"trial\": \"-\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_HALFBANDWIDTH_PRODUCT = 2\n",
    "TIME_WINDOW_DURATION = 1\n",
    "TIME_WINDOW_STEP = 0.5\n",
    "RESAMPLE_RATE=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_TO_VELOCITY = {0: \"0 to 2.5cm/s\", 1: \"2.5 to 5cm/s\", 2: \"5 to 10 cm/s\", 3: \"10cm/s+\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_VELOCITY = 0\n",
    "MAX_VELOCITY = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DISTANCE = 0\n",
    "MAX_DISTANCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_BANDS = [\"theta\", \"beta\", \"gamma\"]\n",
    "BAND_TO_FREQ = {\"theta\": {\"low_freq\": 6, \"high_freq\": 11}, \"beta\": {\"low_freq\": 20, \"high_freq\": 31}, \"gamma\": {\"low_freq\": 30, \"high_freq\": 51}}\n",
    "BAND_TO_FREQ = {\"theta\": (6,11), \"beta\": (20,31), \"gamma\": (30,51)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_YLIM = {\"theta\": 0.065,\n",
    "\"beta\": 0.007,\n",
    "\"gamma\": 0.005}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAIN_REGIONS = [\"mPFC\",\n",
    "\"vHPC\",\n",
    "\"BLA\",\n",
    "\"LH\",\n",
    "\"MD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_COMPARISONS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPINGS = \"trial_outcome\"\n",
    "# GROUPINGS = \"competition_closeness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_TRIALS_AND_VIDEO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAP_AND_ALL_TRIALS_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(lst):\n",
    "    pairs = []\n",
    "    n = len(lst)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            pairs.append((lst[i], lst[j]))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict():\n",
    "    return defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_of_counter(counter):\n",
    "    # Extract values from the Counter and calculate the mean\n",
    "    values = list(counter.values())\n",
    "    return sum(values) / len(values) if values else 0  # Prevent division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lightness(color, amount=0.5):\n",
    "    \"\"\"\n",
    "    Adjusts the lightness of the given color by the provided amount.\n",
    "    :param color: Input color in some format that matplotlib's `to_rgb` can handle.\n",
    "    :param amount: Amount to adjust. > 1 for lighter, < 1 for darker.\n",
    "    :return: Adjusted color.\n",
    "    \"\"\"\n",
    "    import colorsys\n",
    "    c = mcolors.to_rgb(color)\n",
    "    h, l, s = colorsys.rgb_to_hls(*c)\n",
    "    return colorsys.hls_to_rgb(h, max(0, min(1, amount * l)), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gradient_colors(base_color, num_colors=10):\n",
    "    \"\"\"\n",
    "    Generate gradient colors based on a base color.\n",
    "    \n",
    "    :param base_color: The base color to create a gradient from.\n",
    "    :param num_colors: The number of gradient colors to generate.\n",
    "    :return: List of colors.\n",
    "    \"\"\"\n",
    "    # Convert base color to HLS (Hue, Lightness, Saturation)\n",
    "    h, l, s = colorsys.rgb_to_hls(*mcolors.to_rgb(base_color))\n",
    "\n",
    "    # Determine the step size for lightness\n",
    "    middle_index = num_colors // 2\n",
    "    lightness_step = l / (middle_index if middle_index > 0 else 1)\n",
    "\n",
    "    colors = []\n",
    "    for i in range(num_colors):\n",
    "        if i < middle_index:\n",
    "            # For the lighter colors (before the middle)\n",
    "            new_lightness = l + (middle_index - i) * lightness_step\n",
    "        elif i == middle_index:\n",
    "            # The middle color remains the base color\n",
    "            new_lightness = l\n",
    "        else:\n",
    "            # For the darker colors (after the middle)\n",
    "            new_lightness = l - (i - middle_index) * lightness_step\n",
    "\n",
    "        # Ensure new lightness is within the valid range [0, 1]\n",
    "        new_lightness = max(0, min(new_lightness, 1))\n",
    "\n",
    "        new_color = colorsys.hls_to_rgb(h, new_lightness, s)\n",
    "        colors.append(new_color)\n",
    "\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significance_stars_from_p_value(p_value, number_of_comparisons=3):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if p_value <= 0.001 / number_of_comparisons:\n",
    "        return \"***\"\n",
    "    elif p_value <= 0.01 / number_of_comparisons:\n",
    "        return \"***\"\n",
    "    elif p_value <= 0.05 / number_of_comparisons:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original color\n",
    "original_color = 'red'  # Can be any color matplotlib understands\n",
    "\n",
    "# Generate lighter versions\n",
    "lighter_colors = [adjust_lightness(original_color, amount=1+(0.1*i)) for i in range(12)]\n",
    "\n",
    "# Plotting to demonstrate the colors\n",
    "for i, color in enumerate(lighter_colors):\n",
    "    plt.plot([i-0.5, i+0.5], [1, 1], color=color, linewidth=6)  \n",
    "\n",
    "plt.ylim(0.9, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base color\n",
    "base_color = '#ff5733'  # Reddish color\n",
    "\n",
    "# Number of colors you want in the gradient\n",
    "num_colors = 10\n",
    "\n",
    "# Generate gradient colors\n",
    "gradient_colors = generate_gradient_colors(base_color, num_colors)\n",
    "\n",
    "# Set the color cycle to use the gradient colors\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=gradient_colors)\n",
    "\n",
    "# Test by plotting some data\n",
    "for i in range(num_colors):\n",
    "    plt.plot(np.arange(10), np.random.rand(10) + i)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAP_AND_ALL_TRIALS_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MERGED_TRIALS_AND_VIDEO.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging LFP Trace dataframe and SLEAP pose tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_columns = [\"time\", \"recording_file\", \"current_subject\", \"video_number\"]\n",
    "# Find columns in df2 that are not in merge_columns and also exist in df1, then drop them from df2\n",
    "cols_to_drop = [col for col in CHANNEL_MAP_AND_ALL_TRIALS_DF.columns if col not in merge_columns and col in MERGED_TRIALS_AND_VIDEO.columns]\n",
    "CHANNEL_MAP_AND_ALL_TRIALS_DF = CHANNEL_MAP_AND_ALL_TRIALS_DF.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF = pd.merge(left=CHANNEL_MAP_AND_ALL_TRIALS_DF, right=MERGED_TRIALS_AND_VIDEO, on=merge_columns, how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Dropping all unnecessary columns\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"spike_interface\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"index\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"stamp\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"box\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"height\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"width\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"ratio\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"width\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=['individual_subj',\n",
    " 'all_subj',\n",
    " 'recording_name',\n",
    " 'track_names',\n",
    " 'subject_id',\n",
    " 'corner_path',\n",
    " 'corner_parts',\n",
    " 'rescaled_locations',\n",
    " 'reward_port'], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LFP_TRACES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_columns = [col for col in LFP_TRACES_DF.columns if \"trace\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_trace_columns = sorted([col for col in LFP_TRACES_DF.columns if \"trial_lfp_trace\" in col])\n",
    "baseline_trace_columns = sorted([col for col in LFP_TRACES_DF.columns if \"baseline_lfp_trace\" in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_trace_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging the power for all the windows(without any velocity parsing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_all_window_columns = [col for col in LFP_TRACES_DF.columns if \"power_all-window\" in col and \"baseline-trial\" not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_all_window_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in power_all_window_columns:\n",
    "    brain_region = \"_\".join(col.split(\"_\")[:2])\n",
    "    print(brain_region)\n",
    "    LFP_TRACES_DF[\"{}_power_window-averaged\".format(brain_region)] = LFP_TRACES_DF.apply(lambda x: np.array(x[col]).mean(axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF[\"{}_power_window-averaged\".format(brain_region)].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF.drop(columns=trace_columns, errors=\"ignore\").to_pickle(\"./proc/rce_lfp_all-window_power.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing by velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting a mask for each segment based on velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bins = set(x for lst in LFP_TRACES_DF[\"trial_subject_thorax_velocity_binned\"] for x in lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_power_all_window_columns = [col for col in LFP_TRACES_DF if \"baseline_power_all-window\" in col and \"baseline-trial\" not in col]\n",
    "trial_power_window_averaged_columns = [col for col in LFP_TRACES_DF if \"trial_power_all-window\" in col and \"baseline-trial\" not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_power_all_window_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF[baseline_power_all_window_columns[0]].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF[\"baseline_subject_thorax-to-reward-port_distance_binned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bin_df = []\n",
    "for bin in all_bins:\n",
    "    current_df = LFP_TRACES_DF.copy()\n",
    "    current_df[\"baseline_velocity_binned-mask\"] = current_df[\"baseline_subject_thorax_velocity_binned\"].apply(lambda x: [index for index, num in enumerate(x) if num == bin])\n",
    "    current_df[\"trial_velocity_binned-mask\"] = current_df[\"trial_subject_thorax_velocity_binned\"].apply(lambda x: [index for index, num in enumerate(x) if num == bin])\n",
    "    \n",
    "    for col in baseline_power_all_window_columns:\n",
    "        brain_region = \"_\".join(col.split(\"_\")[:2])\n",
    "        current_df[\"{}_power_window-averaged-velocity-parsed\".format(brain_region)] = current_df.apply(lambda x: np.nanmean(np.array([x[col][i] for i in x[\"baseline_velocity_binned-mask\"]]), axis=0), axis=1)\n",
    "\n",
    "    for col in trial_power_window_averaged_columns:\n",
    "        brain_region = \"_\".join(col.split(\"_\")[:2])\n",
    "        current_df[\"{}_power_window-averaged-velocity-parsed\".format(brain_region)] = current_df.apply(lambda x: np.nanmean(np.array([x[col][i] for i in x[\"trial_velocity_binned-mask\"]]), axis=0), axis=1)\n",
    "    \n",
    "    current_df[\"velocity_bin\"] = bin\n",
    "    all_bin_df.append(current_df)\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VELOCITY_PARSED_LFP_TRACES_DF = pd.concat(all_bin_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting all the similar velocities together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_window_averaged_columns = [col for col in VELOCITY_PARSED_LFP_TRACES_DF.columns if \"power_window-averaged-velocity-parsed\" in col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grouping by trial outcome and velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_window_averaged_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df = VELOCITY_PARSED_LFP_TRACES_DF.groupby([GROUPINGS, 'velocity_bin']).agg({k: lambda x: np.vstack([arr for arr in x.tolist() if not np.any(np.isnan(arr))]) for k in power_window_averaged_columns}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"mPFC_baseline_power_window-averaged-velocity-parsed\"].iloc[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df = pd.melt(grouped_all_trials_df, id_vars =[GROUPINGS, 'velocity_bin'], value_vars =grouped_all_trials_df.drop(columns=[GROUPINGS, \"velocity_bin\"]).columns, value_name=\"power\", var_name=\"brain_region\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"brain_region\"] = grouped_all_trials_df[\"brain_region\"].apply(lambda x: x.split(\"_\")[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"trial_or_baseline\"] = grouped_all_trials_df[\"brain_region\"].apply(lambda x: x.split(\"_\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df = grouped_all_trials_df[grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"mean_power\"] = grouped_all_trials_df[\"power\"].apply(lambda x: np.nanmean(np.vstack(x), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"std_power\"] = grouped_all_trials_df[\"power\"].apply(lambda x: np.nanstd(np.vstack(x), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[\"power\"].apply(lambda x: np.sum(~np.isnan(x), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"sem_power\"] = grouped_all_trials_df.apply(lambda x: x[\"std_power\"] / np.sqrt(x[\"n_trials\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_all_trials_df[GROUPINGS].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_all_trials_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing all velocity bins together for each trial outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_FREQUENCIES = [int(num) for num in VELOCITY_PARSED_LFP_TRACES_DF[[col for col in VELOCITY_PARSED_LFP_TRACES_DF if \"frequencies\" in col][0]].iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "low_freq = 0\n",
    "high_freq = 13\n",
    "for region in grouped_all_trials_df[\"brain_region\"].unique():\n",
    "    region_df = grouped_all_trials_df[grouped_all_trials_df[\"brain_region\"] == region]\n",
    "\n",
    "    for outcome in region_df[GROUPINGS].unique():\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.title(\"{} during {} trials\".format(region.split(\"_\")[0], outcome), fontsize=30)\n",
    "        plt.xlabel(\"Frequency\", fontsize=20)\n",
    "        plt.ylabel(\"Power\", fontsize=20)\n",
    "        plt.xlim(low_freq, high_freq) \n",
    "        # plt.yscale(\"log\")\n",
    "        plt.ylim(0, 0.1)\n",
    "        outcome_df = region_df[(region_df[GROUPINGS] == outcome)]\n",
    "        # Generate gradient colors\n",
    "        gradient_colors = generate_gradient_colors(OUTCOME_TO_COLOR[outcome], 20)\n",
    "        \n",
    "        for index, row in outcome_df.iterrows():           \n",
    "            current_frequencies = ALL_FREQUENCIES[low_freq: high_freq]\n",
    "            mean_power = row[\"mean_power\"][low_freq: high_freq]\n",
    "            sem_power = row[\"sem_power\"][low_freq: high_freq]\n",
    "                \n",
    "            \n",
    "            try:\n",
    "                ax = sns.lineplot(x=current_frequencies, y=mean_power, \\\n",
    "                label=\"{}\".format(BIN_TO_VELOCITY[row[\"velocity_bin\"]]), linewidth=3, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "                \n",
    "                plt.fill_between(current_frequencies, \n",
    "                mean_power - sem_power, mean_power + sem_power, \\\n",
    "                alpha=0.1, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "            \n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "                continue\n",
    "                \n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"./proc/velocity_parsed_power/rce_velocity_parsed_lfp_power_freq_{}_to_{}_region_{}_{}.png\".format(low_freq, high_freq, region.split(\"_\")[0], outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq = 12\n",
    "high_freq = 31\n",
    "for region in grouped_all_trials_df[\"brain_region\"].unique():\n",
    "    region_df = grouped_all_trials_df[grouped_all_trials_df[\"brain_region\"] == region]\n",
    "\n",
    "    for outcome in region_df[GROUPINGS].unique():\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.title(\"Z-Scored LFP Power in {} for {}\".format(region.split(\"_\")[0], outcome))\n",
    "        plt.xlabel(\"Frequency\")\n",
    "        plt.ylabel(\"Power\")\n",
    "        plt.xlim(low_freq, high_freq) \n",
    "        # plt.yscale(\"log\")\n",
    "        plt.ylim(0, 0.015)\n",
    "        \n",
    "        outcome_df = region_df[(region_df[GROUPINGS] == outcome)]\n",
    "        # Generate gradient colors\n",
    "        gradient_colors = generate_gradient_colors(OUTCOME_TO_COLOR[outcome], 20)\n",
    "        \n",
    "        for index, row in outcome_df.iterrows():           \n",
    "            current_frequencies = ALL_FREQUENCIES[low_freq: high_freq]\n",
    "            mean_power = row[\"mean_power\"][low_freq: high_freq]\n",
    "            sem_power = row[\"sem_power\"][low_freq: high_freq]\n",
    "                \n",
    "            \n",
    "            try:\n",
    "                ax = sns.lineplot(x=current_frequencies, y=mean_power, \\\n",
    "                label=\"{} {}\".format(outcome, BIN_TO_VELOCITY[row[\"velocity_bin\"]]), linewidth=3, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "                \n",
    "                plt.fill_between(current_frequencies, \n",
    "                mean_power - sem_power, mean_power + sem_power, \\\n",
    "                alpha=0.1, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "            \n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "                continue\n",
    "        plt.legend()\n",
    "        plt.savefig(\"./proc/velocity_parsed_power/rce_velocity_parsed_lfp_power_freq_{}_to_{}_region_{}_{}.png\".format(low_freq, high_freq, region.split(\"_\")[0], outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "low_freq = 30\n",
    "high_freq = 91\n",
    "for region in grouped_all_trials_df[\"brain_region\"].unique():\n",
    "    region_df = grouped_all_trials_df[grouped_all_trials_df[\"brain_region\"] == region]\n",
    "\n",
    "    for outcome in region_df[GROUPINGS].unique():\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.title(\"Z-Scored LFP Power in {} for {}\".format(region.split(\"_\")[0], outcome))\n",
    "        plt.xlabel(\"Frequency\")\n",
    "        plt.ylabel(\"Power\")\n",
    "        plt.xlim(low_freq, high_freq) \n",
    "        # plt.yscale(\"log\")\n",
    "        plt.ylim(0, 0.004)\n",
    "        outcome_df = region_df[(region_df[GROUPINGS] == outcome)]\n",
    "        # Generate gradient colors\n",
    "        gradient_colors = generate_gradient_colors(OUTCOME_TO_COLOR[outcome], 20)\n",
    "        \n",
    "        for index, row in outcome_df.iterrows():           \n",
    "            current_frequencies = ALL_FREQUENCIES[low_freq: high_freq]\n",
    "            mean_power = row[\"mean_power\"][low_freq: high_freq]\n",
    "            sem_power = row[\"sem_power\"][low_freq: high_freq]\n",
    "                \n",
    "            \n",
    "            try:\n",
    "                ax = sns.lineplot(x=current_frequencies, y=mean_power, \\\n",
    "                label=\"{} {}\".format(outcome, BIN_TO_VELOCITY[row[\"velocity_bin\"]]), linewidth=3, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "                \n",
    "                plt.fill_between(current_frequencies, \n",
    "                mean_power - sem_power, mean_power + sem_power, \\\n",
    "                alpha=0.1, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "            \n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "                continue\n",
    "        plt.legend()\n",
    "        plt.savefig(\"./proc/velocity_parsed_power/rce_velocity_parsed_lfp_power_freq_{}_to_{}_region_{}_{}.png\".format(low_freq, high_freq, region.split(\"_\")[0], outcome))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting be velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df = VELOCITY_PARSED_LFP_TRACES_DF.groupby(['velocity_bin']).agg({k: lambda x: np.vstack([arr for arr in x.tolist() if not np.any(np.isnan(arr))]) for k in power_window_averaged_columns}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df = pd.melt(grouped_all_trials_df, id_vars =['velocity_bin'], value_vars =grouped_all_trials_df.drop(columns=[\"velocity_bin\"]).columns, value_name=\"power\", var_name=\"brain_region\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"brain_region\"] = grouped_all_trials_df[\"brain_region\"].apply(lambda x: x.split(\"_\")[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"trial_or_baseline\"] = grouped_all_trials_df[\"brain_region\"].apply(lambda x: x.split(\"_\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"mean_power\"] = grouped_all_trials_df[\"power\"].apply(lambda x: np.nanmean(np.vstack(x), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"std_power\"] = grouped_all_trials_df[\"power\"].apply(lambda x: np.nanstd(np.vstack(x), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[\"power\"].apply(lambda x: np.sum(~np.isnan(x), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"sem_power\"] = grouped_all_trials_df.apply(lambda x: x[\"std_power\"] / np.sqrt(x[\"n_trials\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing all velocity bins together for each trial outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME_TO_COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq = 0\n",
    "high_freq = 13\n",
    "for region in grouped_all_trials_df[\"brain_region\"].unique():\n",
    "    region_df = grouped_all_trials_df[(grouped_all_trials_df[\"brain_region\"] == region) & (grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\")]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"{} \".format(region.split(\"_\")[0]), fontsize=30)\n",
    "    plt.xlabel(\"Frequency\", fontsize=30)\n",
    "    plt.ylabel(\"Power\", fontsize=30)\n",
    "    plt.xlim(low_freq, high_freq) \n",
    "    # plt.yscale(\"log\")\n",
    "    \n",
    "    # Generate gradient colors\n",
    "    gradient_colors = generate_gradient_colors(\"red\", 20)\n",
    "    \n",
    "    for index, row in region_df.iterrows():           \n",
    "\n",
    "        current_frequencies = ALL_FREQUENCIES[low_freq: high_freq]\n",
    "        mean_power = row[\"mean_power\"][low_freq: high_freq]\n",
    "        sem_power = row[\"sem_power\"][low_freq: high_freq]\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            ax = sns.lineplot(x=current_frequencies, y=mean_power, \\\n",
    "            label=\"{}\".format(BIN_TO_VELOCITY[row[\"velocity_bin\"]]), linewidth=5, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "            \n",
    "            plt.fill_between(current_frequencies, \n",
    "            mean_power - sem_power, mean_power + sem_power, \\\n",
    "            alpha=0.1, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "        \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            continue\n",
    "    plt.tight_layout()\n",
    "    plt.legend(ncol=2)\n",
    "    plt.savefig(\"./proc/velocity_parsed_power/rce_velocity_parsed_lfp_power_freq_{}_to_{}_region_{}.png\".format(low_freq, high_freq, region.split(\"_\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq = 12\n",
    "high_freq = 31\n",
    "for region in grouped_all_trials_df[\"brain_region\"].unique():\n",
    "    region_df = grouped_all_trials_df[(grouped_all_trials_df[\"brain_region\"] == region) & (grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\")]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"Z-Scored LFP Power in {} \".format(region.split(\"_\")[0]), fontsize=30)\n",
    "    plt.xlabel(\"Frequency\", fontsize=30)\n",
    "    plt.ylabel(\"Power\", fontsize=30)\n",
    "    plt.xlim(low_freq, high_freq) \n",
    "    # plt.yscale(\"log\")\n",
    "    \n",
    "    # Generate gradient colors\n",
    "    gradient_colors = generate_gradient_colors(\"red\", 20)\n",
    "    \n",
    "    for index, row in region_df.iterrows():           \n",
    "\n",
    "        current_frequencies = ALL_FREQUENCIES[low_freq: high_freq]\n",
    "        mean_power = row[\"mean_power\"][low_freq: high_freq]\n",
    "        sem_power = row[\"sem_power\"][low_freq: high_freq]\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            ax = sns.lineplot(x=current_frequencies, y=mean_power, \\\n",
    "            label=\"{}\".format(BIN_TO_VELOCITY[row[\"velocity_bin\"]]), linewidth=5, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "            \n",
    "            plt.fill_between(current_frequencies, \n",
    "            mean_power - sem_power, mean_power + sem_power, \\\n",
    "            alpha=0.1, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "        \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            continue\n",
    "    plt.legend()\n",
    "    plt.savefig(\"./proc/velocity_parsed_power/rce_velocity_parsed_lfp_power_freq_{}_to_{}_region_{}.png\".format(low_freq, high_freq, region.split(\"_\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq = 30\n",
    "high_freq = 90\n",
    "for region in grouped_all_trials_df[\"brain_region\"].unique():\n",
    "    region_df = grouped_all_trials_df[(grouped_all_trials_df[\"brain_region\"] == region) & (grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\")]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"Z-Scored LFP Power in {} \".format(region.split(\"_\")[0]))\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.xlim(low_freq, high_freq) \n",
    "    # plt.yscale(\"log\")\n",
    "    \n",
    "    # Generate gradient colors\n",
    "    gradient_colors = generate_gradient_colors(\"red\", 20)\n",
    "    \n",
    "    for index, row in region_df.iterrows():           \n",
    "\n",
    "        current_frequencies = ALL_FREQUENCIES[low_freq: high_freq]\n",
    "        mean_power = row[\"mean_power\"][low_freq: high_freq]\n",
    "        sem_power = row[\"sem_power\"][low_freq: high_freq]\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            ax = sns.lineplot(x=current_frequencies, y=mean_power, \\\n",
    "            label=\"{}\".format(BIN_TO_VELOCITY[row[\"velocity_bin\"]]), linewidth=5, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "            \n",
    "            plt.fill_between(current_frequencies, \n",
    "            mean_power - sem_power, mean_power + sem_power, \\\n",
    "            alpha=0.1, color=gradient_colors[-(row[\"velocity_bin\"]+1) *4])\n",
    "        \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            continue\n",
    "    plt.legend()\n",
    "    plt.savefig(\"./proc/velocity_parsed_power/rce_velocity_parsed_lfp_power_freq_{}_to_{}_region_{}.png\".format(low_freq, high_freq, region.split(\"_\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse power by lower velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LFP_TRACES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LFP_TRACES_DF[\"trial_velocity_binned-mask\"] = LFP_TRACES_DF[\"trial_subject_thorax_velocity_chunked\"].apply(lambda x: [index for index, num in enumerate(x) if MIN_VELOCITY <= num <= MAX_VELOCITY])\n",
    "\n",
    "LFP_TRACES_DF[\"baseline_velocity_binned-mask\"] = LFP_TRACES_DF[\"baseline_subject_thorax_velocity_chunked\"].apply(lambda x: [index for index, num in enumerate(x) if MIN_VELOCITY <= num <= MAX_VELOCITY])\n",
    "\n",
    "for col in baseline_power_all_window_columns:\n",
    "    brain_region = \"_\".join(col.split(\"_\")[:2])\n",
    "    LFP_TRACES_DF[\"{}_power_window-averaged-velocity-parsed\".format(brain_region)] = LFP_TRACES_DF.apply(lambda x: np.nanmean(np.array([x[col][i] for i in x[\"baseline_velocity_binned-mask\"]]), axis=0), axis=1)\n",
    "\n",
    "for col in trial_power_window_averaged_columns:\n",
    "    brain_region = \"_\".join(col.split(\"_\")[:2])\n",
    "    LFP_TRACES_DF[\"{}_power_window-averaged-velocity-parsed\".format(brain_region)] = LFP_TRACES_DF.apply(lambda x: np.nanmean(np.array([x[col][i] for i in x[\"trial_velocity_binned-mask\"]]), axis=0), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in LFP_TRACES_DF.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VELOCITY_PARSED_LFP_TRACES_DF[GROUPINGS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df = VELOCITY_PARSED_LFP_TRACES_DF.groupby([GROUPINGS]).agg({k: lambda x: np.vstack([arr for arr in x.tolist() if not np.any(np.isnan(arr))]) for k in power_window_averaged_columns}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df = pd.melt(grouped_all_trials_df, id_vars =[GROUPINGS], value_vars =grouped_all_trials_df.drop(columns=[GROUPINGS]).columns, value_name=\"power\", var_name=\"brain_region\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"brain_region\"] = grouped_all_trials_df[\"brain_region\"].apply(lambda x: x.split(\"_\")[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"trial_or_baseline\"] = grouped_all_trials_df[\"brain_region\"].apply(lambda x: x.split(\"_\")[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"mean_power\"] = grouped_all_trials_df[\"power\"].apply(lambda x: np.nanmean(np.vstack(x), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"std_power\"] = grouped_all_trials_df[\"power\"].apply(lambda x: np.nanstd(np.vstack(x), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[\"power\"].apply(lambda x: np.sum(~np.isnan(x), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all_trials_df[\"sem_power\"] = grouped_all_trials_df.apply(lambda x: x[\"std_power\"] / np.sqrt(x[\"n_trials\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped_all_trials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME_TO_COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTSIZE=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'weight' : 'medium',\n",
    "        'size'   : 15}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_FREQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_FREQ_PLOT = {'theta': (6, 10), 'beta': (20, 30), 'gamma': (30, 50)}\n",
    "BAND_TO_FREQ_COLOR = {'theta': \"red\", 'beta': \"blue\", 'gamma': \"green\"}\n",
    "\n",
    "BAND_TO_FREQ_PLOT = {'theta': (6, 10), 'gamma': (30, 50)}\n",
    "BAND_TO_FREQ_COLOR = {'theta': \"red\", 'gamma': \"green\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "low_freq = 0\n",
    "high_freq = 51\n",
    "for region in grouped_all_trials_df[\"brain_region\"].unique():\n",
    "    region_df = grouped_all_trials_df[(grouped_all_trials_df[\"brain_region\"] == region) & (grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\")]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"Power Spectra {} \".format(region.split(\"_\")[0]), fontsize=FONTSIZE)\n",
    "    plt.xlabel(\"Frequency (Hz)\", fontsize=FONTSIZE)\n",
    "    plt.ylabel(\"Power (a.u.)\", fontsize=FONTSIZE)\n",
    "    plt.xlim(low_freq, high_freq) \n",
    "    plt.yscale(\"log\")\n",
    "        \n",
    "    for index, row in region_df.iterrows():           \n",
    "\n",
    "        current_frequencies = ALL_FREQUENCIES[low_freq: high_freq]\n",
    "        mean_power = row[\"mean_power\"][low_freq: high_freq]\n",
    "        sem_power = row[\"sem_power\"][low_freq: high_freq]\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            ax = sns.lineplot(x=current_frequencies, y=mean_power, \\\n",
    "            label=\"{}\".format(row[GROUPINGS]), linewidth=5, color=OUTCOME_TO_COLOR[row[GROUPINGS]])\n",
    "            \n",
    "            plt.fill_between(current_frequencies, \n",
    "            mean_power - sem_power, mean_power + sem_power, \\\n",
    "            alpha=0.1, color=OUTCOME_TO_COLOR[row[GROUPINGS]])\n",
    "        \n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            continue\n",
    "    for band, (min_freq, max_freq) in BAND_TO_FREQ_PLOT.items():\n",
    "        ax.axvspan(min_freq, max_freq, facecolor=BAND_TO_FREQ_COLOR[band], alpha=0.1, label=band)\n",
    "    plt.legend(fontsize=15, ncol=2)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./proc/velocity_parsed_power/power_spectra_all_conditions/rce_velocity_parsed_lfp_power_freq_{}_to_{}_region_{}.png\".format(low_freq, high_freq, region.split(\"_\")[0]))\n",
    "    plt.savefig(\"./proc/velocity_parsed_power/power_spectra_all_conditions/rce_velocity_parsed_lfp_power_freq_{}_to_{}_region_{}.eps\".format(low_freq, high_freq, region.split(\"_\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF.to_pickle(\"./proc/rce_sleap_and_power.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in LFP_TRACES_DF:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering for each frequency band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_window_averaged_velocity_parsed_columns = [col for col in LFP_TRACES_DF if \"trial_power_window-averaged-velocity-parsed\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF = LFP_TRACES_DF.dropna(subset=power_window_averaged_velocity_parsed_columns).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for power_column in [col for col in LFP_TRACES_DF if \"trial_power_window-averaged-velocity-parsed\" in col]:\n",
    "    region = power_column.split(\"_\")[0]\n",
    "    \n",
    "    for band, (low_freq, high_freq) in BAND_TO_FREQ.items():\n",
    "        region_band_column = \"{}_{}_band-power_window-averaged-velocity-parsed\".format(region, band)\n",
    "        LFP_TRACES_DF[region_band_column] = LFP_TRACES_DF[power_column].apply(lambda x: np.mean(x[low_freq: high_freq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAIN_REGIONS = [\"spike_interface_mPFC\",\n",
    "\"spike_interface_vHPC\",\n",
    "\"spike_interface_BLA\",\n",
    "\"spike_interface_LH\",\n",
    "\"spike_interface_MD\"]\n",
    "for column in [col for col in LFP_TRACES_DF if \"spike_interface\" in col]:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_power_window_averaged_velocity_parsed_columns = [col for col in LFP_TRACES_DF if \"band-power_window-averaged-velocity-parsed\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "band_power_window_averaged_velocity_parsed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_and_band_to_mannwhitneyu = []\n",
    "for col in band_power_window_averaged_velocity_parsed_columns:\n",
    "    brain_region = col.split(\"_\")[0]\n",
    "    band = col.split(\"_\")[1]\n",
    "    for first_outcome, second_outcome in combinations(sorted(LFP_TRACES_DF[GROUPINGS].unique()), 2):\n",
    "        first_outcome_df = LFP_TRACES_DF[LFP_TRACES_DF[GROUPINGS] == first_outcome]\n",
    "        second_outcome_df = LFP_TRACES_DF[LFP_TRACES_DF[GROUPINGS] == second_outcome]\n",
    "        statistic, p_value = mannwhitneyu(first_outcome_df[col], second_outcome_df[col], alternative='two-sided')\n",
    "        region_and_band_to_mannwhitneyu.append({\"brain_region\": brain_region, \"band\": band, \"trial_outcome\": (first_outcome, second_outcome), \"statistic\": statistic, \"p_value\": p_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_and_band_to_mannwhitneyu = pd.DataFrame(region_and_band_to_mannwhitneyu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_and_band_to_mannwhitneyu[\"significance\"] = region_and_band_to_mannwhitneyu[\"p_value\"].apply(lambda x: get_significance_stars_from_p_value(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_and_band_to_mannwhitneyu = region_and_band_to_mannwhitneyu.sort_values([\"band\", \"brain_region\", \"p_value\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_and_band_to_mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_and_band_to_mannwhitneyu.to_csv(\"./proc/velocity_parsed_power/power_region_and_band_to_mannwhitneyu.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_power_df = LFP_TRACES_DF.groupby(GROUPINGS)[band_power_window_averaged_velocity_parsed_columns].mean()\n",
    "sem_power_df = LFP_TRACES_DF.groupby(GROUPINGS)[band_power_window_averaged_velocity_parsed_columns].sem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_power_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF[LFP_TRACES_DF[\"trial_outcome\"] == \"lose\"][\"mPFC_theta_band-power_window-averaged-velocity-parsed\"].std() / len(LFP_TRACES_DF[LFP_TRACES_DF[\"trial_outcome\"] == \"lose\"]) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for column in band_power_window_averaged_velocity_parsed_columns:\n",
    "    fig, ax = plt.subplots(figsize=(23, 12))\n",
    "\n",
    "    brain_region = column.split(\"_\")[0]\n",
    "    band = column.split(\"_\")[1]\n",
    "    plt.title(\"Power of {} {} Band\".format(brain_region, band.capitalize()), fontsize=80)\n",
    "    plt.ylabel(\"Power (a.u.)\", fontsize=80)\n",
    "    bars = plt.bar(mean_power_df.index, mean_power_df[column], color=mean_power_df.index.map(OUTCOME_TO_COLOR))\n",
    "    \n",
    "    plt.errorbar(mean_power_df.index, mean_power_df[column],\n",
    "        yerr=sem_power_df[column],\n",
    "        color='k',\n",
    "        capsize=30,\n",
    "        linestyle='None',\n",
    "        elinewidth=7,\n",
    "        capthick=7)\n",
    "    \n",
    "    plt.ylim(0, BAND_TO_YLIM[band])\n",
    "    plt.xticks(fontsize=60)\n",
    "    plt.yticks(fontsize=60)\n",
    "    plt.locator_params(axis='y', nbins=4)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./proc/velocity_parsed_power/bar_plots/{}_{}_velocity_parsed_lfp_power_bar.eps\".format(band, brain_region)) #nancy changed png to eps\n",
    "    plt.savefig(\"./proc/velocity_parsed_power/bar_plots/{}_{}_velocity_parsed_lfp_power_bar.png\".format(band, brain_region)) #nancy changed png to eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for column in band_power_window_averaged_velocity_parsed_columns:\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "    brain_region = column.split(\"_\")[0]\n",
    "    band = column.split(\"_\")[1]\n",
    "    plt.title(\"Power of {} {} Band\".format(brain_region, band.capitalize()), fontsize=40)\n",
    "    plt.ylabel(\"Power (a.u.)\", fontsize=40)\n",
    "\n",
    "    all_outcome_data = [LFP_TRACES_DF[LFP_TRACES_DF[\"trial_outcome\"] == trial_outcome][column] for trial_outcome in LFP_TRACES_DF[\"trial_outcome\"].unique()]\n",
    "    \n",
    "    bplot = ax.boxplot(all_outcome_data,\n",
    "                         vert=True,  # vertical box alignment\n",
    "                         patch_artist=True,  # fill with color\n",
    "                         labels=LFP_TRACES_DF[\"trial_outcome\"].unique())  # will be used to label x-ticks\n",
    "\n",
    "    # fill with colors\n",
    "    for patch, trail_outcome in zip(bplot['boxes'], LFP_TRACES_DF[\"trial_outcome\"].unique()):\n",
    "        patch.set_facecolor(OUTCOME_TO_COLOR[trail_outcome])\n",
    "\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=40)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./proc/velocity_parsed_power/box_plots/{}_{}_velocity_parsed_lfp_box_plot.eps\".format(band, brain_region)) #nancy changed png to eps\n",
    "    plt.savefig(\"./proc/velocity_parsed_power/box_plots/{}_{}_velocity_parsed_lfp_box_plot.png\".format(band, brain_region)) #nancy changed png to eps\n",
    "    \n",
    "    # bars = plt.bar(mean_power_df.index, mean_power_df[column], color=mean_power_df.index.map(OUTCOME_TO_COLOR))\n",
    "    \n",
    "    # plt.errorbar(mean_power_df.index, mean_power_df[column],\n",
    "    #     yerr=sem_power_df[column],\n",
    "    #     color='k',\n",
    "    #     capsize=30,\n",
    "    #     linestyle='None',\n",
    "    #     elinewidth=7,\n",
    "    #     capthick=7)\n",
    "    \n",
    "    # plt.ylim(0, BAND_TO_YLIM[band])\n",
    "\n",
    "    # plt.locator_params(axis='y', nbins=4)\n",
    "    # ax.spines['top'].set_visible(False)\n",
    "    # ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE BELOW Exporting Velocity Parsed dataframe for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"lfp_trace\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF[\"mPFC_trial_power_window-averaged-velocity-parsed\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in LFP_TRACES_DF:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF.to_pickle(\"./proc/rce_sleap_and_power.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF[\"recording_file\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF = VELOCITY_PARSED_LFP_TRACES_DF[VELOCITY_PARSED_LFP_TRACES_DF[\"velocity_bin\"] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF = EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF.drop(columns=[col for col in EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF.columns if \"baseline\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF = EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF.drop(columns=[col for col in EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF.columns if \"trace\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF = pd.melt(EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF, id_vars=EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF.columns[:19], value_vars=[col for col in EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF.columns if \"power_window-averaged-velocity-parsed\" in col], value_name=\"power\", var_name=\"brain_region\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF[\"brain_region\"] = EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF[\"brain_region\"].apply(lambda x:x.split(\"_\")[0])\n",
    "EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF[\"trial_or_baseline\"] = EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF[\"brain_region\"].apply(lambda x:x.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF = EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF.dropna(subset=[\"power\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band, (min_freq, max_freq) in BAND_TO_FREQ.items():\n",
    "    EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF[\"mean_{}_power\".format(band)] = EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF[\"power\"].apply(lambda x: np.nanmean(x[min_freq:max_freq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF.to_pickle(\"./proc/rce_velocity_parsed_power_spectra_region_and_baselinetrial_rows.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in EXPORTED_VELOCITY_PARSED_LFP_TRACES_DF.columns[:19]:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the velocity parsed average power for each frequency band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_FREQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_parsed_power_window_averaged_columns = [col for col in LFP_TRACES_DF.columns if \"power_window-averaged-velocity-parsed\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "velocity_parsed_power_window_averaged_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing all trials that have a high velocity trhoguhout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACES_DF = LFP_TRACES_DF[LFP_TRACES_DF[\"trial_velocity_binned-mask\"].map(len) >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in velocity_parsed_power_window_averaged_columns:\n",
    "    region_base_name = \"_\".join(col.split(\"_\")[:2])\n",
    "    print(region_base_name)\n",
    "    for band, (min_freq, max_freq) in BAND_TO_FREQ.items():\n",
    "        print(band)\n",
    "        LFP_TRACES_DF[\"{}_{}_all_power\".format(region_base_name, band)] = LFP_TRACES_DF[col].apply(lambda x: x[min_freq:max_freq])\n",
    "        LFP_TRACES_DF[\"{}_{}_mean_power\".format(region_base_name, band)] = LFP_TRACES_DF[\"{}_{}_all_power\".format(region_base_name, band)].apply(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD_trial_mean_gamma_power\n",
    "mean_power_col = [col for col in LFP_TRACES_DF.columns if \"mean_power\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a2a9b2abc38041eea4133592bab67a87",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 820,
    "execution_start": 1698240824107,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "mean_power_df = pd.DataFrame(LFP_TRACES_DF.groupby([GROUPINGS])[mean_power_col].mean()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_power_df[\"color\"] = mean_power_df[GROUPINGS].map(OUTCOME_TO_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_power_df = pd.DataFrame(LFP_TRACES_DF.groupby([GROUPINGS])[mean_power_col].sem()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_power_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME_COMPARISONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_sum_dict = []\n",
    "for col in mean_power_col:\n",
    "    region = col.split(\"_\")[0]\n",
    "    baseline_or_trial = col.split(\"_\")[1]\n",
    "    band = col.split(\"_\")[2]\n",
    "    if baseline_or_trial != \"trial\":\n",
    "        continue\n",
    "    for key, (first_outcome, second_outcome) in  OUTCOME_COMPARISONS.items():\n",
    "        first_df = LFP_TRACES_DF[LFP_TRACES_DF[GROUPINGS] == first_outcome]\n",
    "        second_df = LFP_TRACES_DF[LFP_TRACES_DF[GROUPINGS] == second_outcome]\n",
    "        statistic, p_value = mannwhitneyu(first_df[col], second_df[col], alternative='two-sided')\n",
    "        rank_sum_dict.append({\"region\": region, \"band\": band, \"comparison\": key, \"mannwhitneyu_statistic\": statistic, \"mannwhitneyu_pvalue\": p_value, \"all_outcomes\": set([first_outcome, second_outcome])})\n",
    "rank_sum_df = pd.DataFrame(rank_sum_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(mean_power_df[[col for col in mean_power_df.columns if \"theta\" in col]].to_numpy().max() * 1.25, 3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bonferroni_threshold = 0.05 / len(OUTCOME_COMPARISONS)\n",
    "\n",
    "\n",
    "for col in mean_power_col:\n",
    "\n",
    "    # colors = [outcome_colors.get(outcome, \"gray\") for outcome in mean_region_df[GROUPINGS]]\n",
    "    # clean_region_name = region.replace(\"spike_interface_\", \"\")\n",
    "    region = col.split(\"_\")[0]\n",
    "    baseline_or_trial = col.split(\"_\")[1]\n",
    "    band = col.split(\"_\")[2]\n",
    "    if baseline_or_trial != \"trial\":\n",
    "        continue\n",
    "    # fig, ax = plt.subplots(figsize=(23, 12))\n",
    "    # fig, ax = plt.subplots()\n",
    "    fig, ax = plt.subplots(figsize=(23, 12))\n",
    "\n",
    "    plt.title(\"Power of {} {} Band\".format(region, band), fontsize=60)\n",
    "    plt.xlabel(\"Trial Condition\", fontsize=60)\n",
    "    plt.ylabel(\"Mean {} Power\".format(band), fontsize=60)\n",
    "\n",
    "    plt.xticks(fontsize=60)\n",
    "    plt.yticks(fontsize=45)\n",
    "    plt.locator_params(axis='y', nbins=4)\n",
    "    plt.ylim(0, round(mean_power_df[[col for col in mean_power_df.columns if band in col and \"trial\" in col]].to_numpy().max() * 1.1, 3))\n",
    "\n",
    "    bars = plt.bar(mean_power_df[GROUPINGS], mean_power_df[col], yerr=sem_power_df[col], color=mean_power_df[\"color\"])\n",
    "    \n",
    "    # Get the y-axis limits\n",
    "    bottom, top = ax.get_ylim()\n",
    "    y_range = top - bottom\n",
    "\n",
    "    # Retrieve x-coordinates of the bars\n",
    "    x_coords = [bar.get_x() + bar.get_width() / 2.0 for bar in bars]  # get_x() retrieves the left coordinate, we adjust by half the width to get the center\n",
    "    group_to_x_coord = {group: x_coord for group, x_coord in zip(mean_power_df[GROUPINGS].values, x_coords)}\n",
    "\n",
    "    current_df = rank_sum_df[(rank_sum_df[\"region\"] == region) & (rank_sum_df[\"band\"] == band)]\n",
    "    for index, row in current_df.iterrows():\n",
    "        p_value = row[\"mannwhitneyu_pvalue\"]\n",
    "        x1 = list(row[\"all_outcomes\"])[0]\n",
    "        x2 = list(row[\"all_outcomes\"])[1]\n",
    "        \n",
    "        if p_value < bonferroni_threshold:\n",
    "            if p_value < 0.001 / len(OUTCOME_COMPARISONS):\n",
    "                sig_symbol = '***'\n",
    "            elif p_value < 0.01 / len(OUTCOME_COMPARISONS):\n",
    "                sig_symbol = '**'\n",
    "            elif p_value < 0.05 / len(OUTCOME_COMPARISONS):\n",
    "                sig_symbol = '*'\n",
    "            else:\n",
    "                continue\n",
    "            # What level is this bar among the bars above the plot?\n",
    "            level = len(OUTCOME_COMPARISONS) - i\n",
    "            # Plot the bar\n",
    "            bar_height = (y_range * 0.055 * level) + top * 0.5\n",
    "            bar_tips = bar_height - (y_range * 0.025)\n",
    "            plt.plot(\n",
    "                # [x1, x1, x2, x2],\n",
    "                [x2, x2, x1, x1],\n",
    "\n",
    "                [bar_tips, bar_height, bar_height, bar_tips], lw=5, c='k'\n",
    "            )\n",
    "            \n",
    "            text_height = bar_height * 0.95 + (y_range / 100)\n",
    "            plt.text((group_to_x_coord[x1] + group_to_x_coord[x2]) * 0.5, text_height, sig_symbol, ha='center', va='bottom', c='k', size=50)\n",
    "        \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"./proc/velocity_parsed_power/rce_{}_{}_averaged_power.png\".format(region, band))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_TRACES_DF = LFP_TRACES_DF.copy()\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"multitaper\" in col], errors=\"ignore\").copy()\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"connectivity\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"frequencies\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"spike_interface\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"power_window-averaged-velocity-parsed\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"all-window_power\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"all_power\" in col], errors=\"ignore\")\n",
    "LFP_TRACES_DF = LFP_TRACES_DF.drop(columns=[col for col in LFP_TRACES_DF if \"window-averaged_power\" in col], errors=\"ignore\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "spike_interface_0_99_0",
   "language": "python",
   "name": "spike_interface_0_99_0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
