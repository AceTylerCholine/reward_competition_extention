{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# SLEAP Distance Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "THORAX_INDEX = 1\n",
    "CHANNEL_MAPPING_DF = pd.read_excel(\"../../channel_mapping.xlsx\")\n",
    "TONE_TIMESTAMP_DF = pd.read_excel(\"../../rce_tone_timestamp.xlsx\", index_col=0)\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = pd.read_excel(\"./video_to_frame_and_subject.xlsx\")\n",
    "SLEAP_DIR = \"/scratch/back_up/reward_competition_extention/proc/id_corrected\"\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n",
    "\n",
    "def calc_bmi(weight, height):\n",
    "    \"\"\"\n",
    "    This is a function that calculates BMI.\n",
    "    it uses height and weight...etc.\n",
    "    Meghan plz show us your docsctring format here.\n",
    "    \"\"\"\n",
    "    bmi = weight/(height**2)\n",
    "    return(bmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleap_tracks_from_h5(filename):\n",
    "    \"\"\"\n",
    "    Retrieve pose tracking data (tracks) from a SLEAP-generated h5 file.\n",
    "    \n",
    "    This function is intended for use with Pandas' apply method on columns containing filenames.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the SLEAP h5 file containing pose tracking data.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A transposed version of the 'tracks' dataset in the provided h5 file.\n",
    "        \n",
    "    Example:\n",
    "    --------\n",
    "    df['tracks'] = df['filename_column'].apply(get_sleap_tracks_from_h5)\n",
    "    \n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        return f[\"tracks\"][:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleap_track_names_from_h5(filename):\n",
    "    \"\"\"\n",
    "    Retrieve the names of tracked features from a SLEAP-generated h5 file.\n",
    "    \n",
    "    This function is intended for use with Pandas' apply method on columns containing filenames.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the SLEAP h5 file containing pose tracking data.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    h5py.Dataset\n",
    "        The 'track_names' dataset in the provided h5 file, representing the names of the tracked features.\n",
    "        \n",
    "    Example:\n",
    "    --------\n",
    "    df['track_names'] = df['filename_column'].apply(get_sleap_track_names_from_h5)\n",
    "    \n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        return [item.tobytes().decode('utf-8') for item in f[\"track_names\"][:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_names_from_sleap(filename):\n",
    "    \"\"\"\n",
    "    Retrieve node names from a SLEAP h5 file.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): Path to the SLEAP h5 file.\n",
    "\n",
    "    Returns:\n",
    "    - list of str: List of node names.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        return [n.decode() for n in f[\"node_names\"][:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_missing(Y, kind=\"linear\"):\n",
    "    \"\"\"Fills missing values independently along each dimension after the first.\"\"\"\n",
    "\n",
    "    # Store initial shape.\n",
    "    initial_shape = Y.shape\n",
    "\n",
    "    # Flatten after first dim.\n",
    "    Y = Y.reshape((initial_shape[0], -1))\n",
    "\n",
    "    # Interpolate along each slice.\n",
    "    for i in range(Y.shape[-1]):\n",
    "        y = Y[:, i]\n",
    "\n",
    "        # Build interpolant.\n",
    "        x = np.flatnonzero(~np.isnan(y))\n",
    "        f = interp1d(x, y[x], kind=kind, fill_value=np.nan, bounds_error=False)\n",
    "\n",
    "        # Fill missing\n",
    "        xq = np.flatnonzero(np.isnan(y))\n",
    "        y[xq] = f(xq)\n",
    "        \n",
    "        # Fill leading or trailing NaNs with the nearest non-NaN values\n",
    "        mask = np.isnan(y)\n",
    "        y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), y[~mask])\n",
    "\n",
    "        # Save slice\n",
    "        Y[:, i] = y\n",
    "\n",
    "    # Restore to initial shape.\n",
    "    Y = Y.reshape(initial_shape)\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_velocity(node_loc, window_size=25, polynomial_order=3):\n",
    "    \"\"\"\n",
    "    Calculate the velocity of tracked nodes from pose data.\n",
    "    \n",
    "    The function utilizes the Savitzky-Golay filter to smooth the data and compute the velocity.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    node_loc : numpy.ndarray\n",
    "        The location of nodes, represented as an array of shape [frames, 2]. \n",
    "        Each row represents x and y coordinates for a particular frame.\n",
    "        \n",
    "    window_size : int, optional\n",
    "        The size of the window used for the Savitzky-Golay filter. \n",
    "        Represents the number of consecutive data points used when smoothing the data.\n",
    "        Default is 25.\n",
    "        \n",
    "    polynomial_order : int, optional\n",
    "        The order of the polynomial fit to the data within the Savitzky-Golay filter window.\n",
    "        Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The velocity for each frame, calculated from the smoothed x and y coordinates.\n",
    "    \n",
    "    \"\"\"\n",
    "    node_loc_vel = np.zeros_like(node_loc)\n",
    "    \n",
    "    # For each coordinate (x and y), smooth the data and calculate the derivative (velocity)\n",
    "    for c in range(node_loc.shape[-1]):\n",
    "        node_loc_vel[:, c] = savgol_filter(node_loc[:, c], window_size, polynomial_order, deriv=1)\n",
    "    \n",
    "    # Calculate the magnitude of the velocity vectors for each frame\n",
    "    node_vel = np.linalg.norm(node_loc_vel, axis=1)\n",
    "\n",
    "    return node_vel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the h5 files between recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = VIDEO_TO_FRAME_AND_SUBJECT_DF.dropna(subset=\"start_frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>stop_frame</th>\n",
       "      <th>individual_subj</th>\n",
       "      <th>all_subj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>32792.0</td>\n",
       "      <td>68495.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1_1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32316.0</td>\n",
       "      <td>1.1_1.4</td>\n",
       "      <td>1.1_1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>32792.0</td>\n",
       "      <td>68495.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1_1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>32860.0</td>\n",
       "      <td>68288.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1_1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>32240.0</td>\n",
       "      <td>1.1_1.2</td>\n",
       "      <td>1.1_1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  start_frame  stop_frame  \\\n",
       "0  /scratch/back_up/reward_competition_extention/...      32792.0     68495.0   \n",
       "1  /scratch/back_up/reward_competition_extention/...          0.0     32316.0   \n",
       "2  /scratch/back_up/reward_competition_extention/...      32792.0     68495.0   \n",
       "4  /scratch/back_up/reward_competition_extention/...      32860.0     68288.0   \n",
       "5  /scratch/back_up/reward_competition_extention/...       2027.0     32240.0   \n",
       "\n",
       "  individual_subj all_subj  \n",
       "0             1.4  1.1_1.4  \n",
       "1         1.1_1.4  1.1_1.4  \n",
       "2             1.1  1.1_1.4  \n",
       "4             1.2  1.1_1.2  \n",
       "5         1.1_1.2  1.1_1.2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be indexing for the frames, so they must be integers and not floats\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"start_frame\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"start_frame\"].astype(int)\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"stop_frame\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"stop_frame\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the basename of the file which corresponds to the ephys recording that the h5 file came from\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"recording_name\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].apply(lambda x: os.path.basename(x).split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the coordinates of all the body parts for all the animals for the entire recording\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"locations\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].apply(lambda x: get_sleap_tracks_from_h5(x))\n",
    "# Getting the name of the tracks which correspond to the animal id\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"track_names\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].apply(lambda x: get_sleap_track_names_from_h5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68495, 6, 2, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"locations\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure all the subject IDs are strings instead of floating point numbers\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"individual_subj\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"individual_subj\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                [1.4]\n",
       "1    [1.1, 1.4, track_867, track_868, track_869, tr...\n",
       "2                                                [1.1]\n",
       "4                                                [1.2]\n",
       "5    [1.1, 1.2, track_16, track_18, track_40, track...\n",
       "6                                                [1.1]\n",
       "Name: track_names, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"track_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the indexes of each subject from the track list\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_index\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: {k: x[\"track_names\"].index(k) for k in x[\"individual_subj\"].split(\"_\")}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              {'1.4': 0}\n",
       "1    {'1.1': 0, '1.4': 1}\n",
       "2              {'1.1': 0}\n",
       "4              {'1.2': 0}\n",
       "5    {'1.1': 0, '1.2': 1}\n",
       "6              {'1.1': 0}\n",
       "Name: subject_to_index, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: {k: x[\"locations\"][:,:,:,v] for k, v in x[\"subject_to_index\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68495, 6, 2)\n",
      "[[[340.27038574 388.14276123]\n",
      "  [324.34329224 380.16009521]\n",
      "  [332.32067871 407.44903564]\n",
      "  [383.79647827 355.59390259]\n",
      "  [356.37075806 364.52984619]\n",
      "  [332.01358032 396.19528198]]\n",
      "\n",
      " [[339.76290894 388.28674316]\n",
      "  [324.04089355 379.49035645]\n",
      "  [331.72134399 404.118927  ]\n",
      "  [384.02911377 355.74206543]\n",
      "  [359.64349365 367.85821533]\n",
      "  [328.55419922 395.83575439]]\n",
      "\n",
      " [[336.63510132 391.50439453]\n",
      "  [324.08578491 376.36730957]\n",
      "  [328.13803101 403.8515625 ]\n",
      "  [384.125      355.57141113]\n",
      "  [359.96517944 368.1416626 ]\n",
      "  [328.0453186  395.5512085 ]]]\n"
     ]
    }
   ],
   "source": [
    "for k,v in VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"].iloc[0].items():\n",
    "    print(v.shape)\n",
    "    print(v[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"].apply(lambda x: {k: fill_missing(v) for k, v in x.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking over the tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].iloc[1], \"r\") as f:\n",
    "    dset_names = list(f.keys())\n",
    "    locations = f[\"tracks\"][:].T\n",
    "    node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "    \n",
    "print(\"===HDF5 datasets===\")\n",
    "print(dset_names)\n",
    "print()\n",
    "\n",
    "print(\"===locations data shape===\")\n",
    "print(locations.shape)\n",
    "print()\n",
    "\n",
    "print(\"===nodes===\")\n",
    "for i, name in enumerate(node_names):\n",
    "    print(f\"{i}: {name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thorax_loc = locations[:, THORAX_INDEX, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set('notebook', 'ticks', font_scale=1.2)\n",
    "mpl.rcParams['figure.figsize'] = [15,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(thorax_loc[:,0,0], 'y',label='fly-0')\n",
    "\n",
    "plt.plot(-1*thorax_loc[:,1,0], 'y')\n",
    "\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.title('Thorax locations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(thorax_loc[:,0,0],thorax_loc[:,1,0], 'y',label='fly-0')\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks([])\n",
    "\n",
    "plt.yticks([])\n",
    "plt.title('Thorax tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the coordinates of the corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_path\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].apply(lambda x: \"{}.fixed.corner.h5\".format(x.split(\"fixed\")[0].strip(\".\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_parts\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_path\"].apply(lambda x: get_node_names_from_sleap(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_parts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_coordinates\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_path\"].apply(lambda x: get_sleap_tracks_from_h5(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: {part: x[\"corner_coordinates\"][:,index,:,:] for index, part in enumerate(x[\"corner_parts\"])}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: {k: v[~np.isnan(v)] for k, v in x[\"corner_to_coordinate\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].iloc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the distances between corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the average width and height so that we can convert pixels to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"bottom_width\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_right\"][0] - x[\"box_bottom_left\"][0])\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"top_width\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_top_right\"][0] - x[\"box_top_left\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"right_height\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_right\"][1] - x[\"box_top_right\"][1])\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"left_height\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_left\"][1] - x[\"box_top_left\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"average_height\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda row: (row[\"right_height\"] + row[\"left_height\"])/2, axis=1)\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"average_width\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda row: (row[\"bottom_width\"] + row[\"top_width\"])/2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getthing the pixel to cm ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"width_ratio\"] = 29.5 / VIDEO_TO_FRAME_AND_SUBJECT_DF[\"average_width\"]\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"height_ratio\"] = 24 / VIDEO_TO_FRAME_AND_SUBJECT_DF[\"average_height\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"width_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF.iloc[0][\"corner_to_coordinate\"][\"reward_port\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"reward_port_scaled\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda row: np.array([row[\"corner_to_coordinate\"][\"reward_port\"][0] * row[\"width_ratio\"], row[\"corner_to_coordinate\"][\"reward_port\"][1] * row[\"height_ratio\"]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"reward_port_scaled\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Pixels to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"].iloc[0][\"1.4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"].iloc[0][\"1.4\"][:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_array(row):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    row[\"subject_to_tracks\"].apply(lambda x: {k: v[:, THORAX_INDEX, :] for k, v in x.items()})\n",
    "\n",
    "\n",
    "    \n",
    "    # Access the dictionary and then the numpy array inside it\n",
    "    arr = row['data_dict']['key1']\n",
    "    \n",
    "    # Modify the desired part of the array\n",
    "    arr[0] = 99\n",
    "    \n",
    "    # Return the modified dictionary\n",
    "    return row['data_dict']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_converted_x_coordinates\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: {k: v[:,:,0] for k, v in x[\"subject_to_tracks\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_converted_x_coordinates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"].apply(lambda x: {k: v[:, THORAX_INDEX, :] for k, v in x.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"].apply(lambda x: {k: v[:, THORAX_INDEX, :] for k, v in x.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_START = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_STOP = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = \"1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_velocities\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].apply(lambda x: {k: compute_velocity(v, window_size=WINDOW_SIZE) for k, v in x.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_velocities\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].apply(lambda x: {k: compute_velocity(v, window_size=WINDOW_SIZE) for k, v in x.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_velocities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_diff(node_loc, win=25, poly=3, deriv=0):\n",
    "    \"\"\"\n",
    "    node_loc is a [frames, 2] array\n",
    "    \n",
    "    win defines the window to smooth over\n",
    "    \n",
    "    poly defines the order of the polynomial\n",
    "    to fit with\n",
    "    \n",
    "    \"\"\"\n",
    "    node_loc_vel = np.zeros_like(node_loc)\n",
    "    \n",
    "    for c in range(node_loc.shape[-1]):\n",
    "        node_loc_vel[:, c] = savgol_filter(node_loc[:, c], win, poly, deriv=deriv)\n",
    "    \n",
    "    node_vel = np.linalg.norm(node_loc_vel,axis=1)\n",
    "\n",
    "    return node_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].iloc[file_index][subject_id][FRAME_START:200,0], label=\"X-axis\")\n",
    "plt.plot(savgol_filter(VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].iloc[file_index][subject_id][FRAME_START:200,0], 25, 3, deriv=0))\n",
    "\n",
    "plt.plot(-1*VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].iloc[file_index][subject_id][FRAME_START:200,1], label=\"Y-axis\")\n",
    "plt.plot(-1*savgol_filter(VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].iloc[file_index][subject_id][FRAME_START:200,1], 25, 3, deriv=0))\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Thorax locations')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].iloc[file_index][subject_id][FRAME_START:FRAME_STOP,0], label=\"X-axis\")\n",
    "\n",
    "plt.plot(-1*VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].iloc[file_index][subject_id][FRAME_START:FRAME_STOP,1], label=\"Y-axis\")\n",
    "plt.legend()\n",
    "plt.title('Thorax locations')\n",
    "\n",
    "compute_velocity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.lineplot(VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].iloc[file_index][subject_id][FRAME_START:FRAME_STOP,0], label=\"X-axis\")\n",
    "\n",
    "sns.lineplot(-1*VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].iloc[file_index][subject_id][FRAME_START:FRAME_STOP,1], label=\"Y-axis\")\n",
    "plt.legend()\n",
    "plt.title('Thorax locations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(5,50,5):\n",
    "    VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_velocities\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_locations\"].apply(lambda x: {k: compute_velocity(v, window_size=num) for k, v in x.items()})\n",
    "    plt.figure()\n",
    "    sns.lineplot(VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_thorax_velocities\"].iloc[file_index][subject_id][FRAME_START:FRAME_STOP])\n",
    "    \n",
    "    plt.title('Thorax Velocity with window size: {}'.format(num))\n",
    "    plt.savefig(\"./proc/velocity_window_size_{}.png\".format(num))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = TONE_TIMESTAMP_DF.dropna(subset=\"condition\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_trials_df[\"recording_dir\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"resampled_index\"] = all_trials_df[\"time_stamp_index\"] // 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"recording_dir\"] = all_trials_df[\"recording_dir\"].apply(lambda x: x if \"2023\" in x else \"subj\" + \"_\".join(x.split(\"_\")[-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"all_subjects\"] = all_trials_df[\"recording_dir\"].apply(lambda x: sorted([num.strip(\"_\").replace(\"_\",\".\") for num in x.replace(\"-\", \"_\").split(\"subj\")[-1].strip(\"_\").split(\"and\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"current_subject\"] = all_trials_df[\"subject_info\"].apply(lambda x: \".\".join(x.replace(\"-\",\"_\").split(\"_\")[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_outcome\"] = all_trials_df.apply(\n",
    "    lambda x: \"win\" if str(x[\"condition\"]).strip() == str(x[\"current_subject\"]) \n",
    "             else (\"lose\" if str(x[\"condition\"]) in x[\"all_subjects\"] \n",
    "                   else x[\"condition\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Coordinates of all the corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reading in all the files with the corner coordinate and the pose tracking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_corner_h5 = glob.glob(os.path.join(SLEAP_DIR, \"*/*.corner.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pose_estimation_h5 = glob.glob(os.path.join(SLEAP_DIR, \"*/*.id_corrected.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_corner_h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_pose_estimation_h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matching all the video file names to the corresponding corner and pose tracking coordinate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_to_corner = {item.split(\"/\")[-1].split(\".\")[0].strip(): item for item in all_corner_h5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_to_pose_estimation = {item.split(\"/\")[-1].split(\".\")[0].strip(): item for item in all_pose_estimation_h5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[\"corner_file\"] = tone_start_df[\"File Name\"].map(file_name_to_corner)\n",
    "tone_start_df[\"pose_estimation_file\"] = tone_start_df[\"File Name\"].map(file_name_to_pose_estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function that gets the SLEAP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleap_coordinates(filename):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        dset_names = list(f.keys())\n",
    "        locations = f[\"tracks\"][:].T\n",
    "        node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "        track_names = [n.decode() for n in f[\"track_names\"][:]]\n",
    "    return locations, node_names, track_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corner_node_names = get_sleap_coordinates(all_corner_h5[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_node_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the coordinates of each corner and the reward port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, node in enumerate(corner_node_names):\n",
    "    tone_start_df[\"{}_coordinates\".format(node)] = tone_start_df[\"corner_file\"].apply(lambda x: get_sleap_coordinates(x)[0][0,index,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_columns = [col for col in tone_start_df.columns if \"coordinates\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for index, row in tone_start_df.iterrows():\n",
    "    for corner in corner_columns:\n",
    "        plt.scatter(row[corner][0], row[corner][1], label=corner)\n",
    "    break\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the distances between corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the average width and height so that we can convert pixels to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[\"bottom_width\"] = tone_start_df.apply(lambda row: row[\"box_bottom_right_coordinates\"][0] - row[\"box_bottom_left_coordinates\"][0], axis=1)\n",
    "tone_start_df[\"top_width\"] = tone_start_df.apply(lambda row: row[\"box_top_right_coordinates\"][0] - row[\"box_top_left_coordinates\"][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[\"right_height\"] = tone_start_df.apply(lambda row: row[\"box_bottom_right_coordinates\"][1] - row[\"box_top_right_coordinates\"][1], axis=1)\n",
    "tone_start_df[\"left_height\"] = tone_start_df.apply(lambda row: row[\"box_bottom_left_coordinates\"][1] - row[\"box_top_left_coordinates\"][1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[\"average_height\"] = tone_start_df.apply(lambda row: (row[\"right_height\"] + row[\"left_height\"])/2, axis=1)\n",
    "tone_start_df[\"average_width\"] = tone_start_df.apply(lambda row: (row[\"bottom_width\"] + row[\"top_width\"])/2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getthing the pixel to cm ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[\"width_ratio\"] = 29.5 / tone_start_df[\"average_width\"]\n",
    "tone_start_df[\"height_ratio\"] = 24 / tone_start_df[\"average_height\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[\"reward_port_scaled\"] = tone_start_df.apply(lambda row: np.array([row[\"reward_port_coordinates\"][0] * row[\"width_ratio\"], row[\"reward_port_coordinates\"][1] * row[\"height_ratio\"]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tone_start_df[\"reward_port_scaled\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the coordinates of each mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function that fills missing coordinates by interpolating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def fill_missing(Y, kind=\"linear\"):\n",
    "    \"\"\"Fills missing values independently along each dimension after the first.\"\"\"\n",
    "\n",
    "    # Store initial shape.\n",
    "    initial_shape = Y.shape\n",
    "\n",
    "    # Flatten after first dim.\n",
    "    Y = Y.reshape((initial_shape[0], -1))\n",
    "\n",
    "    # Interpolate along each slice.\n",
    "    for i in range(Y.shape[-1]):\n",
    "        y = Y[:, i]\n",
    "\n",
    "        # Build interpolant.\n",
    "        x = np.flatnonzero(~np.isnan(y))\n",
    "        f = interp1d(x, y[x], kind=kind, fill_value=np.nan, bounds_error=False)\n",
    "\n",
    "        # Fill missing\n",
    "        xq = np.flatnonzero(np.isnan(y))\n",
    "        y[xq] = f(xq)\n",
    "        \n",
    "        # Fill leading or trailing NaNs with the nearest non-NaN values\n",
    "        mask = np.isnan(y)\n",
    "        y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), y[~mask])\n",
    "\n",
    "        # Save slice\n",
    "        Y[:, i] = y\n",
    "\n",
    "    # Restore to initial shape.\n",
    "    Y = Y.reshape(initial_shape)\n",
    "\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_part_node_names = get_sleap_coordinates(all_pose_estimation_h5[0])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_part_node_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Function that scales each coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_coordinates(row, coordinate_col, height_ratio_col=\"height_ratio\", width_ratio_col=\"width_ratio\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return np.dstack((row[coordinate_col][:,:,0] * row[width_ratio_col], row[coordinate_col][:,:,1] * row[height_ratio_col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(2):\n",
    "    tone_start_df[\"pose_estimation_subj_{}_original_coordinates\".format(num + 1)] = tone_start_df[\"pose_estimation_file\"].apply(lambda x: fill_missing(get_sleap_coordinates(x)[0][:,:,:,num]))\n",
    "    tone_start_df[\"pose_estimation_subj_{}_scaled_coordinates\".format(num + 1)] = tone_start_df.apply(lambda row: scale_coordinates(row, \"pose_estimation_subj_{}_original_coordinates\".format(num + 1)), axis=1)     \n",
    "    tone_start_df[\"pose_estimation_subj_{}_thorax_coordinates\".format(num + 1)] = tone_start_df[\"pose_estimation_subj_{}_scaled_coordinates\".format(num + 1)].apply(lambda x: x[:,4,:])\n",
    "    tone_start_df[\"pose_estimation_subj_{}_name\".format(num + 1)] = tone_start_df[\"pose_estimation_file\"].apply(lambda x: get_sleap_coordinates(x)[2][num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[\"pose_estimation_subj_1_thorax_coordinates\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the distance from thorax to reward port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[\"thorax_to_reward_port_distance_subj_1\"] = tone_start_df.apply(lambda row: np.linalg.norm(row[\"pose_estimation_subj_1_thorax_coordinates\"] - row[\"reward_port_scaled\"], axis=1), axis=1)\n",
    "tone_start_df[\"thorax_to_reward_port_distance_subj_2\"] = tone_start_df.apply(lambda row: np.linalg.norm(row[\"pose_estimation_subj_2_thorax_coordinates\"] - row[\"reward_port_scaled\"], axis=1), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_range = 20 * 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[\"thorax_to_reward_port_tone_slices_subj_1\"] = tone_start_df.apply(lambda row:  np.vstack([row[\"thorax_to_reward_port_distance_subj_1\"][tone_frame-frame_range:tone_frame+frame_range] for tone_frame in row[\"all_tone_frame\"] if tone_frame <= row[\"thorax_to_reward_port_distance_subj_1\"].shape[0]]), axis=1)\n",
    "tone_start_df[\"thorax_to_reward_port_tone_slices_subj_2\"] = tone_start_df.apply(lambda row:  np.vstack([row[\"thorax_to_reward_port_distance_subj_2\"][tone_frame-frame_range:tone_frame+frame_range] for tone_frame in row[\"all_tone_frame\"] if tone_frame <= row[\"thorax_to_reward_port_distance_subj_2\"].shape[0]]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in the array\n",
    "for i, row in enumerate(tone_start_df[\"thorax_to_reward_port_tone_slices_subj_1\"].iloc[4]):\n",
    "    # Plot the row data\n",
    "    plt.plot(row, label=f'Line {i+1}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging across trials based on strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tone_start_df[\"thorax_to_reward_port_tone_slices_subj_1\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[\"thorax_to_reward_port_tone_trial_average_subj_1\"] = tone_start_df[\"thorax_to_reward_port_tone_slices_subj_1\"].apply(lambda x: np.mean(x, axis=0))\n",
    "tone_start_df[\"thorax_to_reward_port_tone_trial_average_subj_2\"] = tone_start_df[\"thorax_to_reward_port_tone_slices_subj_2\"].apply(lambda x: np.mean(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tone_start_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c57_mean_distance = np.mean(tone_start_df[tone_start_df[\"Strain\"] == \"C57\"][\"thorax_to_reward_port_tone_trial_average_subj_1\"], axis=0)\n",
    "cd1_mean_distance = np.mean(tone_start_df[tone_start_df[\"Strain\"] == \"CD1\"][\"thorax_to_reward_port_tone_trial_average_subj_1\"], axis=0)\n",
    "cd1_sem_distance = np.std(tone_start_df[tone_start_df[\"Strain\"] == \"CD1\"][\"thorax_to_reward_port_tone_trial_average_subj_1\"].to_list(), axis=0) / np.sqrt(tone_start_df[tone_start_df[\"Strain\"] == \"CD1\"][\"thorax_to_reward_port_tone_trial_average_subj_1\"].iloc[0].shape[0])  \n",
    "c57_sem_distance = np.std(tone_start_df[tone_start_df[\"Strain\"] == \"C57\"][\"thorax_to_reward_port_tone_trial_average_subj_1\"].to_list(), axis=0) / np.sqrt(tone_start_df[tone_start_df[\"Strain\"] == \"C57\"][\"thorax_to_reward_port_tone_trial_average_subj_1\"].iloc[0].shape[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df[tone_start_df[\"Strain\"] == \"CD1\"][\"thorax_to_reward_port_tone_trial_average_subj_1\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(tone_start_df[tone_start_df[\"Strain\"] == \"CD1\"][\"thorax_to_reward_port_tone_trial_average_subj_1\"].shape[0])  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c57s mustard: ffaf00 ffcf66 (Leo's #400000)\n",
    "cd1s teal: 15616f 73a0a9 (Leo's #001620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add shading for the standard error\n",
    "plt.plot(cd1_mean_distance, color=\"#ffaf00\", label=\"CD1\")\n",
    "plt.fill_between(range(len(cd1_mean_distance)), cd1_mean_distance - cd1_sem_distance, cd1_mean_distance + cd1_sem_distance, color=\"#ffaf00\", alpha=0.2)\n",
    "\n",
    "# Add shading for the standard error\n",
    "plt.plot(c57_mean_distance, color=\"#15616f\", label=\"C57\")\n",
    "plt.fill_between(range(len(c57_mean_distance)), c57_mean_distance - c57_sem_distance, c57_mean_distance + c57_sem_distance, color=\"#15616f\", alpha=0.2)\n",
    "plt.ylabel(\"Distance of thorax to reward port (cm)\")\n",
    "plt.xlabel(\"Time from tone onset (seconds)\")\n",
    "\n",
    "xticks = plt.xticks()[0]  # Get current x-axis ticks\n",
    "plt.xticks(xticks, xticks // 30 - 20)  # Set new x-axis ticks\n",
    "plt.xlim(0, 1200)\n",
    "plt.ylim(0, 12)\n",
    "plt.title(\"C57 are closer to the reward port\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating Rows into the two subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_start_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting all the columns with subject 1 or subject 2 in the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_1_col = [col for col in tone_start_df.columns if \"subj_1\" in col or \"Strain\" in col or \"all_subj\" in col or \"date\" in col]\n",
    "subj_2_col = [col for col in tone_start_df.columns if \"subj_2\" in col or \"Strain\" in col or \"all_subj\" in col or \"date\" in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_1_df = tone_start_df[subj_1_col].copy()\n",
    "subj_2_df = tone_start_df[subj_2_col].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standarizing all the columns so it's just \"subj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_1_df.columns = [col.replace(\"subj_1\", \"subj\") for col in subj_1_df.columns]\n",
    "subj_2_df.columns = [col.replace(\"subj_2\", \"subj\") for col in subj_2_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Putting the dataframes for subject 1 and subject 2 together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subj_df = pd.concat([subj_1_df, subj_2_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subj_df[\"agent\"] = combined_subj_df.apply(lambda x: list(set(x[\"all_subj\"]) - set([x[\"subj\"]]))[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subj_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subj_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(combined_subj_df[\"subj\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculating the average distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c57_combined_subj_df = combined_subj_df[combined_subj_df[\"Strain\"] == \"C57\"]\n",
    "cd1_combined_subj_df = combined_subj_df[combined_subj_df[\"Strain\"] == \"CD1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c57_combined_subj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c57_mean_distance = np.mean(c57_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"], axis=0)\n",
    "cd1_mean_distance = np.mean(cd1_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cd1_std_distance = np.std(cd1_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"].to_list(), axis=0) \n",
    "c57_std_distance = np.std(c57_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"].to_list(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(cd1_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(c57_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cd1_sem_distance = cd1_std_distance / np.sqrt(len(cd1_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"]))  \n",
    "c57_sem_distance = c57_std_distance / np.sqrt(len(c57_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"])) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "cd1_sem_distance = np.std(cd1_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"].to_list(), axis=0) / np.sqrt(cd1_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"].iloc[0].shape[0])  \n",
    "c57_sem_distance = np.std(c57_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"].to_list(), axis=0) / np.sqrt(c57_combined_subj_df[\"thorax_to_reward_port_tone_trial_average_subj\"].iloc[0].shape[0])  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c57s mustard: ffaf00 ffcf66 (Leo's #400000)\n",
    "cd1s teal: 15616f 73a0a9 (Leo's #001620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add shading for the standard error\n",
    "plt.plot(cd1_mean_distance, color=\"#15616f\", label=\"CD1\")\n",
    "plt.fill_between(range(len(cd1_mean_distance)), cd1_mean_distance - cd1_sem_distance, cd1_mean_distance + cd1_sem_distance, color=\"#15616f\", alpha=0.2)\n",
    "\n",
    "# Add shading for the standard error\n",
    "plt.plot(c57_mean_distance, color=\"#ffaf00\", label=\"C57\")\n",
    "plt.fill_between(range(len(c57_mean_distance)), c57_mean_distance - c57_sem_distance, c57_mean_distance + c57_sem_distance, color=\"#ffaf00\", alpha=0.2)\n",
    "plt.ylabel(\"Distance of thorax to reward port (cm)\")\n",
    "plt.xlabel(\"Time from tone onset (seconds)\")\n",
    "\n",
    "xticks = plt.xticks()[0]  # Get current x-axis ticks\n",
    "plt.xticks(xticks, xticks // 30 - 20)  # Set new x-axis ticks\n",
    "plt.xlim(0, 1200)\n",
    "plt.ylim(0, 12)\n",
    "plt.title(\"C57 are closer to the reward port\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding the win and loss information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporating Winning and Losing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_comp_scoring_df = pd.read_csv(\"./data/scoring/pilot_3_reward_competition_all_competition_cage_1_2_3_4_5_6_date_20221003_20221004.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_comp_scoring_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Updating the date so that we can merge using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_comp_scoring_df[\"date\"] = reward_comp_scoring_df[\"rc_date\"].apply(lambda x: str(x).strip(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_comp_scoring_df[\"date\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Updating the IDs so we can merge using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_comp_scoring_df[\"all_subj\"] = reward_comp_scoring_df[\"rc_animal_ids\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_comp_scoring_df[\"all_subj\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_comp_scoring_df[\"rc_winner\"] = reward_comp_scoring_df[\"rc_winner\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_comp_scoring_df[\"rc_averaged_winner\"] = reward_comp_scoring_df[\"rc_averaged_winner\"].astype(str)\n",
    "reward_comp_scoring_df[\"rc_averaged_loser\"] = reward_comp_scoring_df[\"rc_averaged_loser\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in reward_comp_scoring_df[\"rc_winner\"]:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merging the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_subj_df[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_comp_scoring_df[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distance_and_scoring_df = combined_subj_df.merge(reward_comp_scoring_df, on=['date', 'all_subj'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df = distance_and_scoring_df.dropna(subset=[\"rc_winner\", \"subj\"])#.dropna(subset=\"subj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting all the winning and losing trials based on matching IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"subj\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"per_trial_winning_indexes\"] = distance_and_scoring_df.apply(lambda x: [i for i, trial in enumerate(x[\"rc_winner\"]) if trial == x[\"subj\"] and i < x[\"thorax_to_reward_port_tone_slices_subj\"].shape[0]], axis=1)\n",
    "distance_and_scoring_df[\"per_trial_losing_indexes\"] = distance_and_scoring_df.apply(lambda x: [i for i, trial in enumerate(x[\"rc_winner\"]) if trial == x[\"agent\"] and i < x[\"thorax_to_reward_port_tone_slices_subj\"].shape[0]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"all_subj\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"rc_winner\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"per_trial_winning_indexes\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"per_trial_losing_indexes\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Check the winner vs loser ste calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"thorax_to_reward_port_all_winning_trial_distances\"] = distance_and_scoring_df.apply(lambda x: x[\"thorax_to_reward_port_tone_slices_subj\"][x[\"per_trial_winning_indexes\"]], axis=1)\n",
    "distance_and_scoring_df[\"thorax_to_reward_port_all_losing_trial_distances\"] = distance_and_scoring_df.apply(lambda x: x[\"thorax_to_reward_port_tone_slices_subj\"][x[\"per_trial_losing_indexes\"]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"thorax_to_reward_port_all_winning_trial_distances\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"thorax_to_reward_port_all_losing_trial_distances\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"thorax_to_reward_port_all_winning_trial_distances\"].iloc[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"thorax_to_reward_port_all_losing_trial_distances\"].iloc[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Averaging across winning and losing trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"thorax_to_reward_port_tone_winning_trial_average\"] = distance_and_scoring_df[\"thorax_to_reward_port_all_winning_trial_distances\"].apply(lambda x: np.mean(x, axis=0))\n",
    "distance_and_scoring_df[\"thorax_to_reward_port_tone_losing_trial_average\"] = distance_and_scoring_df[\"thorax_to_reward_port_all_losing_trial_distances\"].apply(lambda x: np.mean(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distance_and_scoring_df[\"thorax_to_reward_port_tone_winning_trial_average\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtering out rows that have NANs in the average distance array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[~distance_and_scoring_df[\"thorax_to_reward_port_tone_winning_trial_average\"].apply(lambda x: np.isnan(x).any())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[~distance_and_scoring_df[\"thorax_to_reward_port_tone_losing_trial_average\"].apply(lambda x: np.isnan(x).any())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c57_all_distance_and_scoring_df = distance_and_scoring_df[distance_and_scoring_df[\"Strain\"] == \"C57\"]\n",
    "cd1_all_distance_and_scoring_df = distance_and_scoring_df[distance_and_scoring_df[\"Strain\"] == \"CD1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check if a NumPy array contains any NaN values\n",
    "def contains_nan(arr):\n",
    "    return np.isnan(arr).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the apply method to apply the function to each element in the 'A' column,\n",
    "# and then use the resulting Boolean Series to select the rows where 'A' does not contain a NaN\n",
    "c57_winning_distance_and_scoring_df = c57_all_distance_and_scoring_df[~c57_all_distance_and_scoring_df['thorax_to_reward_port_tone_winning_trial_average'].apply(contains_nan)]\n",
    "c57_losing_distance_and_scoring_df = c57_all_distance_and_scoring_df[~c57_all_distance_and_scoring_df['thorax_to_reward_port_tone_losing_trial_average'].apply(contains_nan)]\n",
    "cd1_winning_distance_and_scoring_df = cd1_all_distance_and_scoring_df[~cd1_all_distance_and_scoring_df['thorax_to_reward_port_tone_winning_trial_average'].apply(contains_nan)]\n",
    "cd1_losing_distance_and_scoring_df = cd1_all_distance_and_scoring_df[~cd1_all_distance_and_scoring_df['thorax_to_reward_port_tone_losing_trial_average'].apply(contains_nan)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c57_winning_mean_distance = np.mean(c57_winning_distance_and_scoring_df[\"thorax_to_reward_port_tone_winning_trial_average\"], axis=0)\n",
    "c57_winning_sem_distance = np.std(c57_winning_distance_and_scoring_df[\"thorax_to_reward_port_tone_winning_trial_average\"].to_list(), axis=0) / np.sqrt(c57_winning_distance_and_scoring_df[\"thorax_to_reward_port_tone_winning_trial_average\"].iloc[0].shape[0])  \n",
    "c57_losing_mean_distance = np.mean(c57_losing_distance_and_scoring_df[\"thorax_to_reward_port_tone_losing_trial_average\"], axis=0)\n",
    "c57_losing_sem_distance = np.std(c57_losing_distance_and_scoring_df[\"thorax_to_reward_port_tone_losing_trial_average\"].to_list(), axis=0) / np.sqrt(c57_losing_distance_and_scoring_df[\"thorax_to_reward_port_tone_losing_trial_average\"].iloc[0].shape[0])  \n",
    "\n",
    "cd1_winning_mean_distance = np.mean(cd1_winning_distance_and_scoring_df[\"thorax_to_reward_port_tone_winning_trial_average\"], axis=0)\n",
    "cd1_winning_sem_distance = np.std(cd1_winning_distance_and_scoring_df[\"thorax_to_reward_port_tone_winning_trial_average\"].to_list(), axis=0) / np.sqrt(cd1_winning_distance_and_scoring_df[\"thorax_to_reward_port_tone_winning_trial_average\"].iloc[0].shape[0])  \n",
    "cd1_losing_mean_distance = np.mean(cd1_losing_distance_and_scoring_df[\"thorax_to_reward_port_tone_losing_trial_average\"], axis=0)\n",
    "cd1_losing_sem_distance = np.std(cd1_losing_distance_and_scoring_df[\"thorax_to_reward_port_tone_losing_trial_average\"].to_list(), axis=0) / np.sqrt(cd1_losing_distance_and_scoring_df[\"thorax_to_reward_port_tone_losing_trial_average\"].iloc[0].shape[0])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colors are the website colors (Yellow #FFAF00; teal #15616F) but ive added these: light yellow: #FFDB91 (r 255 g 219 b 145) light teal: #C2DBDC  (r 194 g 219 b 220), thoughts on making all titles, axes, and numbers gray instead of black? specifically #666666 (r 96 b 96 g 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add shading for the standard error\n",
    "plt.plot(cd1_winning_mean_distance, color=\"#15616F\", label=\"CD1 Winning Trials\")\n",
    "plt.fill_between(range(len(cd1_winning_mean_distance)), cd1_winning_mean_distance - cd1_winning_sem_distance, cd1_winning_mean_distance + cd1_winning_sem_distance, color=\"#15616f\", alpha=0.2)\n",
    "\n",
    "# Add shading for the standard error\n",
    "plt.plot(cd1_losing_mean_distance, color=\"#C2DBDC\", label=\"CD1 Lost Trials\")\n",
    "plt.fill_between(range(len(cd1_losing_mean_distance)), cd1_losing_mean_distance - cd1_losing_sem_distance, cd1_losing_mean_distance + cd1_losing_sem_distance, color=\"#C2DBDC\", alpha=0.2)\n",
    "\n",
    "# Add shading for the standard error\n",
    "plt.plot(c57_losing_mean_distance, color=\"#FFDB91\", label=\"C57 Lost Trials\")\n",
    "plt.fill_between(range(len(c57_losing_mean_distance)), c57_losing_mean_distance - c57_losing_sem_distance, c57_losing_mean_distance + c57_losing_sem_distance, color=\"#FFDB91\", alpha=0.2)\n",
    "\n",
    "# Add shading for the standard error\n",
    "plt.plot(c57_winning_mean_distance, color=\"#FFAF00\", label=\"C57 Winning Trials\")\n",
    "plt.fill_between(range(len(c57_winning_mean_distance)), c57_winning_mean_distance - c57_winning_sem_distance, c57_winning_mean_distance + c57_winning_sem_distance, color=\"#ffaf00\", alpha=0.2)\n",
    "\n",
    "\n",
    "plt.ylabel(\"Distance of thorax to reward port (cm)\")\n",
    "plt.xlabel(\"Time from tone onset (seconds)\")\n",
    "\n",
    "xticks = plt.xticks()[0]  # Get current x-axis ticks\n",
    "plt.xticks(xticks, xticks // 30 - 20)  # Set new x-axis ticks\n",
    "plt.xlim(0, 1200)\n",
    "\n",
    "plt.title(\"C57 have closer competitions than CD1\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating by overall winner and loser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tie_distance_and_scoring_df = distance_and_scoring_df[~distance_and_scoring_df[\"rc_is_win_to_win_and_loss_ratio_tie\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tie_distance_and_scoring_df[\"is_winner\"] = no_tie_distance_and_scoring_df[\"subj\"] == no_tie_distance_and_scoring_df[\"rc_averaged_winner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c57_winner_distance_and_scoring_df = no_tie_distance_and_scoring_df[(no_tie_distance_and_scoring_df[\"Strain\"] == \"C57\") & (no_tie_distance_and_scoring_df[\"is_winner\"])]\n",
    "c57_loser_distance_and_scoring_df = no_tie_distance_and_scoring_df[(no_tie_distance_and_scoring_df[\"Strain\"] == \"C57\") & ~(no_tie_distance_and_scoring_df[\"is_winner\"])]\n",
    "\n",
    "cd1_winner_distance_and_scoring_df = no_tie_distance_and_scoring_df[(no_tie_distance_and_scoring_df[\"Strain\"] == \"CD1\") & (no_tie_distance_and_scoring_df[\"is_winner\"])]\n",
    "cd1_loser_distance_and_scoring_df = no_tie_distance_and_scoring_df[(no_tie_distance_and_scoring_df[\"Strain\"] == \"CD1\") & ~(no_tie_distance_and_scoring_df[\"is_winner\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c57_winner_mean_distance = np.mean(c57_winner_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"], axis=0)\n",
    "c57_winner_sem_distance = np.std(c57_winner_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"].to_list(), axis=0) / np.sqrt(c57_winner_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"].iloc[0].shape[0])  \n",
    "c57_loser_mean_distance = np.mean(c57_loser_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"], axis=0)\n",
    "c57_loser_sem_distance = np.std(c57_loser_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"].to_list(), axis=0) / np.sqrt(c57_loser_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"].iloc[0].shape[0])  \n",
    "\n",
    "cd1_winner_mean_distance = np.mean(cd1_winner_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"], axis=0)\n",
    "cd1_winner_sem_distance = np.std(cd1_winner_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"].to_list(), axis=0) / np.sqrt(cd1_winner_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"].iloc[0].shape[0])  \n",
    "cd1_loser_mean_distance = np.mean(cd1_loser_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"], axis=0)\n",
    "cd1_loser_sem_distance = np.std(cd1_loser_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"].to_list(), axis=0) / np.sqrt(cd1_loser_distance_and_scoring_df[\"thorax_to_reward_port_tone_trial_average_subj\"].iloc[0].shape[0])  \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c57s mustard: ffaf00 ffcf66 (Leo's #400000)\n",
    "cd1s teal: 15616f 73a0a9 (Leo's #001620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add shading for the standard error\n",
    "plt.plot(cd1_winner_mean_distance, color=\"#15616F\", label=\"CD1 Overall Winner\")\n",
    "plt.fill_between(range(len(cd1_winner_mean_distance)), cd1_winner_mean_distance - cd1_winner_sem_distance, cd1_winner_mean_distance + cd1_winner_sem_distance, color=\"#15616f\", alpha=0.2)\n",
    "\n",
    "# Add shading for the standard error\n",
    "plt.plot(cd1_loser_mean_distance, color=\"#C2DBDC\", label=\"CD1 Overall Loser\")\n",
    "plt.fill_between(range(len(cd1_loser_mean_distance)), cd1_loser_mean_distance - cd1_loser_sem_distance, cd1_loser_mean_distance + cd1_loser_sem_distance, color=\"#C2DBDC\", alpha=0.2)\n",
    "\n",
    "# Add shading for the standard error\n",
    "plt.plot(c57_loser_mean_distance, color=\"#FFDB91\", label=\"C57 Overall Loser\")\n",
    "plt.fill_between(range(len(c57_loser_mean_distance)), c57_loser_mean_distance - c57_loser_sem_distance, c57_loser_mean_distance + c57_loser_sem_distance, color=\"#FFDB91\", alpha=0.2)\n",
    "\n",
    "# Add shading for the standard error\n",
    "plt.plot(c57_winner_mean_distance, color=\"#FFAF00\", label=\"C57 Overall Winner\")\n",
    "plt.fill_between(range(len(c57_winner_mean_distance)), c57_winner_mean_distance - c57_winner_sem_distance, c57_winner_mean_distance + c57_winner_sem_distance, color=\"#ffaf00\", alpha=0.2)\n",
    "\n",
    "\n",
    "plt.ylabel(\"Distance of thorax to reward port (cm)\")\n",
    "plt.xlabel(\"Time from tone onset (seconds)\")\n",
    "\n",
    "xticks = plt.xticks()[0]  # Get current x-axis ticks\n",
    "plt.xticks(xticks, xticks // 30 - 20)  # Set new x-axis ticks\n",
    "plt.xlim(0, 1200)\n",
    "\n",
    "plt.title(\"C57 have closer competitions than CD1\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(distance_and_scoring_df[distance_and_scoring_df[\"strain\"] == \"C57\"][\"rc_tie_count\"], alpha=0.5, color=\"#FFAF00\", binwidth=1, label=\"C57\")\n",
    "sns.histplot(distance_and_scoring_df[distance_and_scoring_df[\"strain\"] == \"CD1\"][\"rc_tie_count\"], alpha=0.5, color=\"#15616F\", binwidth=1, label=\"CD1\")\n",
    "plt.title(\"C57 have more ties\")\n",
    "plt.xlabel(\"Number of ties\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[distance_and_scoring_df[\"strain\"] == \"C57\"][\"rc_tie_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_and_scoring_df[distance_and_scoring_df[\"strain\"] == \"CD1\"][\"rc_tie_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a4490980-3f6a-4f44-80eb-ebd789a5b21f' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
