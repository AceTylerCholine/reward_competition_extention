{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Omission LFP Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import itertools\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as sp\n",
    "from spectral_connectivity import Multitaper, Connectivity\n",
    "import spectral_connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_HALFBANDWIDTH_PRODUCT = 2\n",
    "TIME_WINDOW_DURATION = 1\n",
    "TIME_WINDOW_STEP = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_MAX = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your keywords\n",
    "KEYWORD_TOP = '_trial_'\n",
    "KEYWORD_BOTTOM = '_baseline_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPING = \"all\"\n",
    "# GROUPING = \"velocity_parsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBOX_TO_ANCHOR=(1.5, 0.9)\n",
    "LOC='upper right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_BANDS = [\"theta\", \"beta\", \"gamma\"]\n",
    "BAND_TO_FREQ = {\"theta\": {\"low_freq\": 4, \"high_freq\": 12}, \"beta\": {\"low_freq\": 13, \"high_freq\": 30}, \"gamma\": {\"low_freq\": 30, \"high_freq\": 70}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for LFP extraction\n",
    "FREQ_MIN=0.5\n",
    "FREQ_MAX=300\n",
    "NOTCH_FREQ=60\n",
    "ORIGINAL_SAMPLE_RATE = 20000\n",
    "RESAMPLE_RATE=1000\n",
    "TRIAL_DURATION=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_VARIABLE = 1\n",
    "\n",
    "TIME_HALFBANDWIDTH_PRODUCT = 2\n",
    "TIME_WINDOW_DURATION = 1\n",
    "TIME_WINDOW_STEP = 0.5\n",
    "\n",
    "\n",
    "TRIAL_TIME_STAMP_DURATION = 1000*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_TO_COLOR = {0: {\"baseline\": \"lightblue\", \"trial\": \"blue\"}, 1: {\"baseline\": \"lightgreen\", \"trial\": \"green\"}, 2: {\"baseline\": \"lightcoral\", \"trial\": \"red\"}}\n",
    "TRIAL_OR_BASELINE_TO_STYLE = {'baseline': \"--\", \"trial\": \"-\"}\n",
    "BIN_TO_VELOCITY = {0: \"0 to 2.5cm/s\", 1: \"2.5 to 5cm/s\", 2: \"5cm/s+\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LINES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_OUTCOME_TO_COLOR = {\n",
    "'lose': \"red\",\n",
    "'lose_trial': \"red\",\n",
    "'lose_baseline': \"hotpink\",\n",
    "\n",
    "'omission': \"orange\",\n",
    "'omission_trial': \"orange\",\n",
    "'omission_baseline': \"navajowhite\",\n",
    "\n",
    "'rewarded': \"green\",\n",
    "'rewarded_trial': \"green\",\n",
    "'rewarded_baseline': \"lightgreen\",\n",
    "\n",
    "'win': \"blue\",\n",
    "'win_trial': \"blue\",\n",
    "'win_baseline': \"lightblue\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_OR_BASELINE_TO_STYLE = {'baseline': \"--\", \"trial\": \"-\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF = pd.read_excel(\"../../data/channel_mapping.xlsx\")\n",
    "CHANNEL_MAPPING_DF[\"Subject\"] = CHANNEL_MAPPING_DF[\"Subject\"].astype(str)\n",
    "\n",
    "TONE_TIMESTAMP_DF = pd.read_excel(\"../../data/rce_tone_timestamp.xlsx\", index_col=0)\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_col_name(col_name, keywords, replacement=\"_\"):\n",
    "    \"\"\"\n",
    "    Standardize the column name by removing specified keywords.\n",
    "\n",
    "    Parameters:\n",
    "    col_name (str): The original column name.\n",
    "    keywords (list of str): A list of keywords to remove from the column name.\n",
    "\n",
    "    Returns:\n",
    "    str: The standardized column name.\n",
    "    \"\"\"\n",
    "    for keyword in keywords:\n",
    "        col_name = col_name.replace(keyword, replacement)\n",
    "    # Replace any double underscores possibly created and strip leading/trailing underscores\n",
    "    col_name = col_name.replace('__', '_').strip('_')\n",
    "    return col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- Ideally functions are defined here first and then data is processed using the functions\n",
    "    - function names are short and in snake case all lowercase\n",
    "    - a function name should be unique but does not have to describe the function\n",
    "    - doc strings describe functions not function names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(lst):\n",
    "    pairs = []\n",
    "    n = len(lst)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            pairs.append((lst[i], lst[j]))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict():\n",
    "    return defaultdict(dict)\n",
    "\n",
    "triple_nested_dict = defaultdict(nested_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP = pd.read_pickle(\"./proc/full_baseline_and_trial_lfp_traces.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>time_stamp_index</th>\n",
       "      <th>video_file</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>video_number</th>\n",
       "      <th>subject_info</th>\n",
       "      <th>competition_closeness</th>\n",
       "      <th>video_name</th>\n",
       "      <th>...</th>\n",
       "      <th>mPFC_baseline_lfp_trace</th>\n",
       "      <th>mPFC_trial_lfp_trace</th>\n",
       "      <th>vHPC_baseline_lfp_trace</th>\n",
       "      <th>vHPC_trial_lfp_trace</th>\n",
       "      <th>BLA_baseline_lfp_trace</th>\n",
       "      <th>BLA_trial_lfp_trace</th>\n",
       "      <th>LH_baseline_lfp_trace</th>\n",
       "      <th>LH_trial_lfp_trace</th>\n",
       "      <th>MD_baseline_lfp_trace</th>\n",
       "      <th>MD_trial_lfp_trace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6310663</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>1390826</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>1734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.8457601, 1.7363818, 1.6475118, 1.59738, 1.2...</td>\n",
       "      <td>[0.6927297, 0.96389693, 0.7884358, -0.04101689...</td>\n",
       "      <td>[-0.06969439, -0.09568214, -0.05315674, 0.1571...</td>\n",
       "      <td>[1.5864334, 1.5710771, 1.5970649, 1.2155175, 0...</td>\n",
       "      <td>[2.0367627, 2.1163385, 2.1618104, 2.2679114, 2...</td>\n",
       "      <td>[0.3164087, 0.36377528, 0.18757163, -0.5020857...</td>\n",
       "      <td>[3.1382985, 3.2319791, 3.2788196, 3.2881875, 3...</td>\n",
       "      <td>[0.8118982, 1.2209699, 0.87435186, -0.4028264,...</td>\n",
       "      <td>[1.3934726, 1.494771, 1.764077, 1.828315, 1.68...</td>\n",
       "      <td>[-0.9783956, -0.86721426, -0.7288553, -1.40582...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7910662</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>2990825</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>3728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.2191132, 1.1348007, 1.2054409, 1.0960625, 0...</td>\n",
       "      <td>[1.0732753, 0.7246318, 0.7633699, 0.3782669, -...</td>\n",
       "      <td>[0.31539667, 0.23152715, 0.29767776, 0.4217101...</td>\n",
       "      <td>[0.03543783, -0.27641505, -0.40044746, -0.6638...</td>\n",
       "      <td>[0.3107247, 0.14209972, -0.05873455, -0.331566...</td>\n",
       "      <td>[0.026525281, -0.04547191, 0.11936376, -0.4092...</td>\n",
       "      <td>[-1.180375, -1.2959143, -1.3771042, -1.458294,...</td>\n",
       "      <td>[0.9492963, 0.46840277, 0.6713773, 0.043717593...</td>\n",
       "      <td>[-0.14577106, -0.16059524, 0.027177656, 0.1680...</td>\n",
       "      <td>[1.6281886, 1.349, 1.4675934, 0.9487473, -0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9710660</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>4790823</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>5972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1.2669662, -1.2965895, -1.2532939, -0.986684...</td>\n",
       "      <td>[0.28711826, 0.84996116, 1.0960625, 0.8226166,...</td>\n",
       "      <td>[-1.2556804, -1.2580429, -1.3312811, -1.118654...</td>\n",
       "      <td>[0.060244307, 0.4748669, 0.7654571, 0.6591436,...</td>\n",
       "      <td>[-1.9912907, -1.9041362, -1.9325562, -1.542255...</td>\n",
       "      <td>[0.69344664, 1.4001559, 1.7582471, 1.4304705, ...</td>\n",
       "      <td>[-0.19985186, -0.074944444, -0.18423842, -0.13...</td>\n",
       "      <td>[-0.59643286, 0.27167362, 0.6901134, 0.4371759...</td>\n",
       "      <td>[-0.32119048, -0.52872896, -0.96851283, -0.753...</td>\n",
       "      <td>[0.096357144, 0.88450915, 1.2131118, 0.8943919...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11310658</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>6390821</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>7966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>omission</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-2.0257788, -2.0348935, -1.9323514, -1.754611...</td>\n",
       "      <td>[2.376701, 2.3015034, 1.7796774, 0.9411098, 0....</td>\n",
       "      <td>[0.16655779, 0.42879772, 0.66268736, 0.6934002...</td>\n",
       "      <td>[-1.8427671, -2.303459, -2.6802812, -3.060647,...</td>\n",
       "      <td>[-1.2637402, -1.0382752, -0.82986236, -0.74649...</td>\n",
       "      <td>[2.6771586, 2.3929594, 2.209177, 1.9761335, 1....</td>\n",
       "      <td>[-2.538743, -2.1983705, -1.8673657, -1.7143542...</td>\n",
       "      <td>[2.8447661, 2.3045416, 1.5301157, 0.96490973, ...</td>\n",
       "      <td>[-2.7647088, -2.5546997, -2.3051593, -2.055619...</td>\n",
       "      <td>[2.087738, 1.7418406, 1.1266373, 0.45954946, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12810657</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>7890820</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>9836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.5765152, 0.25749493, 0.6403192, 0.4375135,...</td>\n",
       "      <td>[-0.043295607, 0.73602533, 0.31674156, 0.07747...</td>\n",
       "      <td>[-0.31421542, 0.19727057, 0.4453354, 0.3744597...</td>\n",
       "      <td>[0.21617076, 0.8221576, 0.58236164, 0.43116024...</td>\n",
       "      <td>[-2.1352851, -2.0576038, -2.0822346, -2.140969...</td>\n",
       "      <td>[-0.18188764, 0.113679774, -0.66123736, -0.935...</td>\n",
       "      <td>[-2.1671436, -1.4832754, -1.0554676, -1.130412...</td>\n",
       "      <td>[0.5339792, 1.5113796, 0.57145137, -0.02810416...</td>\n",
       "      <td>[-2.0111465, -1.714663, -1.4255916, -1.3662949...</td>\n",
       "      <td>[0.31871977, 1.008044, 0.25942308, -0.22730403...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time                                      recording_dir  \\\n",
       "0   6310663  20221202_134600_omission_and_competition_subje...   \n",
       "1   7910662  20221202_134600_omission_and_competition_subje...   \n",
       "2   9710660  20221202_134600_omission_and_competition_subje...   \n",
       "3  11310658  20221202_134600_omission_and_competition_subje...   \n",
       "4  12810657  20221202_134600_omission_and_competition_subje...   \n",
       "\n",
       "                                      recording_file  time_stamp_index  \\\n",
       "0  20221202_134600_omission_and_competition_subje...           1390826   \n",
       "1  20221202_134600_omission_and_competition_subje...           2990825   \n",
       "2  20221202_134600_omission_and_competition_subje...           4790823   \n",
       "3  20221202_134600_omission_and_competition_subje...           6390821   \n",
       "4  20221202_134600_omission_and_competition_subje...           7890820   \n",
       "\n",
       "                                          video_file  video_frame  \\\n",
       "0  20221202_134600_omission_and_competition_subje...         1734   \n",
       "1  20221202_134600_omission_and_competition_subje...         3728   \n",
       "2  20221202_134600_omission_and_competition_subje...         5972   \n",
       "3  20221202_134600_omission_and_competition_subje...         7966   \n",
       "4  20221202_134600_omission_and_competition_subje...         9836   \n",
       "\n",
       "   video_number      subject_info competition_closeness  \\\n",
       "0           1.0  6_1_top_2_base_3              rewarded   \n",
       "1           1.0  6_1_top_2_base_3              rewarded   \n",
       "2           1.0  6_1_top_2_base_3              rewarded   \n",
       "3           1.0  6_1_top_2_base_3              omission   \n",
       "4           1.0  6_1_top_2_base_3              rewarded   \n",
       "\n",
       "                                          video_name  ...  \\\n",
       "0  20221202_134600_omission_and_competition_subje...  ...   \n",
       "1  20221202_134600_omission_and_competition_subje...  ...   \n",
       "2  20221202_134600_omission_and_competition_subje...  ...   \n",
       "3  20221202_134600_omission_and_competition_subje...  ...   \n",
       "4  20221202_134600_omission_and_competition_subje...  ...   \n",
       "\n",
       "                             mPFC_baseline_lfp_trace  \\\n",
       "0  [1.8457601, 1.7363818, 1.6475118, 1.59738, 1.2...   \n",
       "1  [1.2191132, 1.1348007, 1.2054409, 1.0960625, 0...   \n",
       "2  [-1.2669662, -1.2965895, -1.2532939, -0.986684...   \n",
       "3  [-2.0257788, -2.0348935, -1.9323514, -1.754611...   \n",
       "4  [-0.5765152, 0.25749493, 0.6403192, 0.4375135,...   \n",
       "\n",
       "                                mPFC_trial_lfp_trace  \\\n",
       "0  [0.6927297, 0.96389693, 0.7884358, -0.04101689...   \n",
       "1  [1.0732753, 0.7246318, 0.7633699, 0.3782669, -...   \n",
       "2  [0.28711826, 0.84996116, 1.0960625, 0.8226166,...   \n",
       "3  [2.376701, 2.3015034, 1.7796774, 0.9411098, 0....   \n",
       "4  [-0.043295607, 0.73602533, 0.31674156, 0.07747...   \n",
       "\n",
       "                             vHPC_baseline_lfp_trace  \\\n",
       "0  [-0.06969439, -0.09568214, -0.05315674, 0.1571...   \n",
       "1  [0.31539667, 0.23152715, 0.29767776, 0.4217101...   \n",
       "2  [-1.2556804, -1.2580429, -1.3312811, -1.118654...   \n",
       "3  [0.16655779, 0.42879772, 0.66268736, 0.6934002...   \n",
       "4  [-0.31421542, 0.19727057, 0.4453354, 0.3744597...   \n",
       "\n",
       "                                vHPC_trial_lfp_trace  \\\n",
       "0  [1.5864334, 1.5710771, 1.5970649, 1.2155175, 0...   \n",
       "1  [0.03543783, -0.27641505, -0.40044746, -0.6638...   \n",
       "2  [0.060244307, 0.4748669, 0.7654571, 0.6591436,...   \n",
       "3  [-1.8427671, -2.303459, -2.6802812, -3.060647,...   \n",
       "4  [0.21617076, 0.8221576, 0.58236164, 0.43116024...   \n",
       "\n",
       "                              BLA_baseline_lfp_trace  \\\n",
       "0  [2.0367627, 2.1163385, 2.1618104, 2.2679114, 2...   \n",
       "1  [0.3107247, 0.14209972, -0.05873455, -0.331566...   \n",
       "2  [-1.9912907, -1.9041362, -1.9325562, -1.542255...   \n",
       "3  [-1.2637402, -1.0382752, -0.82986236, -0.74649...   \n",
       "4  [-2.1352851, -2.0576038, -2.0822346, -2.140969...   \n",
       "\n",
       "                                 BLA_trial_lfp_trace  \\\n",
       "0  [0.3164087, 0.36377528, 0.18757163, -0.5020857...   \n",
       "1  [0.026525281, -0.04547191, 0.11936376, -0.4092...   \n",
       "2  [0.69344664, 1.4001559, 1.7582471, 1.4304705, ...   \n",
       "3  [2.6771586, 2.3929594, 2.209177, 1.9761335, 1....   \n",
       "4  [-0.18188764, 0.113679774, -0.66123736, -0.935...   \n",
       "\n",
       "                               LH_baseline_lfp_trace  \\\n",
       "0  [3.1382985, 3.2319791, 3.2788196, 3.2881875, 3...   \n",
       "1  [-1.180375, -1.2959143, -1.3771042, -1.458294,...   \n",
       "2  [-0.19985186, -0.074944444, -0.18423842, -0.13...   \n",
       "3  [-2.538743, -2.1983705, -1.8673657, -1.7143542...   \n",
       "4  [-2.1671436, -1.4832754, -1.0554676, -1.130412...   \n",
       "\n",
       "                                  LH_trial_lfp_trace  \\\n",
       "0  [0.8118982, 1.2209699, 0.87435186, -0.4028264,...   \n",
       "1  [0.9492963, 0.46840277, 0.6713773, 0.043717593...   \n",
       "2  [-0.59643286, 0.27167362, 0.6901134, 0.4371759...   \n",
       "3  [2.8447661, 2.3045416, 1.5301157, 0.96490973, ...   \n",
       "4  [0.5339792, 1.5113796, 0.57145137, -0.02810416...   \n",
       "\n",
       "                               MD_baseline_lfp_trace  \\\n",
       "0  [1.3934726, 1.494771, 1.764077, 1.828315, 1.68...   \n",
       "1  [-0.14577106, -0.16059524, 0.027177656, 0.1680...   \n",
       "2  [-0.32119048, -0.52872896, -0.96851283, -0.753...   \n",
       "3  [-2.7647088, -2.5546997, -2.3051593, -2.055619...   \n",
       "4  [-2.0111465, -1.714663, -1.4255916, -1.3662949...   \n",
       "\n",
       "                                  MD_trial_lfp_trace  \n",
       "0  [-0.9783956, -0.86721426, -0.7288553, -1.40582...  \n",
       "1  [1.6281886, 1.349, 1.4675934, 0.9487473, -0.21...  \n",
       "2  [0.096357144, 0.88450915, 1.2131118, 0.8943919...  \n",
       "3  [2.087738, 1.7418406, 1.1266373, 0.45954946, 0...  \n",
       "4  [0.31871977, 1.008044, 0.25942308, -0.22730403...  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MERGED_LFP_AND_SLEAP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_columns = [col for col in MERGED_LFP_AND_SLEAP.columns if \"trace\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [col for col in MERGED_LFP_AND_SLEAP.columns if col not in trace_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mPFC_baseline_lfp_trace',\n",
       " 'mPFC_trial_lfp_trace',\n",
       " 'vHPC_baseline_lfp_trace',\n",
       " 'vHPC_trial_lfp_trace',\n",
       " 'BLA_baseline_lfp_trace',\n",
       " 'BLA_trial_lfp_trace',\n",
       " 'LH_baseline_lfp_trace',\n",
       " 'LH_trial_lfp_trace',\n",
       " 'MD_baseline_lfp_trace',\n",
       " 'MD_trial_lfp_trace']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP = MERGED_LFP_AND_SLEAP.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherece Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the brain region pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_trace_columns = sorted([col for col in MERGED_LFP_AND_SLEAP.columns if \"trial_lfp_trace\" in col])\n",
    "baseline_trace_columns = sorted([col for col in MERGED_LFP_AND_SLEAP.columns if \"baseline_lfp_trace\" in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLA_trial_lfp_trace',\n",
       " 'LH_trial_lfp_trace',\n",
       " 'MD_trial_lfp_trace',\n",
       " 'mPFC_trial_lfp_trace',\n",
       " 'vHPC_trial_lfp_trace']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_trace_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_brain_region_pairs = generate_pairs(trial_trace_columns)\n",
    "trial_brain_region_pairs = sorted(trial_brain_region_pairs)\n",
    "baseline_brain_region_pairs = generate_pairs(baseline_trace_columns)\n",
    "baseline_brain_region_pairs = sorted(baseline_brain_region_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BLA_trial_lfp_trace', 'LH_trial_lfp_trace'),\n",
       " ('BLA_trial_lfp_trace', 'MD_trial_lfp_trace'),\n",
       " ('BLA_trial_lfp_trace', 'mPFC_trial_lfp_trace'),\n",
       " ('BLA_trial_lfp_trace', 'vHPC_trial_lfp_trace'),\n",
       " ('LH_trial_lfp_trace', 'MD_trial_lfp_trace'),\n",
       " ('LH_trial_lfp_trace', 'mPFC_trial_lfp_trace'),\n",
       " ('LH_trial_lfp_trace', 'vHPC_trial_lfp_trace'),\n",
       " ('MD_trial_lfp_trace', 'mPFC_trial_lfp_trace'),\n",
       " ('MD_trial_lfp_trace', 'vHPC_trial_lfp_trace'),\n",
       " ('mPFC_trial_lfp_trace', 'vHPC_trial_lfp_trace')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_brain_region_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BLA_baseline_lfp_trace', 'LH_baseline_lfp_trace'),\n",
       " ('BLA_baseline_lfp_trace', 'MD_baseline_lfp_trace'),\n",
       " ('BLA_baseline_lfp_trace', 'mPFC_baseline_lfp_trace'),\n",
       " ('BLA_baseline_lfp_trace', 'vHPC_baseline_lfp_trace'),\n",
       " ('LH_baseline_lfp_trace', 'MD_baseline_lfp_trace'),\n",
       " ('LH_baseline_lfp_trace', 'mPFC_baseline_lfp_trace'),\n",
       " ('LH_baseline_lfp_trace', 'vHPC_baseline_lfp_trace'),\n",
       " ('MD_baseline_lfp_trace', 'mPFC_baseline_lfp_trace'),\n",
       " ('MD_baseline_lfp_trace', 'vHPC_baseline_lfp_trace'),\n",
       " ('mPFC_baseline_lfp_trace', 'vHPC_baseline_lfp_trace')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_brain_region_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculating the granger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_HALFBANDWIDTH_PRODUCT = 2\n",
    "TIME_WINDOW_DURATION = 1\n",
    "TIME_WINDOW_STEP = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP = MERGED_LFP_AND_SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MERGED_LFP_AND_SLEAP[\"BLA_baseline_lfp_trace\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLA_LH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riwata/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spectral_connectivity/connectivity.py:342: DeprecationWarning: invalid escape sequence \\p\n",
      "  \"\"\"The normalized imaginary component of the cross-spectrum.\n",
      "/home/riwata/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spectral_connectivity/connectivity.py:991: DeprecationWarning: invalid escape sequence \\p\n",
      "  \"\"\"Find a range of possible delays from the coherence phase.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m MERGED_LFP_AND_SLEAP[multitaper_col] \u001b[38;5;241m=\u001b[39m MERGED_LFP_AND_SLEAP\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: Multitaper(time_series\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([x[region_1],x[region_2]])\u001b[38;5;241m.\u001b[39mT, sampling_frequency\u001b[38;5;241m=\u001b[39mRESAMPLE_RATE, time_halfbandwidth_product\u001b[38;5;241m=\u001b[39mTIME_HALFBANDWIDTH_PRODUCT, time_window_duration\u001b[38;5;241m=\u001b[39mTIME_WINDOW_DURATION, time_window_step\u001b[38;5;241m=\u001b[39mTIME_WINDOW_STEP), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m connectivity_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_trial_connectivity\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pair_base_name)\n\u001b[0;32m---> 12\u001b[0m MERGED_LFP_AND_SLEAP[connectivity_col] \u001b[38;5;241m=\u001b[39m \u001b[43mMERGED_LFP_AND_SLEAP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmultitaper_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mConnectivity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_multitaper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m MERGED_LFP_AND_SLEAP[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_trial_frequencies\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pair_base_name)] \u001b[38;5;241m=\u001b[39m MERGED_LFP_AND_SLEAP[connectivity_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mfrequencies)\n\u001b[1;32m     16\u001b[0m MERGED_LFP_AND_SLEAP[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_granger\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(region_1_trimmed, region_2_trimmed)] \u001b[38;5;241m=\u001b[39m MERGED_LFP_AND_SLEAP[connectivity_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mnanmean(x\u001b[38;5;241m.\u001b[39mpairwise_spectral_granger_prediction()[:,:,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/pandas/core/series.py:4758\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4761\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4763\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4765\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/pandas/core/apply.py:1201\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/pandas/core/apply.py:1281\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1281\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1286\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning a DataFrame from Series.apply when the supplied function \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturns a Series is deprecated and will be removed in a future \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1291\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1292\u001b[0m     )  \u001b[38;5;66;03m# GH52116\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/pandas/core/algorithms.py:1812\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1810\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1815\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1816\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m MERGED_LFP_AND_SLEAP[multitaper_col] \u001b[38;5;241m=\u001b[39m MERGED_LFP_AND_SLEAP\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: Multitaper(time_series\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([x[region_1],x[region_2]])\u001b[38;5;241m.\u001b[39mT, sampling_frequency\u001b[38;5;241m=\u001b[39mRESAMPLE_RATE, time_halfbandwidth_product\u001b[38;5;241m=\u001b[39mTIME_HALFBANDWIDTH_PRODUCT, time_window_duration\u001b[38;5;241m=\u001b[39mTIME_WINDOW_DURATION, time_window_step\u001b[38;5;241m=\u001b[39mTIME_WINDOW_STEP), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m connectivity_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_trial_connectivity\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pair_base_name)\n\u001b[0;32m---> 12\u001b[0m MERGED_LFP_AND_SLEAP[connectivity_col] \u001b[38;5;241m=\u001b[39m MERGED_LFP_AND_SLEAP[multitaper_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mConnectivity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_multitaper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     14\u001b[0m MERGED_LFP_AND_SLEAP[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_trial_frequencies\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pair_base_name)] \u001b[38;5;241m=\u001b[39m MERGED_LFP_AND_SLEAP[connectivity_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mfrequencies)\n\u001b[1;32m     16\u001b[0m MERGED_LFP_AND_SLEAP[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_granger\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(region_1_trimmed, region_2_trimmed)] \u001b[38;5;241m=\u001b[39m MERGED_LFP_AND_SLEAP[connectivity_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mnanmean(x\u001b[38;5;241m.\u001b[39mpairwise_spectral_granger_prediction()[:,:,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spectral_connectivity/connectivity.py:166\u001b[0m, in \u001b[0;36mConnectivity.from_multitaper\u001b[0;34m(cls, multitaper_instance, expectation_type, blocks, dtype)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_multitaper\u001b[39m(\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mxp\u001b[38;5;241m.\u001b[39mcomplex128,\n\u001b[1;32m    163\u001b[0m ):\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct connectivity class using a multitaper instance\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m--> 166\u001b[0m         fourier_coefficients\u001b[38;5;241m=\u001b[39m\u001b[43mmultitaper_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    167\u001b[0m         expectation_type\u001b[38;5;241m=\u001b[39mexpectation_type,\n\u001b[1;32m    168\u001b[0m         time\u001b[38;5;241m=\u001b[39mmultitaper_instance\u001b[38;5;241m.\u001b[39mtime,\n\u001b[1;32m    169\u001b[0m         frequencies\u001b[38;5;241m=\u001b[39mmultitaper_instance\u001b[38;5;241m.\u001b[39mfrequencies,\n\u001b[1;32m    170\u001b[0m         blocks\u001b[38;5;241m=\u001b[39mblocks,\n\u001b[1;32m    171\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    172\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spectral_connectivity/transforms.py:259\u001b[0m, in \u001b[0;36mMultitaper.fft\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m     time_series \u001b[38;5;241m=\u001b[39m detrend(time_series, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetrend_type)\n\u001b[1;32m    256\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _multitaper_fft(\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapers\u001b[49m, time_series, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_fft_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_frequency\n\u001b[1;32m    260\u001b[0m )\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spectral_connectivity/transforms.py:127\u001b[0m, in \u001b[0;36mMultitaper.tapers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the tapers used for the multitpaer function. Tapers are the windowing function.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03mReturns\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tapers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tapers \u001b[38;5;241m=\u001b[39m \u001b[43m_make_tapers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_time_samples_per_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_halfbandwidth_product\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_tapers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_low_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_low_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tapers\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spectral_connectivity/transforms.py:381\u001b[0m, in \u001b[0;36m_make_tapers\u001b[0;34m(n_time_samples_per_window, sampling_frequency, time_halfbandwidth_product, n_tapers, is_low_bias)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_tapers\u001b[39m(\n\u001b[1;32m    358\u001b[0m     n_time_samples_per_window,\n\u001b[1;32m    359\u001b[0m     sampling_frequency,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m     is_low_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    363\u001b[0m ):\n\u001b[1;32m    364\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the Discrete prolate spheroidal sequences (tapers) for\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    multi-taper spectral analysis.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 381\u001b[0m     tapers, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdpss_windows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_time_samples_per_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_halfbandwidth_product\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_tapers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_low_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_low_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tapers\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m xp\u001b[38;5;241m.\u001b[39msqrt(sampling_frequency)\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spectral_connectivity/transforms.py:536\u001b[0m, in \u001b[0;36mdpss_windows\u001b[0;34m(n_time_samples_per_window, time_halfbandwidth_product, n_tapers, is_low_bias, interp_from, interp_kind)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     tapers \u001b[38;5;241m=\u001b[39m _find_tapers_from_optimization(\n\u001b[1;32m    533\u001b[0m         n_time_samples_per_window, time_index, half_bandwidth, n_tapers\n\u001b[1;32m    534\u001b[0m     )\n\u001b[0;32m--> 536\u001b[0m tapers \u001b[38;5;241m=\u001b[39m \u001b[43m_fix_taper_sign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_time_samples_per_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m eigenvalues \u001b[38;5;241m=\u001b[39m _get_taper_eigenvalues(tapers, half_bandwidth, time_index)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    540\u001b[0m     _get_low_bias_tapers(tapers, eigenvalues)\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_low_bias\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (tapers, eigenvalues)\n\u001b[1;32m    543\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spectral_connectivity/transforms.py:646\u001b[0m, in \u001b[0;36m_fix_taper_sign\u001b[0;34m(tapers, n_time_samples_per_window)\u001b[0m\n\u001b[1;32m    644\u001b[0m fix_sign \u001b[38;5;241m=\u001b[39m is_not_symmetric \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    645\u001b[0m fix_sign[fix_sign \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 646\u001b[0m tapers[::\u001b[38;5;241m2\u001b[39m, :] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m fix_sign[:, xp\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# Fix sign of antisymmetric tapers.\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;66;03m# rather than test the sign of one point, test the sign of the\u001b[39;00m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;66;03m# linear slope up to the first (largest) peak\u001b[39;00m\n\u001b[1;32m    651\u001b[0m largest_peak_ind \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39margmax(\n\u001b[1;32m    652\u001b[0m     xp\u001b[38;5;241m.\u001b[39mabs(tapers[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m, : n_time_samples_per_window \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    653\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for region_1, region_2 in trial_brain_region_pairs:\n",
    "    region_1_trimmed = region_1.split(\"_\")[0]\n",
    "    region_2_trimmed = region_2.split(\"_\")[0]\n",
    "    pair_base_name = \"{}_{}\".format(region_1_trimmed, region_2_trimmed)\n",
    "    print(pair_base_name)\n",
    "    try:\n",
    "        multitaper_col = \"{}_trial_multitaper\".format(pair_base_name)\n",
    "        # MERGED_LFP_AND_SLEAP[multitaper_col] = MERGED_LFP_AND_SLEAP.apply(lambda x: Multitaper(time_series=np.array([x[region_1],x[region_2]]).T, sampling_frequency=RESAMPLE_RATE, time_halfbandwidth_product=TIME_HALFBANDWIDTH_PRODUCT), axis=1)\n",
    "        MERGED_LFP_AND_SLEAP[multitaper_col] = MERGED_LFP_AND_SLEAP.apply(lambda x: Multitaper(time_series=np.array([x[region_1],x[region_2]]).T, sampling_frequency=RESAMPLE_RATE, time_halfbandwidth_product=TIME_HALFBANDWIDTH_PRODUCT, time_window_duration=TIME_WINDOW_DURATION, time_window_step=TIME_WINDOW_STEP), axis=1)\n",
    "    \n",
    "        connectivity_col = \"{}_trial_connectivity\".format(pair_base_name)\n",
    "        MERGED_LFP_AND_SLEAP[connectivity_col] = MERGED_LFP_AND_SLEAP[multitaper_col].apply(lambda x: Connectivity.from_multitaper(x))\n",
    "        \n",
    "        MERGED_LFP_AND_SLEAP[\"{}_trial_frequencies\".format(pair_base_name)] = MERGED_LFP_AND_SLEAP[connectivity_col].apply(lambda x: x.frequencies)\n",
    "\n",
    "        MERGED_LFP_AND_SLEAP[\"{}_{}_granger\".format(region_1_trimmed, region_2_trimmed)] = MERGED_LFP_AND_SLEAP[connectivity_col].apply(lambda x: np.nanmean(x.pairwise_spectral_granger_prediction()[:,:,0,1], axis=0))\n",
    "\n",
    "        MERGED_LFP_AND_SLEAP[\"{}_{}_granger\".format(region_2_trimmed, region_1_trimmed)] = MERGED_LFP_AND_SLEAP[connectivity_col].apply(lambda x: np.nanmean(x.pairwise_spectral_granger_prediction()[:,:,1,0], axis=0))\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP[\"BLA_LH_trial_frequencies\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPINGS = \"trial_outcome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frequencies = MERGED_LFP_AND_SLEAP[\"BLA_LH_trial_frequencies\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq = 0\n",
    "high_freq = 12\n",
    "\n",
    "for region_1, region_2 in trial_brain_region_pairs:\n",
    "    region_1_trimmed = region_1.split(\"_\")[0]\n",
    "    region_2_trimmed = region_2.split(\"_\")[0]\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"granger of Z-scored LFP in {} to {}\".format(region_1_trimmed, region_2_trimmed))\n",
    "    plt.xlim(low_freq, high_freq)\n",
    "    plt.ylim(0,1)\n",
    "    \n",
    "    granger_col = \"{}_{}_granger\".format(region_1_trimmed, region_2_trimmed)\n",
    "    grouped_all_trials_df = MERGED_LFP_AND_SLEAP.groupby([GROUPINGS]).agg({granger_col: lambda x: np.vstack(x.tolist())}).reset_index()\n",
    "    # grouped_all_trials_df = grouped_all_trials_df[grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\"]\n",
    "    grouped_all_trials_df[\"mean_granger\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.nanmean(np.vstack(x), axis=0))\n",
    "    grouped_all_trials_df[\"std_granger\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.nanstd(np.vstack(x), axis=0))\n",
    "    grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.sum(~np.isnan(x), axis=0))\n",
    "    grouped_all_trials_df[\"sem_granger\"] = grouped_all_trials_df.apply(lambda x: x[\"std_granger\"] / np.sqrt(x[\"n_trials\"]), axis=1)\n",
    "    for index, row in grouped_all_trials_df.iterrows():\n",
    "        try:\n",
    "\n",
    "            ax = sns.lineplot(x=all_frequencies, y=row[\"mean_granger\"], \\\n",
    "            label=\"{}\".format(row[GROUPINGS]), color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "            linewidth=3)\n",
    "\n",
    "    \n",
    "    \n",
    "            plt.fill_between(all_frequencies, \\\n",
    "            row[\"mean_granger\"] - row[\"sem_granger\"], row[\"mean_granger\"] + row[\"sem_granger\"], alpha=0.1,\n",
    "            color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]])\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    plt.show()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"granger of Z-scored LFP in {} to {}\".format(region_2_trimmed, region_1_trimmed))\n",
    "    plt.xlim(low_freq, high_freq)\n",
    "\n",
    "    \n",
    "    granger_col = \"{}_{}_granger\".format(region_2_trimmed, region_1_trimmed)\n",
    "    grouped_all_trials_df = MERGED_LFP_AND_SLEAP.groupby([GROUPINGS]).agg({granger_col: lambda x: np.vstack(x.tolist())}).reset_index()\n",
    "    # grouped_all_trials_df = grouped_all_trials_df[grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\"]\n",
    "    grouped_all_trials_df[\"mean_granger\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.nanmean(np.vstack(x), axis=0))\n",
    "    grouped_all_trials_df[\"std_granger\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.nanstd(np.vstack(x), axis=0))\n",
    "    grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.sum(~np.isnan(x), axis=0))\n",
    "    grouped_all_trials_df[\"sem_granger\"] = grouped_all_trials_df.apply(lambda x: x[\"std_granger\"] / np.sqrt(x[\"n_trials\"]), axis=1)\n",
    "    for index, row in grouped_all_trials_df.iterrows():\n",
    "        try:\n",
    "\n",
    "            ax = sns.lineplot(x=all_frequencies, y=row[\"mean_granger\"], \\\n",
    "            label=\"{}\".format(row[GROUPINGS]), color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "            linewidth=3)\n",
    "\n",
    "    \n",
    "    \n",
    "            plt.fill_between(all_frequencies, \\\n",
    "            row[\"mean_granger\"] - row[\"sem_granger\"], row[\"mean_granger\"] + row[\"sem_granger\"], alpha=0.1,\n",
    "            color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]])\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq =30\n",
    "high_freq = 90\n",
    "for pair_base_name in all_pair_base_name:\n",
    "    print(pair_base_name)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"granger of Z-scored LFP in {}\".format(pair_base_name))\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"granger of Z-scored LFP\")\n",
    "    plt.xlim(low_freq, high_freq)\n",
    "    plt.xticks(np.arange(low_freq, high_freq+1, 5))\n",
    "    plt.yticks(np.arange(0, 1, 0.1))\n",
    "    plt.ylim(0,1)\n",
    "    plt.grid()\n",
    "\n",
    "    for trial_or_baseline in TRIAL_AND_BASELINE:\n",
    "\n",
    "        granger_col = \"{}_{}_granger_magnitude\".format(pair_base_name, trial_or_baseline)\n",
    "        grouped_all_trials_df = channel_map_and_all_trials_df.groupby([GROUPINGS]).agg({granger_col: lambda x: np.vstack(x.tolist())}).reset_index()\n",
    "        # grouped_all_trials_df = grouped_all_trials_df[grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\"]\n",
    "        grouped_all_trials_df[\"mean_granger\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.nanmean(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"std_granger\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.nanstd(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.sum(~np.isnan(x), axis=0))\n",
    "        grouped_all_trials_df[\"sem_granger\"] = grouped_all_trials_df.apply(lambda x: x[\"std_granger\"] / np.sqrt(x[\"n_trials\"]), axis=1)\n",
    "        for index, row in grouped_all_trials_df.iterrows():\n",
    "            try:\n",
    "                if trial_or_baseline == \"trial\":\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_granger\"], \\\n",
    "                label=\"{} {}\".format(row[GROUPINGS], trial_or_baseline), color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                else:\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_granger\"], \\\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                \n",
    "\n",
    "    \n",
    "                plt.fill_between(all_frequencies, \\\n",
    "                row[\"mean_granger\"] - row[\"sem_granger\"], row[\"mean_granger\"] + row[\"sem_granger\"], alpha=0.1,\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]])\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "\n",
    "    \n",
    "    # plt.savefig(\"./proc/granger/{}_{}hz_{}_granger_of_zscored_lfp.png\".format(low_freq, high_freq, pair_base_name))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP[\"BLA_trial_lfp_trace\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for region_1, region_2 in trial_brain_region_pairs:\n",
    "    pair_base_name = \"{}_{}\".format(region_1.split(\"_\")[0], region_2.split(\"_\")[0])\n",
    "    print(pair_base_name)\n",
    "    try:\n",
    "        multitaper_col = \"{}_trial_multitaper\".format(pair_base_name)\n",
    "        MERGED_LFP_AND_SLEAP[multitaper_col] = MERGED_LFP_AND_SLEAP.apply(lambda x: Multitaper(time_series=np.array([x[region_1],x[region_2]]).T, sampling_frequency=RESAMPLE_RATE, time_halfbandwidth_product=5, time_window_duration=10), axis=1)\n",
    "    \n",
    "        connectivity_col = \"{}_trial_connectivity\".format(pair_base_name)\n",
    "        MERGED_LFP_AND_SLEAP[connectivity_col] = MERGED_LFP_AND_SLEAP[multitaper_col].apply(lambda x: Connectivity.from_multitaper(x))\n",
    "        \n",
    "        MERGED_LFP_AND_SLEAP[\"{}_trial_frequencies\".format(pair_base_name)] = MERGED_LFP_AND_SLEAP[connectivity_col].apply(lambda x: x.frequencies)\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = MERGED_LFP_AND_SLEAP[\"BLA_LH_trial_connectivity\"].iloc[0].pairwise_spectral_granger_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = MERGED_LFP_AND_SLEAP[\"BLA_LH_trial_connectivity\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example[:,:100][0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example[:,:100][0][4][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example[:,:100,1,0].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example[:,:100,0,1].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example.pairwise_spectral_granger_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq =30\n",
    "high_freq = 90\n",
    "for pair_base_name in all_pair_base_name:\n",
    "    print(pair_base_name)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"granger of Z-scored LFP in {}\".format(pair_base_name))\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"granger of Z-scored LFP\")\n",
    "    plt.xlim(low_freq, high_freq)\n",
    "    plt.xticks(np.arange(low_freq, high_freq+1, 5))\n",
    "    plt.yticks(np.arange(0, 1, 0.1))\n",
    "    plt.ylim(0,1)\n",
    "    plt.grid()\n",
    "\n",
    "    for trial_or_baseline in TRIAL_AND_BASELINE:\n",
    "\n",
    "        granger_col = \"{}_{}_granger_magnitude\".format(pair_base_name, trial_or_baseline)\n",
    "        grouped_all_trials_df = channel_map_and_all_trials_df.groupby([GROUPINGS]).agg({granger_col: lambda x: np.vstack(x.tolist())}).reset_index()\n",
    "        # grouped_all_trials_df = grouped_all_trials_df[grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\"]\n",
    "        grouped_all_trials_df[\"mean_granger\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.nanmean(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"std_granger\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.nanstd(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[granger_col].apply(lambda x: np.sum(~np.isnan(x), axis=0))\n",
    "        grouped_all_trials_df[\"sem_granger\"] = grouped_all_trials_df.apply(lambda x: x[\"std_granger\"] / np.sqrt(x[\"n_trials\"]), axis=1)\n",
    "        for index, row in grouped_all_trials_df.iterrows():\n",
    "            try:\n",
    "                if trial_or_baseline == \"trial\":\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_granger\"], \\\n",
    "                label=\"{} {}\".format(row[GROUPINGS], trial_or_baseline), color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                else:\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_granger\"], \\\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                \n",
    "\n",
    "    \n",
    "                plt.fill_between(all_frequencies, \\\n",
    "                row[\"mean_granger\"] - row[\"sem_granger\"], row[\"mean_granger\"] + row[\"sem_granger\"], alpha=0.1,\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]])\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "\n",
    "    \n",
    "    # plt.savefig(\"./proc/granger/{}_{}hz_{}_granger_of_zscored_lfp.png\".format(low_freq, high_freq, pair_base_name))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating average power per band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in MERGED_LFP_AND_SLEAP.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_averaged_power_columns = [col for col in MERGED_LFP_AND_SLEAP.columns if \"trial_lfp_trace\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_averaged_power_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region_1 in chunk_averaged_power_columns:\n",
    "    for region_2 in chunk_averaged_power_columns:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([MERGED_LFP_AND_SLEAP.iloc[0][region_1], MERGED_LFP_AND_SLEAP.iloc[0][region_2]]).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region_1, region_2 in permutations(chunk_averaged_power_columns, 2):\n",
    "    pair_base_name = \"{}_{}\".format(region_1.split(\"_\")[0], region_2.split(\"_\")[0],)\n",
    "    print(pair_base_name)\n",
    "    try:\n",
    "        \n",
    "        # granger_value = grangercausalitytests(MERGED_LFP_AND_SLEAP[[region_1, region_2]], maxlag=[3])\n",
    "        MERGED_LFP_AND_SLEAP[\"{}_granger\".format(pair_base_name)] = MERGED_LFP_AND_SLEAP.apply(lambda row: get_single_granger_causality(arr1=row[region_1], arr2=row[region_2]), axis=1)\n",
    "        print()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region_1, region_2 in permutations(chunk_averaged_power_columns, 2):\n",
    "    pair_base_name = \"{}_{}\".format(region_1.strip(\"trace\").strip(\"_\"), region_2.strip(\"trace\").strip(\"_\"))\n",
    "    print(pair_base_name)\n",
    "    try:\n",
    "        \n",
    "        # granger_value = grangercausalitytests(MERGED_LFP_AND_SLEAP[[region_1, region_2]], maxlag=[3])\n",
    "        MERGED_LFP_AND_SLEAP[\"{}_granger\".format(pair_base_name)] = MERGED_LFP_AND_SLEAP.apply(lambda row: grangercausalitytests(np.array([row[region_1], row[region_2]]).T, maxlag=1), axis=1)\n",
    "        print()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power correlation between brain regions calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combining the trial/baseline and outcome label for coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP[\"outcome_and_trial_or_baseline\"] = MERGED_LFP_AND_SLEAP.apply(lambda x: \"_\".join([x[\"trial_outcome\"], x[\"trial_or_baseline\"]]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_columns = [col for col in MERGED_LFP_AND_SLEAP.columns if \"trace\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_region_pairs = generate_pairs(trace_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_region_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grangercausalitytests(df[['column1', 'column2']], maxlag=[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP[region_1].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for region_1, region_2 in brain_region_pairs:\n",
    "    pair_base_name = \"{}_{}\".format(region_1.strip(\"trace\").strip(\"_\"), region_2.strip(\"trace\").strip(\"_\"))\n",
    "    print(pair_base_name)\n",
    "    try:\n",
    "        \n",
    "        # granger_value = grangercausalitytests(MERGED_LFP_AND_SLEAP[[region_1, region_2]], maxlag=[3])\n",
    "        MERGED_LFP_AND_SLEAP[\"{}_granger\".format(pair_base_name)] = MERGED_LFP_AND_SLEAP.apply(lambda row: grangercausalitytests(np.array([row[region_1], row[region_2]]).T, maxlag=[3]), axis=1)\n",
    "        print()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "granger_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtering out the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_to_power_correlation = defaultdict(dict)\n",
    "for band in ALL_BANDS:\n",
    "    # Getting all the pairs of brain regions\n",
    "    band_averaged_columns = [col for col in MERGED_LFP_AND_SLEAP.columns if \"averaged_{}\".format(band) in col]\n",
    "    band_to_power_correlation[band][\"brain_region_pairs\"] = generate_pairs(band_averaged_columns)\n",
    "    print(band_to_power_correlation[band][\"brain_region_pairs\"])\n",
    "\n",
    "    # Removing rows that are outliers\n",
    "    filtered_df = MERGED_LFP_AND_SLEAP.copy()\n",
    "    \n",
    "    for col in band_averaged_columns:\n",
    "        # filtered_df = filtered_df[filtered_df[col] <= 3]\n",
    "        # Assuming data is a 1D numpy array\n",
    "        Q1 = np.percentile(filtered_df[col], 25)\n",
    "        Q3 = np.percentile(filtered_df[col], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        band_to_power_correlation[band][\"outlier_removed_df\"] = filtered_df[(filtered_df[col] >= Q1 - 1.5 * IQR) & (filtered_df[col] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "\n",
    "    \n",
    "    # Getting the mean and standard deviation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_to_power_correlation = defaultdict(dict)\n",
    "for band in ALL_BANDS:\n",
    "    # Getting all the pairs of brain regions\n",
    "    band_averaged_columns = [col for col in MERGED_LFP_AND_SLEAP.columns if \"averaged_{}\".format(band) in col]\n",
    "    band_to_power_correlation[band][\"brain_region_pairs\"] = generate_pairs(band_averaged_columns)\n",
    "    print(band_to_power_correlation[band][\"brain_region_pairs\"])\n",
    "\n",
    "    # Removing rows that are outliers\n",
    "    filtered_df = MERGED_LFP_AND_SLEAP.copy()\n",
    "    \n",
    "    for col in band_averaged_columns:\n",
    "        # filtered_df = filtered_df[filtered_df[col] <= 3]\n",
    "        # Assuming data is a 1D numpy array\n",
    "        Q1 = np.percentile(filtered_df[col], 25)\n",
    "        Q3 = np.percentile(filtered_df[col], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        filtered_df = filtered_df[(filtered_df[col] >= Q1 - 1.5 * IQR) & (filtered_df[col] <= Q3 + 1.5 * IQR)]\n",
    "    band_to_power_correlation[band][\"outlier_removed_df\"] = filtered_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "band_to_power_correlation = defaultdict(dict)\n",
    "for band in ALL_BANDS:\n",
    "    # Getting all the pairs of brain regions\n",
    "    band_averaged_columns = [col for col in MERGED_LFP_AND_SLEAP.columns if \"averaged_{}\".format(band) in col]\n",
    "    band_to_power_correlation[band][\"brain_region_pairs\"] = generate_pairs(band_averaged_columns)\n",
    "    print(band_to_power_correlation[band][\"brain_region_pairs\"])\n",
    "    \n",
    "    # code to filter based on std\n",
    "    filtered_df = MERGED_LFP_AND_SLEAP.copy()\n",
    "    for col in band_averaged_columns:\n",
    "        # Assuming data is a 1D numpy array\n",
    "        threshold = 1\n",
    "        mean = np.median(filtered_df[col])\n",
    "        std = np.std(filtered_df[col])\n",
    "        filtered_df = filtered_df[np.abs(filtered_df[col] - mean) < threshold * std]\n",
    "    band_to_power_correlation[band][\"outlier_removed_df\"] = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_to_power_correlation[band][\"outlier_removed_df\"].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# code to filter based on std\n",
    "filtered_df = MERGED_LFP_AND_SLEAP.copy()\n",
    "for col in averaged_col:\n",
    "    # Assuming data is a 1D numpy array\n",
    "    threshold = 3.5\n",
    "    mean = np.mean(filtered_df[col])\n",
    "    std = np.std(filtered_df[col])\n",
    "    filtered_df = filtered_df[np.abs(filtered_df[col] - mean) < threshold * std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plotting all of the conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for band in ALL_BANDS:\n",
    "    for region_1, region_2 in band_to_power_correlation[band][\"brain_region_pairs\"]:\n",
    "        region_1_basename = region_1.split(\"_\")[0]\n",
    "        region_2_basename = region_2.split(\"_\")[0]\n",
    "        x = band_to_power_correlation[band][\"outlier_removed_df\"][region_1]\n",
    "        y = band_to_power_correlation[band][\"outlier_removed_df\"][region_2]\n",
    "        \n",
    "        # Perform linear regression to get the slope, intercept and r-value (correlation coefficient)\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "        \n",
    "        # Create a line of best fit using the slope and intercept\n",
    "        line = slope * x + intercept\n",
    "        \n",
    "        # Create scatter plot\n",
    "        sns.scatterplot(x=x, y=y, data=band_to_power_correlation[band][\"outlier_removed_df\"], hue='outcome_and_trial_or_baseline', palette=BASELINE_OUTCOME_TO_COLOR)\n",
    "        \n",
    "        # Plot line of best fit\n",
    "        plt.plot(x, line, color='red')\n",
    "        \n",
    "        # Add R² value to the plot\n",
    "        plt.text(0.1, 0.9, f'R = {r_value:.2f}', transform=plt.gca().transAxes)\n",
    "        \n",
    "        # Add labels and legend\n",
    "        plt.title(\"Power correlation of Z-scored {} band LFP: {} and {}\".format(band, region_2_basename, region_1_basename))\n",
    "        plt.xlabel('{} {} power of Z-scored LFP'.format(band, region_1_basename))\n",
    "        plt.ylabel('{} {} power of Z-scored LFP'.format(band, region_2_basename))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"./proc/power_correlation/zscored/{}/all_condition_{}_{}_power_correlation_of_zscored_{}_lfp.png\".format(band, region_1_basename, region_2_basename, band))\n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP[\"trial_outcome\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_LFP_AND_SLEAP[\"trial_or_baseline\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for band in ALL_BANDS:\n",
    "    for region_1, region_2 in band_to_power_correlation[band][\"brain_region_pairs\"]:\n",
    "        region_1_basename = region_1.split(\"_\")[0]\n",
    "        region_2_basename = region_2.split(\"_\")[0]\n",
    "        x = band_to_power_correlation[band][\"outlier_removed_df\"][region_1]\n",
    "        y = band_to_power_correlation[band][\"outlier_removed_df\"][region_2]\n",
    "        \n",
    "        # Perform linear regression to get the slope, intercept and r-value (correlation coefficient)\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "        \n",
    "        # Create a line of best fit using the slope and intercept\n",
    "        line = slope * x + intercept\n",
    "        \n",
    "        # Create scatter plot\n",
    "        sns.scatterplot(x=x, y=y, data=band_to_power_correlation[band][\"outlier_removed_df\"], hue='outcome_and_trial_or_baseline', palette=BASELINE_OUTCOME_TO_COLOR)\n",
    "        \n",
    "        # Plot line of best fit\n",
    "        plt.plot(x, line, color='red')\n",
    "        \n",
    "        # Add R² value to the plot\n",
    "        plt.text(0.1, 0.9, f'R = {r_value:.2f}', transform=plt.gca().transAxes)\n",
    "        \n",
    "        # Add labels and legend\n",
    "        plt.title(\"Power correlation of Z-scored {} band LFP: {} and {}\".format(band, region_2_basename, region_1_basename))\n",
    "        plt.xlabel('{} {} power of Z-scored LFP'.format(band, region_1_basename))\n",
    "        plt.ylabel('{} {} power of Z-scored LFP'.format(band, region_2_basename))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        # plt.savefig(\"./proc/power_correlation/zscored/all_condition_{}_{}_power_correlation_of_zscored_theta_lfp.png\".format(region_1_basename, region_2_basename))\n",
    "        # Display the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for band in ALL_BANDS:\n",
    "    band_df = band_to_power_correlation[band][\"outlier_removed_df\"]\n",
    "    band_to_power_correlation[band][\"region_pair_to_outcome_to_r2\"] = defaultdict(nested_dict)\n",
    "    for outcome in band_df[\"trial_outcome\"].unique():\n",
    "        outcome_df = band_df[band_df[\"trial_outcome\"] == outcome]\n",
    "        for region_1, region_2 in brain_region_pairs:\n",
    "            region_1_basename = region_1.split(\"_\")[0]\n",
    "            region_2_basename = region_2.split(\"_\")[0]\n",
    "            \n",
    "            x = outcome_df[region_1]\n",
    "            y = outcome_df[region_2]\n",
    "            \n",
    "            # Perform linear regression to get the slope, intercept and r-value (correlation coefficient)\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "            # Square the r value to get the r squared value\n",
    "            r2_value = r_value**2\n",
    "            band_to_power_correlation[band][\"region_pair_to_outcome_to_r2\"][\"{}_{}\".format(region_1.split(\"_\")[0], region_2.split(\"_\")[0])][outcome][\"r\"] = r_value\n",
    "            band_to_power_correlation[band][\"region_pair_to_outcome_to_r2\"][\"{}_{}\".format(region_1.split(\"_\")[0], region_2.split(\"_\")[0])][outcome][\"std\"] = std_err\n",
    "            \n",
    "            # Create a line of best fit using the slope and intercept\n",
    "            line = slope * x + intercept\n",
    "            \n",
    "            # Create scatter plot\n",
    "            sns.scatterplot(x=x, y=y, data=outcome_df, hue='outcome_and_trial_or_baseline', palette=BASELINE_OUTCOME_TO_COLOR, style='outcome_and_trial_or_baseline', markers=['^', 'o'])\n",
    "            \n",
    "            # Plot line of best fit\n",
    "            plt.plot(x, line, color='red')\n",
    "            \n",
    "            # Add R² value to the plot\n",
    "            plt.text(0.1, 0.9, f'R = {r_value:.2f}', transform=plt.gca().transAxes)\n",
    "            \n",
    "            # Add labels and legend\n",
    "            plt.title(\"Power Correlation of Z-scored {} LFP: {} and {}\".format(band, region_2_basename, region_1_basename))\n",
    "            plt.xlabel('{} {} Power of Z-scored LFP'.format(region_1_basename, band))\n",
    "            plt.ylabel('{} {} Power of Z-scored LFP'.format(region_2_basename, band))\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"./proc/power_correlation/zscored/{}/{}_{}_{}_power_correlation_of_zscored_{}_lfp.png\".format(band, outcome, region_1_basename, region_2_basename, band))\n",
    "            # Display the plot\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in ALL_BANDS:\n",
    "    # Convert the nested dictionary to a DataFrame\n",
    "    data = []\n",
    "    for group_name, group_data in band_to_power_correlation[band]['region_pair_to_outcome_to_r2'].items():\n",
    "        for bar_name, bar_dict in group_data.items():\n",
    "            data.append({\"Group\": group_name, \"Bar\": bar_name, \"r\": bar_dict[\"r\"], \"std\": bar_dict[\"std\"]})\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create the bar plot using seaborn\n",
    "    # sns.catplot(\n",
    "    #     data=df, \n",
    "    #     x='Group', \n",
    "    #     y='r2', \n",
    "    #     hue='Bar', \n",
    "    #     kind='bar', \n",
    "    #     height=4, \n",
    "    #     aspect=2,\n",
    "    #     legend=False,\n",
    "    #     # yerr=df['std'].values,  # This line adds the SEM bars\n",
    "    #     # capsize=0.1  # This line adds caps on the error bars\n",
    "    # )\n",
    "    \n",
    "    # Create barplot\n",
    "    ax = sns.barplot(x='Group', y='r', hue='Bar', data=df, ci=None)\n",
    "    \n",
    "    # Adding error bars\n",
    "    groups = df['Group'].unique()\n",
    "    bars_per_group = df['Bar'].nunique()\n",
    "    bar_width = 0.8 / bars_per_group\n",
    "    x_positions = []\n",
    "    \n",
    "    for i, group in enumerate(groups):\n",
    "        num_bars = df[df['Group'] == group].shape[0]\n",
    "        group_positions = np.linspace(i - bar_width*(num_bars-1)/2, i + bar_width*(num_bars-1)/2, num_bars)\n",
    "        x_positions.extend(group_positions)\n",
    "    \n",
    "    for i, (r2, sem) in enumerate(zip(df['r'], df['std'])):\n",
    "        plt.errorbar(x_positions[i], r2, yerr=sem, fmt='none', color='black', capsize=5)\n",
    "    \n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Brain region pairs\")\n",
    "    plt.ylabel(\"Power correlation r\")\n",
    "    plt.legend(title=\"Trial Conditions\")\n",
    "    plt.title(\"{} Power correlations\".format(band))\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.savefig(\"./proc/power_correlation/zscored/all_zscored_{}_lfp_power_correlation.png\".format(band))\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert the nested dictionary to a DataFrame\n",
    "data = []\n",
    "for group_name, group_data in region_pair_to_outcome_to_r2.items():\n",
    "    for bar_name, bar_dict in group_data.items():\n",
    "        data.append({\"Group\": group_name, \"Bar\": bar_name, \"r\": bar_dict[\"r\"], \"std\": bar_dict[\"std\"]})\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create the bar plot using seaborn\n",
    "# sns.catplot(\n",
    "#     data=df, \n",
    "#     x='Group', \n",
    "#     y='r2', \n",
    "#     hue='Bar', \n",
    "#     kind='bar', \n",
    "#     height=4, \n",
    "#     aspect=2,\n",
    "#     legend=False,\n",
    "#     # yerr=df['std'].values,  # This line adds the SEM bars\n",
    "#     # capsize=0.1  # This line adds caps on the error bars\n",
    "# )\n",
    "\n",
    "# Create barplot\n",
    "ax = sns.barplot(x='Group', y='r', hue='Bar', data=df, ci=None)\n",
    "\n",
    "# Adding error bars\n",
    "groups = df['Group'].unique()\n",
    "bars_per_group = df['Bar'].nunique()\n",
    "bar_width = 0.8 / bars_per_group\n",
    "x_positions = []\n",
    "\n",
    "for i, group in enumerate(groups):\n",
    "    num_bars = df[df['Group'] == group].shape[0]\n",
    "    group_positions = np.linspace(i - bar_width*(num_bars-1)/2, i + bar_width*(num_bars-1)/2, num_bars)\n",
    "    x_positions.extend(group_positions)\n",
    "\n",
    "for i, (r2, sem) in enumerate(zip(df['r'], df['std'])):\n",
    "    plt.errorbar(x_positions[i], r2, yerr=sem, fmt='none', color='black', capsize=5)\n",
    "\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Brain region pairs\")\n",
    "plt.ylabel(\"Power correlation r\")\n",
    "plt.legend(title=\"Trial Conditions\")\n",
    "plt.title(\"Power correlations\")\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(\"./proc/power_correlation/zscored/all_zscored_lfp_power_correlation.png\")\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statannot\n",
    "statannot.add_stat_annotation(\n",
    "    ax,\n",
    "    data=df,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=hue,\n",
    "    box_pairs=[\n",
    "        ((\"Biscoe\", \"Male\"), (\"Torgersen\", \"Female\")),\n",
    "        ((\"Dream\", \"Male\"), (\"Dream\", \"Female\")),\n",
    "    ],\n",
    "    test=\"t-test_ind\",\n",
    "    text_format=\"star\",\n",
    "    loc=\"outside\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "groups = ['Group1', 'Group2', 'Group3']\n",
    "values = [1.2, 2.3, 1.8]\n",
    "\n",
    "# Dictionary holding the results of your statistical comparisons\n",
    "# Keys are tuples indicating the groups being compared; values are the corresponding p-values\n",
    "stats_dict = {('Group1', 'Group2'): 0.04, ('Group1', 'Group3'): 0.01, ('Group2', 'Group3'): 0.01}\n",
    "\n",
    "# Thresholds for significance levels\n",
    "alpha = 0.05  # usually 0.05\n",
    "alpha_strong = 0.01  # example value\n",
    "\n",
    "# Create bar plot\n",
    "fig, ax = plt.subplots()\n",
    "bars = plt.bar(groups, values, color=['blue', 'green', 'red'])\n",
    "\n",
    "# Get the y-axis limits\n",
    "bottom, top = ax.get_ylim()\n",
    "y_range = top - bottom\n",
    "\n",
    "# Retrieve x-coordinates of the bars\n",
    "x_coords = [bar.get_x() + bar.get_width() / 2.0 for bar in bars]  # get_x() retrieves the left coordinate, we adjust by half the width to get the center\n",
    "group_to_x_coord = {group: x_coord for group, x_coord in zip(groups, x_coords)}\n",
    "\n",
    "\n",
    "# Significance bars\n",
    "for i, (key, value) in enumerate(stats_dict.items()):\n",
    "    # Significance level\n",
    "    p = value\n",
    "    if p < 0.001:\n",
    "        sig_symbol = '***'\n",
    "    elif p < 0.01:\n",
    "        sig_symbol = '**'\n",
    "    elif p < 0.05:\n",
    "        sig_symbol = '*'\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Columns corresponding to the datasets of interest\n",
    "    x1 = key[0]\n",
    "    x2 = key[1]\n",
    "    # What level is this bar among the bars above the plot?\n",
    "    level = len(stats_dict) - i\n",
    "    # Plot the bar\n",
    "    bar_height = (y_range * 0.15 * level) + top\n",
    "    bar_tips = bar_height - (y_range * 0.02)\n",
    "    plt.plot(\n",
    "        [x1, x1, x2, x2],\n",
    "        [bar_tips, bar_height, bar_height, bar_tips], lw=1, c='k'\n",
    "    )\n",
    "    \n",
    "    text_height = bar_height + (y_range * 0.01)\n",
    "    plt.text((group_to_x_coord[x1] + group_to_x_coord[x2]) * 0.5, text_height, sig_symbol, ha='center', va='bottom', c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "groups = ['Group1', 'Group2', 'Group3']\n",
    "values = [1.2, 2.3, 1.8]\n",
    "\n",
    "# Dictionary holding the results of your statistical comparisons\n",
    "# Keys are tuples indicating the groups being compared; values are the corresponding p-values\n",
    "stats_dict = {('Group1', 'Group2'): 0.04, ('Group1', 'Group3'): 0.01, ('Group2', 'Group3'): 0.01}\n",
    "\n",
    "# Thresholds for significance levels\n",
    "alpha = 0.05  # usually 0.05\n",
    "alpha_strong = 0.01  # example value\n",
    "\n",
    "# Create bar plot\n",
    "fig, ax = plt.subplots()\n",
    "bars = plt.bar(groups, values, color=['blue', 'green', 'red'])\n",
    "\n",
    "# Function to draw significance bars\n",
    "def draw_significance_bar(ax, x1, x2, y, height, text, offset):\n",
    "    ax.plot([x1, x1, x2, x2], [y + offset, y + height + offset, y + height + offset, y + offset], lw=1.5, c='black')\n",
    "    ax.text((x1 + x2) * .5, y + height + offset, text, ha='center', va='bottom', color='black')\n",
    "\n",
    "# Height of the small vertical ticks and offset for multiple comparisons\n",
    "tick_height = 0.1\n",
    "offset_step = 0.1  # How much to offset each additional line\n",
    "\n",
    "# Track the current offset\n",
    "current_offsets = {group: 0 for group in groups}\n",
    "\n",
    "# Check each comparison\n",
    "for comparison, p_value in stats_dict.items():\n",
    "    # Determine the index of the groups\n",
    "    index_1 = groups.index(comparison[0])\n",
    "    index_2 = groups.index(comparison[1])\n",
    "\n",
    "    # Set the positions of bars on X axis\n",
    "    x1, x2 = bars[index_1].xy[0] + 0.4, bars[index_2].xy[0] + 0.4  # we use 0.4 to center the line on the bar\n",
    "    max_height = max([bar.get_height() for bar in bars])\n",
    "    y = values[index_1] if values[index_1] > values[index_2] else values[index_2]  # get the maximum value among the two groups\n",
    "    \n",
    "    # Choose the symbol to display depending on the p-value\n",
    "    if p_value < alpha_strong:\n",
    "        text = '**'  # or '***' for an even smaller p-value\n",
    "    elif p_value < alpha:\n",
    "        text = '*'\n",
    "    else:\n",
    "        continue  # Don't draw a bar if not significant\n",
    "\n",
    "    # Determine the offset for this line\n",
    "    offset = max(current_offsets[comparison[0]], current_offsets[comparison[1]])\n",
    "    \n",
    "    # Draw the significance bar\n",
    "    draw_significance_bar(ax, x1, x2, y, tick_height, text, offset)\n",
    "\n",
    "    # Update the current offset for these groups\n",
    "    current_offsets[comparison[0]] = current_offsets[comparison[1]] = offset + offset_step\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
