{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Notebook 1: Extract Z-scored LFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF = pd.read_excel(\"../../data/channel_mapping.xlsx\")\n",
    "TONE_TIMESTAMP_DF = pd.read_excel(\"../../data/rce_tone_timestamp.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPHYS_SAMPLING_RATE = 20000\n",
    "LFP_SAMPLING_RATE = 1000\n",
    "TRIAL_DURATION = 10\n",
    "FRAME_RATE = 22\n",
    "ECU_STREAM_ID = \"ECU\"\n",
    "TRODES_STREAM_ID = \"trodes\"\n",
    "LFP_FREQ_MIN = 0.5\n",
    "LFP_FREQ_MAX = 300\n",
    "ELECTRIC_NOISE_FREQ = 60\n",
    "RECORDING_EXTENTION = \"*.rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SESSION_DIR = list(set(['/scratch/back_up/reward_competition_extention/data/omission/2023_06_17/20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2.rec',\n",
    "'/scratch/back_up/reward_competition_extention/data/omission/2023_06_18/20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1.rec',\n",
    "'/scratch/back_up/reward_competition_extention/data/omission/2023_06_19/20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4.rec',\n",
    "'/scratch/back_up/reward_competition_extention/data/omission/2023_06_20/20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1.rec',\n",
    "'/scratch/back_up/reward_competition_extention/data/omission/2023_06_21/20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2.rec'\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SESSION_DIR = glob.glob(\"/scratch/back_up/reward_competition_extention/data/omission/*/*.rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/back_up/reward_competition_extention/data/omission/2023_12_14/20221214_125409_om_and_comp_6_1_and_6_3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_12_02/20221202_134600_omission_and_competition_subject_6_1_and_6_2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_12_15/20221215_145401_comp_amd_om_6_1_and_6_3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_17/20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_17/20230617_115641_standard_comp_to_omission_D1_subj_2-2_and_2-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_21/20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_20/20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_18/20230618_100646_standard_comp_to_omission_D2_subj_2-4_and_2-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_18/20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_12_03/20221203_154800_omission_and_competition_subject_6_4_and_6_1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_19/20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_19/20230619_115334_standard_comp_to_omission_D3_subj_2-2_and_2-1.rec']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_SESSION_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sorted_index(group, value_column='Value', index_column='SortedIndex'):\n",
    "    \"\"\" \n",
    "    Computes the index of each row's value within its sorted group.\n",
    "\n",
    "    Parameters:\n",
    "    - group (pd.DataFrame): A group of data.\n",
    "    - value_column (str): Name of the column containing the values to be sorted.\n",
    "    - index_column (str): Name of the new column that will contain the indices.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The group with an additional column containing the indices.\n",
    "    \"\"\"\n",
    "    sorted_values = sorted(list(set(group[value_column].tolist())))\n",
    "    group[index_column] = group[value_column].apply(lambda x: sorted_values.index(x))\n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping all rows that have not been labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = TONE_TIMESTAMP_DF.dropna(subset=\"condition\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20221202_134600_omission_and_competition_subject_6_1_and_6_2',\n",
       " '20221203_154800_omission_and_competition_subject_6_4_and_6_1',\n",
       " '20221214_125409_om_and_comp_6_1_and_6_3',\n",
       " '20221215_145401_comp_amd_om_6_1_and_6_3',\n",
       " '20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3',\n",
       " '20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2',\n",
       " '20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1',\n",
       " '20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4',\n",
       " '20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1',\n",
       " '20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(all_trials_df[\"recording_dir\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making the video frame number usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"video_frame\"] = all_trials_df[\"video_frame\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the name of the video so that we can sync it up with the ephys recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"video_name\"]  = all_trials_df[\"video_file\"].apply(lambda x: x.strip(\".videoTimeStamps.cameraHWSync\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting all subject IDs for a given recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using different id extractions for different file formats\n",
    "all_trials_df[\"all_subjects\"] = all_trials_df[\"recording_dir\"].apply(lambda x: x if \"2023\" in x else \"subj\" + \"_\".join(x.split(\"_\")[-5:]))\n",
    "all_trials_df[\"all_subjects\"] = all_trials_df[\"all_subjects\"].apply(lambda x: tuple(sorted([num.strip(\"_\").replace(\"_\",\".\") for num in x.replace(\"-\", \"_\").split(\"subj\")[-1].strip(\"_\").split(\"and\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('6.1', '6.2'), ('6.1', '6.4'), ('6.1', '6.3'), ('1.3', '1.4'),\n",
       "       ('1.1', '1.2'), ('1.1', '1.4'), ('1.2', '1.4')], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df[\"all_subjects\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"current_subject\"] = all_trials_df[\"subject_info\"].apply(lambda x: \".\".join(x.replace(\"-\",\"_\").split(\"_\")[:2])).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6.1', '1.3', '1.4', '1.1', '1.2'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df[\"current_subject\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the trial label to win or lose based on who won the trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_outcome\"] = all_trials_df.apply(\n",
    "    lambda x: \"win\" if str(x[\"condition\"]).strip() == str(x[\"current_subject\"]) \n",
    "             else (\"lose\" if str(x[\"condition\"]) in x[\"all_subjects\"] \n",
    "                   else x[\"condition\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rewarded', 'omission', 'win', 'lose'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df[\"trial_outcome\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the competition closeness as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_closeness_map = {k: \"non_comp\" if \"only\" in str(k).lower() else \"comp\" if type(k) is str else np.nan for k in all_trials_df[\"competition_closeness\"].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: nan,\n",
       " 'Subj 1 Only': 'non_comp',\n",
       " 'Subj 2 blocking Subj 1': 'comp',\n",
       " 'Subj 1 then Subj 2': 'comp',\n",
       " 'Subj 1 blocking Subj 2': 'comp',\n",
       " 'Subj 2 Only': 'non_comp',\n",
       " 'Subj 2 then Subj 1': 'comp',\n",
       " 'Close Call': 'comp'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition_closeness_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"competition_closeness\"] = all_trials_df[\"competition_closeness\"].map(competition_closeness_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"competition_closeness\"] = all_trials_df.apply(lambda x: \"_\".join([str(x[\"trial_outcome\"]), str(x[\"competition_closeness\"])]).strip(\"nan\").strip(\"_\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rewarded', 'omission', 'win_non_comp', 'win_comp',\n",
       "       'lose_non_comp', 'lose_comp'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df[\"competition_closeness\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the LFP index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"lfp_index\"] = (all_trials_df[\"time_stamp_index\"] // (EPHYS_SAMPLING_RATE/LFP_SAMPLING_RATE)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"time\"] = all_trials_df[\"time\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"time_stamp_index\"] = all_trials_df[\"time_stamp_index\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df.drop(columns=[\"state\", \"din\", \"condition\", \"Unnamed: 13\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>time_stamp_index</th>\n",
       "      <th>video_file</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>video_number</th>\n",
       "      <th>subject_info</th>\n",
       "      <th>competition_closeness</th>\n",
       "      <th>video_name</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>trial_outcome</th>\n",
       "      <th>lfp_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6310663</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>1390826</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>1734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>69541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7910662</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>2990825</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>3728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>149541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9710660</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>4790823</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>5972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>239541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11310658</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>6390821</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>7966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>omission</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>omission</td>\n",
       "      <td>319541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12810657</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>7890820</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>9836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>394541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time                                      recording_dir  \\\n",
       "0   6310663  20221202_134600_omission_and_competition_subje...   \n",
       "1   7910662  20221202_134600_omission_and_competition_subje...   \n",
       "2   9710660  20221202_134600_omission_and_competition_subje...   \n",
       "3  11310658  20221202_134600_omission_and_competition_subje...   \n",
       "4  12810657  20221202_134600_omission_and_competition_subje...   \n",
       "\n",
       "                                      recording_file  time_stamp_index  \\\n",
       "0  20221202_134600_omission_and_competition_subje...           1390826   \n",
       "1  20221202_134600_omission_and_competition_subje...           2990825   \n",
       "2  20221202_134600_omission_and_competition_subje...           4790823   \n",
       "3  20221202_134600_omission_and_competition_subje...           6390821   \n",
       "4  20221202_134600_omission_and_competition_subje...           7890820   \n",
       "\n",
       "                                          video_file  video_frame  \\\n",
       "0  20221202_134600_omission_and_competition_subje...         1734   \n",
       "1  20221202_134600_omission_and_competition_subje...         3728   \n",
       "2  20221202_134600_omission_and_competition_subje...         5972   \n",
       "3  20221202_134600_omission_and_competition_subje...         7966   \n",
       "4  20221202_134600_omission_and_competition_subje...         9836   \n",
       "\n",
       "   video_number      subject_info competition_closeness  \\\n",
       "0           1.0  6_1_top_2_base_3              rewarded   \n",
       "1           1.0  6_1_top_2_base_3              rewarded   \n",
       "2           1.0  6_1_top_2_base_3              rewarded   \n",
       "3           1.0  6_1_top_2_base_3              omission   \n",
       "4           1.0  6_1_top_2_base_3              rewarded   \n",
       "\n",
       "                                          video_name all_subjects  \\\n",
       "0  20221202_134600_omission_and_competition_subje...   (6.1, 6.2)   \n",
       "1  20221202_134600_omission_and_competition_subje...   (6.1, 6.2)   \n",
       "2  20221202_134600_omission_and_competition_subje...   (6.1, 6.2)   \n",
       "3  20221202_134600_omission_and_competition_subje...   (6.1, 6.2)   \n",
       "4  20221202_134600_omission_and_competition_subje...   (6.1, 6.2)   \n",
       "\n",
       "  current_subject trial_outcome  lfp_index  \n",
       "0             6.1      rewarded      69541  \n",
       "1             6.1      rewarded     149541  \n",
       "2             6.1      rewarded     239541  \n",
       "3             6.1      omission     319541  \n",
       "4             6.1      rewarded     394541  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making columns of the different timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"baseline_lfp_timestamp_range\"] = all_trials_df[\"lfp_index\"].apply(lambda x: (x - TRIAL_DURATION * LFP_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_lfp_timestamp_range\"] = all_trials_df[\"lfp_index\"].apply(lambda x: (x, x + TRIAL_DURATION * LFP_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"baseline_ephys_timestamp_range\"] = all_trials_df[\"time_stamp_index\"].apply(lambda x: (x - TRIAL_DURATION * EPHYS_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_ephys_timestamp_range\"] = all_trials_df[\"time_stamp_index\"].apply(lambda x: (x, x + TRIAL_DURATION * EPHYS_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"baseline_videoframe_range\"] = all_trials_df[\"video_frame\"].apply(lambda x: (x - TRIAL_DURATION * FRAME_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_videoframe_range\"] = all_trials_df[\"video_frame\"].apply(lambda x: (x, x + TRIAL_DURATION * FRAME_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20221214_125409_om_and_comp_6_1_top_1_base_2_vs_6_3\n",
      "An exception occurred: stream_id trodes is not in ['ECU']\n",
      "20221202_134600_omission_and_competition_subject_6_1_top_2_base_3_merged\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     current_recording \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mnotch_filter(current_recording, freq\u001b[38;5;241m=\u001b[39mELECTRIC_NOISE_FREQ)\n\u001b[1;32m     16\u001b[0m     current_recording \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mresample(current_recording, resample_rate\u001b[38;5;241m=\u001b[39mLFP_SAMPLING_RATE)\n\u001b[0;32m---> 17\u001b[0m     current_recording \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_recording\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     recording_name_to_all_ch_lfp[recording_basename] \u001b[38;5;241m=\u001b[39m current_recording\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# handle the exception\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/core/core_tools.py:26\u001b[0m, in \u001b[0;36mdefine_function_from_class.<locals>.reader_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@copy_signature\u001b[39m(source_class)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreader_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msource_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/preprocessing/normalize_scale.py:223\u001b[0m, in \u001b[0;36mZScoreRecording.__init__\u001b[0;34m(self, recording, mode, dtype, **random_chunk_kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, recording, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian+mad\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m              dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrandom_chunk_kwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian+mad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean+std\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 223\u001b[0m     random_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_random_data_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrandom_chunk_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian+mad\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    226\u001b[0m         medians \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(random_data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/core/recording_tools.py:46\u001b[0m, in \u001b[0;36mget_random_data_chunks\u001b[0;34m(recording, return_scaled, num_chunks_per_segment, chunk_size, concatenated, seed, margin_frames)\u001b[0m\n\u001b[1;32m     44\u001b[0m     random_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState(seed\u001b[38;5;241m=\u001b[39mseed)\u001b[38;5;241m.\u001b[39mrandint(margin_frames, length \u001b[38;5;241m-\u001b[39m chunk_size \u001b[38;5;241m-\u001b[39m margin_frames, size\u001b[38;5;241m=\u001b[39mnum_chunks_per_segment)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m start_frame \u001b[38;5;129;01min\u001b[39;00m random_starts:\n\u001b[0;32m---> 46\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m \u001b[43mrecording\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43msegment_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegment_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mreturn_scaled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m         chunk_list\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concatenated:\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/core/baserecording.py:160\u001b[0m, in \u001b[0;36mBaseRecording.get_traces\u001b[0;34m(self, segment_index, start_frame, end_frame, channel_ids, order, return_scaled, cast_unsigned)\u001b[0m\n\u001b[1;32m    158\u001b[0m channel_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mids_to_indices(channel_ids, prefer_slice\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    159\u001b[0m rs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recording_segments[segment_index]\n\u001b[0;32m--> 160\u001b[0m traces \u001b[38;5;241m=\u001b[39m \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/preprocessing/resample.py:117\u001b[0m, in \u001b[0;36mResampleRecordingSegment.get_traces\u001b[0;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# get parent traces with margin        \u001b[39;00m\n\u001b[1;32m    113\u001b[0m parent_start_frame, parent_end_frame \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mint\u001b[39m((frame \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_frequency) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_rate)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m [start_frame, end_frame]\n\u001b[1;32m    116\u001b[0m ]\n\u001b[0;32m--> 117\u001b[0m parent_traces, left_margin, right_margin \u001b[38;5;241m=\u001b[39m \u001b[43mget_chunk_with_margin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_segment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_start_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_end_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_on_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_zeros\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# get left and right margins for the resampled case\u001b[39;00m\n\u001b[1;32m    123\u001b[0m left_margin_rs, right_margin_rs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mint\u001b[39m((margin \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_rate) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_frequency)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m margin \u001b[38;5;129;01min\u001b[39;00m [left_margin, right_margin]\n\u001b[1;32m    126\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/core/recording_tools.py:147\u001b[0m, in \u001b[0;36mget_chunk_with_margin\u001b[0;34m(rec_segment, start_frame, end_frame, channel_indices, margin, add_zeros, window_on_margin, dtype)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         right_margin \u001b[38;5;241m=\u001b[39m margin\n\u001b[0;32m--> 147\u001b[0m     traces_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mrec_segment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mright_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# add_zeros=True\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m start_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/preprocessing/filter.py:112\u001b[0m, in \u001b[0;36mFilterRecordingSegment.get_traces\u001b[0;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_traces\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_frame, end_frame, channel_indices):\n\u001b[0;32m--> 112\u001b[0m     traces_chunk, left_margin, right_margin \u001b[38;5;241m=\u001b[39m \u001b[43mget_chunk_with_margin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent_recording_segment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmargin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     traces_dtype \u001b[38;5;241m=\u001b[39m traces_chunk\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# if uint --> force int\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/core/recording_tools.py:147\u001b[0m, in \u001b[0;36mget_chunk_with_margin\u001b[0;34m(rec_segment, start_frame, end_frame, channel_indices, margin, add_zeros, window_on_margin, dtype)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         right_margin \u001b[38;5;241m=\u001b[39m margin\n\u001b[0;32m--> 147\u001b[0m     traces_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mrec_segment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mright_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# add_zeros=True\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m start_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/preprocessing/filter.py:112\u001b[0m, in \u001b[0;36mFilterRecordingSegment.get_traces\u001b[0;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_traces\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_frame, end_frame, channel_indices):\n\u001b[0;32m--> 112\u001b[0m     traces_chunk, left_margin, right_margin \u001b[38;5;241m=\u001b[39m \u001b[43mget_chunk_with_margin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent_recording_segment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmargin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     traces_dtype \u001b[38;5;241m=\u001b[39m traces_chunk\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# if uint --> force int\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/core/recording_tools.py:147\u001b[0m, in \u001b[0;36mget_chunk_with_margin\u001b[0;34m(rec_segment, start_frame, end_frame, channel_indices, margin, add_zeros, window_on_margin, dtype)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         right_margin \u001b[38;5;241m=\u001b[39m margin\n\u001b[0;32m--> 147\u001b[0m     traces_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mrec_segment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mleft_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mright_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# add_zeros=True\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m start_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/spikeinterface/extractors/neoextractors/neobaseextractor.py:179\u001b[0m, in \u001b[0;36mNeoRecordingSegment.get_traces\u001b[0;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_traces\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    175\u001b[0m                start_frame: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    176\u001b[0m                end_frame: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    177\u001b[0m                channel_indices: Union[List, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    178\u001b[0m                ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 179\u001b[0m     raw_traces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneo_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_analogsignal_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseg_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegment_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_frame\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannel_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m raw_traces\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/neo/rawio/baserawio.py:574\u001b[0m, in \u001b[0;36mBaseRawIO.get_analogsignal_chunk\u001b[0;34m(self, block_index, seg_index, i_start, i_stop, stream_index, channel_indexes, channel_names, channel_ids, prefer_slice)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39mdiff(channel_indexes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    572\u001b[0m         channel_indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(channel_indexes[\u001b[38;5;241m0\u001b[39m], channel_indexes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 574\u001b[0m raw_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_analogsignal_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblock_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m raw_chunk\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/neo/rawio/spikegadgetsrawio.py:261\u001b[0m, in \u001b[0;36mSpikeGadgetsRawIO._get_analogsignal_chunk\u001b[0;34m(self, block_index, seg_index, i_start, i_stop, stream_index, channel_indexes)\u001b[0m\n\u001b[1;32m    258\u001b[0m         stream_mask \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m chan_mask\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# this copies the data from the memmap into memory\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m raw_unit8_mask \u001b[38;5;241m=\u001b[39m \u001b[43mraw_unit8\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    262\u001b[0m shape \u001b[38;5;241m=\u001b[39m raw_unit8_mask\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    263\u001b[0m shape \u001b[38;5;241m=\u001b[39m (shape[\u001b[38;5;241m0\u001b[39m], shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/numpy/core/memmap.py:334\u001b[0m, in \u001b[0;36mmemmap.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 334\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(res) \u001b[38;5;129;01mis\u001b[39;00m memmap \u001b[38;5;129;01mand\u001b[39;00m res\u001b[38;5;241m.\u001b[39m_mmap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mndarray)\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_97_1/lib/python3.9/site-packages/numpy/core/memmap.py:288\u001b[0m, in \u001b[0;36mmemmap.__array_finalize__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_finalize__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_mmap\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmay_share_memory(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mmap \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_mmap\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recording_name_to_all_ch_lfp = {}\n",
    "# Going through all the recording sessions \n",
    "for session_dir in ALL_SESSION_DIR:\n",
    "    # Going through all the recordings in each session\n",
    "    for recording_path in glob.glob(os.path.join(session_dir, RECORDING_EXTENTION)):\n",
    "        try:\n",
    "            recording_basename = os.path.splitext(os.path.basename(recording_path))[0]\n",
    "            # checking to see if the recording has an ECU component\n",
    "            # if it doesn't, then the next one be extracted\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=ECU_STREAM_ID)\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=TRODES_STREAM_ID)\n",
    "            print(recording_basename)\n",
    "            # Preprocessing the LFP\n",
    "            current_recording = sp.bandpass_filter(current_recording, freq_min=LFP_FREQ_MIN, freq_max=LFP_FREQ_MAX)\n",
    "            current_recording = sp.notch_filter(current_recording, freq=ELECTRIC_NOISE_FREQ)\n",
    "            current_recording = sp.resample(current_recording, resample_rate=LFP_SAMPLING_RATE)\n",
    "            current_recording = sp.zscore(current_recording)\n",
    "            recording_name_to_all_ch_lfp[recording_basename] = current_recording\n",
    "        except Exception as error:\n",
    "            # handle the exception\n",
    "            print(\"An exception occurred:\", error) # An exception occurred: division by zero\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtering for all trials that we got the LFP for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df[all_trials_df[\"recording_file\"].isin(recording_name_to_all_ch_lfp.keys())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_trials_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding trial numbers based on timestamp ordering for each recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df.groupby('recording_file').apply(lambda g: compute_sorted_index(g, value_column='time', index_column='trial_number')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_number\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the LFP trace information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding all the brain region to ch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF[\"Subject\"] = CHANNEL_MAPPING_DF[\"Subject\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = all_trials_df.merge(CHANNEL_MAPPING_DF, left_on=\"current_subject\", right_on=\"Subject\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.drop(columns=[col for col in channel_map_and_all_trials_df.columns if \"eib\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.drop(columns=[\"Subject\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.to_csv(\"./proc/trial_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.to_pickle(\"./proc/trial_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linking up all LFP calculations with all the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"all_ch_lfp\"] = channel_map_and_all_trials_df[\"recording_file\"].map(recording_name_to_all_ch_lfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a new row for each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_region_col = [col for col in CHANNEL_MAPPING_DF if \"spike_interface\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [col for col in channel_map_and_all_trials_df.columns if col not in brain_region_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_region_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in brain_region_col:\n",
    "    channel_map_and_all_trials_df[col] = channel_map_and_all_trials_df[col].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in brain_region_col:\n",
    "    print(col)\n",
    "    channel_map_and_all_trials_df[\"{}_baseline_lfp_trace\".format(col.strip(\"spike_interface\").strip(\"_\"))] = channel_map_and_all_trials_df.apply(lambda row: row[\"all_ch_lfp\"].get_traces(channel_ids=[row[col]], start_frame=row[\"baseline_lfp_timestamp_range\"][0], end_frame=row[\"baseline_lfp_timestamp_range\"][1]).T[0], axis=1)\n",
    "\n",
    "    channel_map_and_all_trials_df[\"{}_trial_lfp_trace\".format(col.strip(\"spike_interface\").strip(\"_\"))] = channel_map_and_all_trials_df.apply(lambda row: row[\"all_ch_lfp\"].get_traces(channel_ids=[row[col]], start_frame=row[\"trial_lfp_timestamp_range\"][0], end_frame=row[\"trial_lfp_timestamp_range\"][1]).T[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.to_pickle(\"./proc/full_baseline_and_trial_lfp_traces.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.head()"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
