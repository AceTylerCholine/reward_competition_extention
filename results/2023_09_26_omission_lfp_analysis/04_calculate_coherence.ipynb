{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Title of notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as sp\n",
    "from spectral_connectivity import Multitaper, Connectivity\n",
    "import spectral_connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF = pd.read_excel(\"../../data/channel_mapping.xlsx\")\n",
    "TONE_TIMESTAMP_DF = pd.read_excel(\"../../data/rce_tone_timestamp.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = pd.read_pickle(\"./proc/full_baseline_and_trial_lfp_traces.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_HALFBANDWIDTH_PRODUCT = 2\n",
    "TIME_WINDOW_DURATION = 1\n",
    "TIME_WINDOW_STEP = 0.5\n",
    "RESAMPLE_RATE=1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_OR_BASELINE_TO_STYLE = {'baseline': \"--\", \"trial\": \"-\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_OUTCOME_TO_COLOR = {'lose': \"red\",\n",
    " 'omission': \"orange\",\n",
    " 'rewarded': \"green\",\n",
    " 'win': \"blue\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(lst):\n",
    "    pairs = []\n",
    "    n = len(lst)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            pairs.append((lst[i], lst[j]))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>time_stamp_index</th>\n",
       "      <th>video_file</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>video_number</th>\n",
       "      <th>subject_info</th>\n",
       "      <th>competition_closeness</th>\n",
       "      <th>video_name</th>\n",
       "      <th>...</th>\n",
       "      <th>mPFC_baseline_lfp_trace</th>\n",
       "      <th>mPFC_trial_lfp_trace</th>\n",
       "      <th>vHPC_baseline_lfp_trace</th>\n",
       "      <th>vHPC_trial_lfp_trace</th>\n",
       "      <th>BLA_baseline_lfp_trace</th>\n",
       "      <th>BLA_trial_lfp_trace</th>\n",
       "      <th>LH_baseline_lfp_trace</th>\n",
       "      <th>LH_trial_lfp_trace</th>\n",
       "      <th>MD_baseline_lfp_trace</th>\n",
       "      <th>MD_trial_lfp_trace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6310663</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>1390826</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>1734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.8457601, 1.7363818, 1.6475118, 1.59738, 1.2...</td>\n",
       "      <td>[0.6927297, 0.96389693, 0.7884358, -0.04101689...</td>\n",
       "      <td>[-0.06969439, -0.09568214, -0.05315674, 0.1571...</td>\n",
       "      <td>[1.5864334, 1.5710771, 1.5970649, 1.2155175, 0...</td>\n",
       "      <td>[2.0367627, 2.1163385, 2.1618104, 2.2679114, 2...</td>\n",
       "      <td>[0.3164087, 0.36377528, 0.18757163, -0.5020857...</td>\n",
       "      <td>[3.1382985, 3.2319791, 3.2788196, 3.2881875, 3...</td>\n",
       "      <td>[0.8118982, 1.2209699, 0.87435186, -0.4028264,...</td>\n",
       "      <td>[1.3934726, 1.494771, 1.764077, 1.828315, 1.68...</td>\n",
       "      <td>[-0.9783956, -0.86721426, -0.7288553, -1.40582...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7910662</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>2990825</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>3728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.2191132, 1.1348007, 1.2054409, 1.0960625, 0...</td>\n",
       "      <td>[1.0732753, 0.7246318, 0.7633699, 0.3782669, -...</td>\n",
       "      <td>[0.31539667, 0.23152715, 0.29767776, 0.4217101...</td>\n",
       "      <td>[0.03543783, -0.27641505, -0.40044746, -0.6638...</td>\n",
       "      <td>[0.3107247, 0.14209972, -0.05873455, -0.331566...</td>\n",
       "      <td>[0.026525281, -0.04547191, 0.11936376, -0.4092...</td>\n",
       "      <td>[-1.180375, -1.2959143, -1.3771042, -1.458294,...</td>\n",
       "      <td>[0.9492963, 0.46840277, 0.6713773, 0.043717593...</td>\n",
       "      <td>[-0.14577106, -0.16059524, 0.027177656, 0.1680...</td>\n",
       "      <td>[1.6281886, 1.349, 1.4675934, 0.9487473, -0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9710660</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>4790823</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>5972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-1.2669662, -1.2965895, -1.2532939, -0.986684...</td>\n",
       "      <td>[0.28711826, 0.84996116, 1.0960625, 0.8226166,...</td>\n",
       "      <td>[-1.2556804, -1.2580429, -1.3312811, -1.118654...</td>\n",
       "      <td>[0.060244307, 0.4748669, 0.7654571, 0.6591436,...</td>\n",
       "      <td>[-1.9912907, -1.9041362, -1.9325562, -1.542255...</td>\n",
       "      <td>[0.69344664, 1.4001559, 1.7582471, 1.4304705, ...</td>\n",
       "      <td>[-0.19985186, -0.074944444, -0.18423842, -0.13...</td>\n",
       "      <td>[-0.59643286, 0.27167362, 0.6901134, 0.4371759...</td>\n",
       "      <td>[-0.32119048, -0.52872896, -0.96851283, -0.753...</td>\n",
       "      <td>[0.096357144, 0.88450915, 1.2131118, 0.8943919...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11310658</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>6390821</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>7966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>omission</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-2.0257788, -2.0348935, -1.9323514, -1.754611...</td>\n",
       "      <td>[2.376701, 2.3015034, 1.7796774, 0.9411098, 0....</td>\n",
       "      <td>[0.16655779, 0.42879772, 0.66268736, 0.6934002...</td>\n",
       "      <td>[-1.8427671, -2.303459, -2.6802812, -3.060647,...</td>\n",
       "      <td>[-1.2637402, -1.0382752, -0.82986236, -0.74649...</td>\n",
       "      <td>[2.6771586, 2.3929594, 2.209177, 1.9761335, 1....</td>\n",
       "      <td>[-2.538743, -2.1983705, -1.8673657, -1.7143542...</td>\n",
       "      <td>[2.8447661, 2.3045416, 1.5301157, 0.96490973, ...</td>\n",
       "      <td>[-2.7647088, -2.5546997, -2.3051593, -2.055619...</td>\n",
       "      <td>[2.087738, 1.7418406, 1.1266373, 0.45954946, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12810657</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>7890820</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>9836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.5765152, 0.25749493, 0.6403192, 0.4375135,...</td>\n",
       "      <td>[-0.043295607, 0.73602533, 0.31674156, 0.07747...</td>\n",
       "      <td>[-0.31421542, 0.19727057, 0.4453354, 0.3744597...</td>\n",
       "      <td>[0.21617076, 0.8221576, 0.58236164, 0.43116024...</td>\n",
       "      <td>[-2.1352851, -2.0576038, -2.0822346, -2.140969...</td>\n",
       "      <td>[-0.18188764, 0.113679774, -0.66123736, -0.935...</td>\n",
       "      <td>[-2.1671436, -1.4832754, -1.0554676, -1.130412...</td>\n",
       "      <td>[0.5339792, 1.5113796, 0.57145137, -0.02810416...</td>\n",
       "      <td>[-2.0111465, -1.714663, -1.4255916, -1.3662949...</td>\n",
       "      <td>[0.31871977, 1.008044, 0.25942308, -0.22730403...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time                                      recording_dir  \\\n",
       "0   6310663  20221202_134600_omission_and_competition_subje...   \n",
       "1   7910662  20221202_134600_omission_and_competition_subje...   \n",
       "2   9710660  20221202_134600_omission_and_competition_subje...   \n",
       "3  11310658  20221202_134600_omission_and_competition_subje...   \n",
       "4  12810657  20221202_134600_omission_and_competition_subje...   \n",
       "\n",
       "                                      recording_file  time_stamp_index  \\\n",
       "0  20221202_134600_omission_and_competition_subje...           1390826   \n",
       "1  20221202_134600_omission_and_competition_subje...           2990825   \n",
       "2  20221202_134600_omission_and_competition_subje...           4790823   \n",
       "3  20221202_134600_omission_and_competition_subje...           6390821   \n",
       "4  20221202_134600_omission_and_competition_subje...           7890820   \n",
       "\n",
       "                                          video_file  video_frame  \\\n",
       "0  20221202_134600_omission_and_competition_subje...         1734   \n",
       "1  20221202_134600_omission_and_competition_subje...         3728   \n",
       "2  20221202_134600_omission_and_competition_subje...         5972   \n",
       "3  20221202_134600_omission_and_competition_subje...         7966   \n",
       "4  20221202_134600_omission_and_competition_subje...         9836   \n",
       "\n",
       "   video_number      subject_info competition_closeness  \\\n",
       "0           1.0  6_1_top_2_base_3              rewarded   \n",
       "1           1.0  6_1_top_2_base_3              rewarded   \n",
       "2           1.0  6_1_top_2_base_3              rewarded   \n",
       "3           1.0  6_1_top_2_base_3              omission   \n",
       "4           1.0  6_1_top_2_base_3              rewarded   \n",
       "\n",
       "                                          video_name  ...  \\\n",
       "0  20221202_134600_omission_and_competition_subje...  ...   \n",
       "1  20221202_134600_omission_and_competition_subje...  ...   \n",
       "2  20221202_134600_omission_and_competition_subje...  ...   \n",
       "3  20221202_134600_omission_and_competition_subje...  ...   \n",
       "4  20221202_134600_omission_and_competition_subje...  ...   \n",
       "\n",
       "                             mPFC_baseline_lfp_trace  \\\n",
       "0  [1.8457601, 1.7363818, 1.6475118, 1.59738, 1.2...   \n",
       "1  [1.2191132, 1.1348007, 1.2054409, 1.0960625, 0...   \n",
       "2  [-1.2669662, -1.2965895, -1.2532939, -0.986684...   \n",
       "3  [-2.0257788, -2.0348935, -1.9323514, -1.754611...   \n",
       "4  [-0.5765152, 0.25749493, 0.6403192, 0.4375135,...   \n",
       "\n",
       "                                mPFC_trial_lfp_trace  \\\n",
       "0  [0.6927297, 0.96389693, 0.7884358, -0.04101689...   \n",
       "1  [1.0732753, 0.7246318, 0.7633699, 0.3782669, -...   \n",
       "2  [0.28711826, 0.84996116, 1.0960625, 0.8226166,...   \n",
       "3  [2.376701, 2.3015034, 1.7796774, 0.9411098, 0....   \n",
       "4  [-0.043295607, 0.73602533, 0.31674156, 0.07747...   \n",
       "\n",
       "                             vHPC_baseline_lfp_trace  \\\n",
       "0  [-0.06969439, -0.09568214, -0.05315674, 0.1571...   \n",
       "1  [0.31539667, 0.23152715, 0.29767776, 0.4217101...   \n",
       "2  [-1.2556804, -1.2580429, -1.3312811, -1.118654...   \n",
       "3  [0.16655779, 0.42879772, 0.66268736, 0.6934002...   \n",
       "4  [-0.31421542, 0.19727057, 0.4453354, 0.3744597...   \n",
       "\n",
       "                                vHPC_trial_lfp_trace  \\\n",
       "0  [1.5864334, 1.5710771, 1.5970649, 1.2155175, 0...   \n",
       "1  [0.03543783, -0.27641505, -0.40044746, -0.6638...   \n",
       "2  [0.060244307, 0.4748669, 0.7654571, 0.6591436,...   \n",
       "3  [-1.8427671, -2.303459, -2.6802812, -3.060647,...   \n",
       "4  [0.21617076, 0.8221576, 0.58236164, 0.43116024...   \n",
       "\n",
       "                              BLA_baseline_lfp_trace  \\\n",
       "0  [2.0367627, 2.1163385, 2.1618104, 2.2679114, 2...   \n",
       "1  [0.3107247, 0.14209972, -0.05873455, -0.331566...   \n",
       "2  [-1.9912907, -1.9041362, -1.9325562, -1.542255...   \n",
       "3  [-1.2637402, -1.0382752, -0.82986236, -0.74649...   \n",
       "4  [-2.1352851, -2.0576038, -2.0822346, -2.140969...   \n",
       "\n",
       "                                 BLA_trial_lfp_trace  \\\n",
       "0  [0.3164087, 0.36377528, 0.18757163, -0.5020857...   \n",
       "1  [0.026525281, -0.04547191, 0.11936376, -0.4092...   \n",
       "2  [0.69344664, 1.4001559, 1.7582471, 1.4304705, ...   \n",
       "3  [2.6771586, 2.3929594, 2.209177, 1.9761335, 1....   \n",
       "4  [-0.18188764, 0.113679774, -0.66123736, -0.935...   \n",
       "\n",
       "                               LH_baseline_lfp_trace  \\\n",
       "0  [3.1382985, 3.2319791, 3.2788196, 3.2881875, 3...   \n",
       "1  [-1.180375, -1.2959143, -1.3771042, -1.458294,...   \n",
       "2  [-0.19985186, -0.074944444, -0.18423842, -0.13...   \n",
       "3  [-2.538743, -2.1983705, -1.8673657, -1.7143542...   \n",
       "4  [-2.1671436, -1.4832754, -1.0554676, -1.130412...   \n",
       "\n",
       "                                  LH_trial_lfp_trace  \\\n",
       "0  [0.8118982, 1.2209699, 0.87435186, -0.4028264,...   \n",
       "1  [0.9492963, 0.46840277, 0.6713773, 0.043717593...   \n",
       "2  [-0.59643286, 0.27167362, 0.6901134, 0.4371759...   \n",
       "3  [2.8447661, 2.3045416, 1.5301157, 0.96490973, ...   \n",
       "4  [0.5339792, 1.5113796, 0.57145137, -0.02810416...   \n",
       "\n",
       "                               MD_baseline_lfp_trace  \\\n",
       "0  [1.3934726, 1.494771, 1.764077, 1.828315, 1.68...   \n",
       "1  [-0.14577106, -0.16059524, 0.027177656, 0.1680...   \n",
       "2  [-0.32119048, -0.52872896, -0.96851283, -0.753...   \n",
       "3  [-2.7647088, -2.5546997, -2.3051593, -2.055619...   \n",
       "4  [-2.0111465, -1.714663, -1.4255916, -1.3662949...   \n",
       "\n",
       "                                  MD_trial_lfp_trace  \n",
       "0  [-0.9783956, -0.86721426, -0.7288553, -1.40582...  \n",
       "1  [1.6281886, 1.349, 1.4675934, 0.9487473, -0.21...  \n",
       "2  [0.096357144, 0.88450915, 1.2131118, 0.8943919...  \n",
       "3  [2.087738, 1.7418406, 1.1266373, 0.45954946, 0...  \n",
       "4  [0.31871977, 1.008044, 0.25942308, -0.22730403...  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_map_and_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_columns = [col for col in channel_map_and_all_trials_df.columns if \"trace\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [col for col in channel_map_and_all_trials_df.columns if col not in trace_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mPFC_baseline_lfp_trace',\n",
       " 'mPFC_trial_lfp_trace',\n",
       " 'vHPC_baseline_lfp_trace',\n",
       " 'vHPC_trial_lfp_trace',\n",
       " 'BLA_baseline_lfp_trace',\n",
       " 'BLA_trial_lfp_trace',\n",
       " 'LH_baseline_lfp_trace',\n",
       " 'LH_trial_lfp_trace',\n",
       " 'MD_baseline_lfp_trace',\n",
       " 'MD_trial_lfp_trace']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherece Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the brain region pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_trace_columns = sorted([col for col in channel_map_and_all_trials_df.columns if \"trial_lfp_trace\" in col])\n",
    "baseline_trace_columns = sorted([col for col in channel_map_and_all_trials_df.columns if \"baseline_lfp_trace\" in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLA_trial_lfp_trace',\n",
       " 'LH_trial_lfp_trace',\n",
       " 'MD_trial_lfp_trace',\n",
       " 'mPFC_trial_lfp_trace',\n",
       " 'vHPC_trial_lfp_trace']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_trace_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_brain_region_pairs = generate_pairs(trial_trace_columns)\n",
    "trial_brain_region_pairs = sorted(trial_brain_region_pairs)\n",
    "baseline_brain_region_pairs = generate_pairs(baseline_trace_columns)\n",
    "baseline_brain_region_pairs = sorted(baseline_brain_region_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BLA_trial_lfp_trace', 'LH_trial_lfp_trace'),\n",
       " ('BLA_trial_lfp_trace', 'MD_trial_lfp_trace'),\n",
       " ('BLA_trial_lfp_trace', 'mPFC_trial_lfp_trace'),\n",
       " ('BLA_trial_lfp_trace', 'vHPC_trial_lfp_trace'),\n",
       " ('LH_trial_lfp_trace', 'MD_trial_lfp_trace'),\n",
       " ('LH_trial_lfp_trace', 'mPFC_trial_lfp_trace'),\n",
       " ('LH_trial_lfp_trace', 'vHPC_trial_lfp_trace'),\n",
       " ('MD_trial_lfp_trace', 'mPFC_trial_lfp_trace'),\n",
       " ('MD_trial_lfp_trace', 'vHPC_trial_lfp_trace'),\n",
       " ('mPFC_trial_lfp_trace', 'vHPC_trial_lfp_trace')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_brain_region_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BLA_baseline_lfp_trace', 'LH_baseline_lfp_trace'),\n",
       " ('BLA_baseline_lfp_trace', 'MD_baseline_lfp_trace'),\n",
       " ('BLA_baseline_lfp_trace', 'mPFC_baseline_lfp_trace'),\n",
       " ('BLA_baseline_lfp_trace', 'vHPC_baseline_lfp_trace'),\n",
       " ('LH_baseline_lfp_trace', 'MD_baseline_lfp_trace'),\n",
       " ('LH_baseline_lfp_trace', 'mPFC_baseline_lfp_trace'),\n",
       " ('LH_baseline_lfp_trace', 'vHPC_baseline_lfp_trace'),\n",
       " ('MD_baseline_lfp_trace', 'mPFC_baseline_lfp_trace'),\n",
       " ('MD_baseline_lfp_trace', 'vHPC_baseline_lfp_trace'),\n",
       " ('mPFC_baseline_lfp_trace', 'vHPC_baseline_lfp_trace')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_brain_region_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculating the coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLA_LH\n",
      "BLA_MD\n",
      "BLA_mPFC\n",
      "BLA_vHPC\n",
      "LH_MD\n",
      "LH_mPFC\n",
      "LH_vHPC\n",
      "MD_mPFC\n",
      "MD_vHPC\n",
      "mPFC_vHPC\n"
     ]
    }
   ],
   "source": [
    "for region_1, region_2 in trial_brain_region_pairs:\n",
    "    pair_base_name = \"{}_{}\".format(region_1.split(\"_\")[0], region_2.split(\"_\")[0])\n",
    "    print(pair_base_name)\n",
    "    try:\n",
    "        multitaper_col = \"{}_trial_multitaper\".format(pair_base_name)\n",
    "        channel_map_and_all_trials_df[multitaper_col] = channel_map_and_all_trials_df.apply(lambda x: Multitaper(time_series=np.array([x[region_1],x[region_2]]).T, sampling_frequency=RESAMPLE_RATE, time_halfbandwidth_product=TIME_HALFBANDWIDTH_PRODUCT, time_window_step=TIME_WINDOW_STEP, time_window_duration=TIME_WINDOW_DURATION), axis=1)\n",
    "    \n",
    "        connectivity_col = \"{}_trial_connectivity\".format(pair_base_name)\n",
    "        channel_map_and_all_trials_df[connectivity_col] = channel_map_and_all_trials_df[multitaper_col].apply(lambda x: Connectivity.from_multitaper(x))\n",
    "        \n",
    "        channel_map_and_all_trials_df[\"{}_trial_frequencies\".format(pair_base_name)] = channel_map_and_all_trials_df[connectivity_col].apply(lambda x: x.frequencies)\n",
    "    \n",
    "        channel_map_and_all_trials_df[\"{}_trial_coherence_magnitude\".format(pair_base_name)] = channel_map_and_all_trials_df[connectivity_col].apply(lambda x: x.coherence_magnitude()[0, :, 0, 1])\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLA_LH\n",
      "BLA_MD\n",
      "BLA_mPFC\n",
      "BLA_vHPC\n",
      "LH_MD\n",
      "LH_mPFC\n",
      "LH_vHPC\n",
      "MD_mPFC\n",
      "MD_vHPC\n",
      "mPFC_vHPC\n"
     ]
    }
   ],
   "source": [
    "for region_1, region_2 in baseline_brain_region_pairs:\n",
    "    pair_base_name = \"{}_{}\".format(region_1.split(\"_\")[0], region_2.split(\"_\")[0])\n",
    "    print(pair_base_name)\n",
    "    try:\n",
    "        multitaper_col = \"{}_baseline_multitaper\".format(pair_base_name)\n",
    "        channel_map_and_all_trials_df[multitaper_col] = channel_map_and_all_trials_df.apply(lambda x: Multitaper(time_series=np.array([x[region_1],x[region_2]]).T, sampling_frequency=RESAMPLE_RATE, time_halfbandwidth_product=TIME_HALFBANDWIDTH_PRODUCT, time_window_step=TIME_WINDOW_STEP, time_window_duration=TIME_WINDOW_DURATION), axis=1)\n",
    "    \n",
    "        connectivity_col = \"{}_baseline_connectivity\".format(pair_base_name)\n",
    "        channel_map_and_all_trials_df[connectivity_col] = channel_map_and_all_trials_df[multitaper_col].apply(lambda x: Connectivity.from_multitaper(x))\n",
    "        \n",
    "        channel_map_and_all_trials_df[\"{}_baseline_frequencies\".format(pair_base_name)] = channel_map_and_all_trials_df[connectivity_col].apply(lambda x: x.frequencies)\n",
    "    \n",
    "        channel_map_and_all_trials_df[\"{}_baseline_coherence_magnitude\".format(pair_base_name)] = channel_map_and_all_trials_df[connectivity_col].apply(lambda x: x.coherence_magnitude()[0, :, 0, 1])\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pair_base_name = []\n",
    "for region_1, region_2 in baseline_brain_region_pairs:\n",
    "    all_pair_base_name.append(\"{}_{}\".format(region_1.split(\"_\")[0], region_2.split(\"_\")[0]))\n",
    "all_pair_base_name = sorted(all_pair_base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pair_base_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq = 0\n",
    "high_freq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"BLA_LH_baseline_coherence_magnitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frequencies = channel_map_and_all_trials_df[\"BLA_LH_baseline_frequencies\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_AND_BASELINE = [\"trial\", \"baseline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"competition_closeness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"competition_closeness\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKUP_channel_map_and_all_trials_df = channel_map_and_all_trials_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df[~channel_map_and_all_trials_df[\"competition_closeness\"].isin(['lose_non_comp', 'win_non_comp'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "low_freq =30\n",
    "high_freq = 90\n",
    "for pair_base_name in all_pair_base_name:\n",
    "    print(pair_base_name)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"Coherence of Z-scored LFP in {}\".format(pair_base_name))\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Coherence of Z-scored LFP\")\n",
    "    plt.xlim(low_freq, high_freq)\n",
    "    plt.xticks(np.arange(low_freq, high_freq+1, 5))\n",
    "    plt.yticks(np.arange(0, 1, 0.1))\n",
    "    plt.ylim(0,1)\n",
    "    plt.grid()\n",
    "\n",
    "    for trial_or_baseline in TRIAL_AND_BASELINE:\n",
    "\n",
    "        coherence_col = \"{}_{}_coherence_magnitude\".format(pair_base_name, trial_or_baseline)\n",
    "        grouped_all_trials_df = channel_map_and_all_trials_df.groupby([GROUPINGS]).agg({coherence_col: lambda x: np.vstack(x.tolist())}).reset_index()\n",
    "        # grouped_all_trials_df = grouped_all_trials_df[grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\"]\n",
    "        grouped_all_trials_df[\"mean_coherence\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.nanmean(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"std_coherence\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.nanstd(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.sum(~np.isnan(x), axis=0))\n",
    "        grouped_all_trials_df[\"sem_coherence\"] = grouped_all_trials_df.apply(lambda x: x[\"std_coherence\"] / np.sqrt(x[\"n_trials\"]), axis=1)\n",
    "        for index, row in grouped_all_trials_df.iterrows():\n",
    "            try:\n",
    "                if trial_or_baseline == \"trial\":\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_coherence\"], \\\n",
    "                label=\"{} {}\".format(row[GROUPINGS], trial_or_baseline), color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                else:\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_coherence\"], \\\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                \n",
    "\n",
    "    \n",
    "                plt.fill_between(all_frequencies, \\\n",
    "                row[\"mean_coherence\"] - row[\"sem_coherence\"], row[\"mean_coherence\"] + row[\"sem_coherence\"], alpha=0.1,\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]])\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "\n",
    "    \n",
    "    plt.savefig(\"./proc/coherence/{}_{}hz_{}_coherence_of_zscored_lfp.png\".format(low_freq, high_freq, pair_base_name))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq = 0\n",
    "high_freq = 12\n",
    "for pair_base_name in all_pair_base_name:\n",
    "    print(pair_base_name)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"Coherence of Z-scored LFP in {}\".format(pair_base_name))\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Coherence of Z-scored LFP\")\n",
    "    plt.xlim(low_freq, high_freq)\n",
    "    plt.xticks(np.arange(low_freq, high_freq+1, 1))\n",
    "    plt.yticks(np.arange(0, 1, 0.1))\n",
    "    plt.ylim(0,1)\n",
    "    plt.grid()\n",
    "\n",
    "    for trial_or_baseline in TRIAL_AND_BASELINE:\n",
    "\n",
    "        coherence_col = \"{}_{}_coherence_magnitude\".format(pair_base_name, trial_or_baseline)\n",
    "        grouped_all_trials_df = channel_map_and_all_trials_df.groupby([GROUPINGS]).agg({coherence_col: lambda x: np.vstack(x.tolist())}).reset_index()\n",
    "        # grouped_all_trials_df = grouped_all_trials_df[grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\"]\n",
    "        grouped_all_trials_df[\"mean_coherence\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.nanmean(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"std_coherence\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.nanstd(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.sum(~np.isnan(x), axis=0))\n",
    "        grouped_all_trials_df[\"sem_coherence\"] = grouped_all_trials_df.apply(lambda x: x[\"std_coherence\"] / np.sqrt(x[\"n_trials\"]), axis=1)\n",
    "        for index, row in grouped_all_trials_df.iterrows():\n",
    "            try:\n",
    "                if trial_or_baseline == \"trial\":\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_coherence\"], \\\n",
    "                label=\"{} {}\".format(row[GROUPINGS], trial_or_baseline), color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                else:\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_coherence\"], \\\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                \n",
    "\n",
    "    \n",
    "                plt.fill_between(all_frequencies, \\\n",
    "                row[\"mean_coherence\"] - row[\"sem_coherence\"], row[\"mean_coherence\"] + row[\"sem_coherence\"], alpha=0.1,\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]])\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "\n",
    "    \n",
    "    plt.savefig(\"./proc/coherence/{}_{}hz_{}_coherence_of_zscored_lfp.png\".format(low_freq, high_freq, pair_base_name))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq = 10\n",
    "high_freq = 30\n",
    "low_freq = 0\n",
    "high_freq = 12\n",
    "for pair_base_name in all_pair_base_name:\n",
    "    print(pair_base_name)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"Coherence of Z-scored LFP in {}\".format(pair_base_name))\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Coherence of Z-scored LFP\")\n",
    "    plt.xlim(low_freq, high_freq)\n",
    "    plt.xticks(np.arange(low_freq, high_freq+1, 1))\n",
    "    plt.yticks(np.arange(0, 1, 0.1))\n",
    "    plt.ylim(0,1)\n",
    "    plt.grid()\n",
    "\n",
    "    for trial_or_baseline in TRIAL_AND_BASELINE:\n",
    "\n",
    "        coherence_col = \"{}_{}_coherence_magnitude\".format(pair_base_name, trial_or_baseline)\n",
    "        grouped_all_trials_df = channel_map_and_all_trials_df.groupby([GROUPINGS]).agg({coherence_col: lambda x: np.vstack(x.tolist())}).reset_index()\n",
    "        # grouped_all_trials_df = grouped_all_trials_df[grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\"]\n",
    "        grouped_all_trials_df[\"mean_coherence\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.nanmean(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"std_coherence\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.nanstd(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.sum(~np.isnan(x), axis=0))\n",
    "        grouped_all_trials_df[\"sem_coherence\"] = grouped_all_trials_df.apply(lambda x: x[\"std_coherence\"] / np.sqrt(x[\"n_trials\"]), axis=1)\n",
    "        for index, row in grouped_all_trials_df.iterrows():\n",
    "            try:\n",
    "                if trial_or_baseline == \"trial\":\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_coherence\"], \\\n",
    "                label=\"{} {}\".format(row[GROUPINGS], trial_or_baseline), color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                else:\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_coherence\"], \\\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                \n",
    "\n",
    "    \n",
    "                plt.fill_between(all_frequencies, \\\n",
    "                row[\"mean_coherence\"] - row[\"sem_coherence\"], row[\"mean_coherence\"] + row[\"sem_coherence\"], alpha=0.1,\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]])\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "\n",
    "    \n",
    "    plt.savefig(\"./proc/coherence/{}_{}hz_{}_coherence_of_zscored_lfp.png\".format(low_freq, high_freq, pair_base_name))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "low_freq = 30\n",
    "high_freq = 90\n",
    "\n",
    "for pair_base_name in all_pair_base_name:\n",
    "    print(pair_base_name)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(\"Coherence of Z-scored LFP in {}\".format(pair_base_name))\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Coherence of Z-scored LFP\")\n",
    "    plt.xlim(low_freq, high_freq)\n",
    "    plt.xticks(np.arange(low_freq, high_freq+1, 5))\n",
    "    plt.yticks(np.arange(0, 1, 0.1))\n",
    "    plt.ylim(0,1)\n",
    "    plt.grid()\n",
    "\n",
    "    for trial_or_baseline in TRIAL_AND_BASELINE:\n",
    "\n",
    "        coherence_col = \"{}_{}_coherence_magnitude\".format(pair_base_name, trial_or_baseline)\n",
    "        grouped_all_trials_df = channel_map_and_all_trials_df.groupby([GROUPINGS]).agg({coherence_col: lambda x: np.vstack(x.tolist())}).reset_index()\n",
    "        # grouped_all_trials_df = grouped_all_trials_df[grouped_all_trials_df[\"trial_or_baseline\"] == \"trial\"]\n",
    "        grouped_all_trials_df[\"mean_coherence\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.nanmean(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"std_coherence\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.nanstd(np.vstack(x), axis=0))\n",
    "        grouped_all_trials_df[\"n_trials\"] = grouped_all_trials_df[coherence_col].apply(lambda x: np.sum(~np.isnan(x), axis=0))\n",
    "        grouped_all_trials_df[\"sem_coherence\"] = grouped_all_trials_df.apply(lambda x: x[\"std_coherence\"] / np.sqrt(x[\"n_trials\"]), axis=1)\n",
    "        for index, row in grouped_all_trials_df.iterrows():\n",
    "            try:\n",
    "                if trial_or_baseline == \"trial\":\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_coherence\"], \\\n",
    "                label=\"{} {}\".format(row[GROUPINGS], trial_or_baseline), color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                else:\n",
    "                    ax = sns.lineplot(x=all_frequencies, y=row[\"mean_coherence\"], \\\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]],\n",
    "                linestyle=TRIAL_OR_BASELINE_TO_STYLE[trial_or_baseline], linewidth=3)\n",
    "                \n",
    "\n",
    "    \n",
    "                plt.fill_between(all_frequencies, \\\n",
    "                row[\"mean_coherence\"] - row[\"sem_coherence\"], row[\"mean_coherence\"] + row[\"sem_coherence\"], alpha=0.1,\n",
    "                color=BASELINE_OUTCOME_TO_COLOR[row[GROUPINGS]])\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "\n",
    "    \n",
    "    plt.savefig(\"./proc/coherence/{}_{}hz_{}_coherence_of_zscored_lfp.png\".format(low_freq, high_freq, pair_base_name))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict():\n",
    "    return defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frequencies[4:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQUENCY_BANDS = (4,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_FREQUENCY = {\"theta\": (4,13), \"beta\": (12,31), \"gamma\": (30, 90)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_ALL_COL = {\"theta\": [], \"beta\": [], \"gamma\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_coherence_col = [col for col in channel_map_and_all_trials_df.columns if \"trial_coherence_magnitude\" in col]\n",
    "for band, frequency in BAND_TO_FREQUENCY.items():\n",
    "    for col in all_coherence_col:\n",
    "        BAND_COL = \"{}_averaged_{}_coherence\".format(col.strip(\"_coherence_magnitude\"), band)\n",
    "        BAND_TO_ALL_COL[band].append(BAND_COL)\n",
    "        print(BAND_COL)\n",
    "        channel_map_and_all_trials_df[BAND_COL] = channel_map_and_all_trials_df[col].apply(lambda x: np.mean(x[frequency[0]:frequency[1]]))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[GROUPINGS].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_pair_to_outcome_to_coherence = {k: defaultdict(nested_dict) for k,v in BAND_TO_FREQUENCY.items()}\n",
    "\n",
    "for band, frequency in BAND_TO_FREQUENCY.items():\n",
    "    for outcome in channel_map_and_all_trials_df[GROUPINGS].unique():\n",
    "        outcome_df = channel_map_and_all_trials_df[channel_map_and_all_trials_df[GROUPINGS] == outcome].copy()\n",
    "        for band_col in BAND_TO_ALL_COL[band]:\n",
    "            band_col.strip(\"_averaged_{}_coherence\".format(band))\n",
    "            region_pair_to_outcome_to_coherence[band][band_col.strip(\"_averaged_{}_coherence\".format(band))][outcome][\"mean\"] = outcome_df[band_col].mean() \n",
    "            region_pair_to_outcome_to_coherence[band][band_col.strip(\"_averaged_{}_coherence\".format(band))][outcome][\"std\"] = outcome_df[band_col].sem() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band, frequency in BAND_TO_FREQUENCY.items(): \n",
    "    # Convert the nested dictionary to a DataFrame\n",
    "    data = []\n",
    "    for group_name, group_data in region_pair_to_outcome_to_coherence[band].items():\n",
    "        for bar_name, bar_dict in group_data.items():\n",
    "            data.append({\"Group\": group_name, \"Bar\": bar_name, \"coherence\": bar_dict[\"mean\"], \"std\": bar_dict[\"std\"]})\n",
    "    df = pd.DataFrame(data)#.sort_values(by=[\"Group\", \"Bar\"])\n",
    "    df[\"color\"] = df[\"Bar\"].map(BASELINE_OUTCOME_TO_COLOR)\n",
    "    \n",
    "    # Create barplot\n",
    "    ax = sns.barplot(x='Group', y='coherence', hue='Bar', data=df, palette=df[\"color\"], ci=None)\n",
    "    \n",
    "    # Adding error bars\n",
    "    groups = df['Group'].unique()\n",
    "    bars_per_group = df['Bar'].nunique()\n",
    "    bar_width = 0.8 / bars_per_group\n",
    "    x_positions = []\n",
    "    \n",
    "    for i, group in enumerate(groups):\n",
    "        num_bars = df[df['Group'] == group].shape[0]\n",
    "        group_positions = np.linspace(i - bar_width*(num_bars-1)/2, i + bar_width*(num_bars-1)/2, num_bars)\n",
    "        x_positions.extend(group_positions)\n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Brain region pairs\")\n",
    "    plt.ylabel(\"Averaged {} Coherence\".format(band))\n",
    "    plt.legend(title=\"Trial Conditions\", loc=\"lower left\", ncol=4)\n",
    "    plt.title(\"Averaged {} Coherence\".format(band))\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.ylim(0,1)\n",
    "    \n",
    "    plt.savefig(\"./proc/coherence/all_zscored_{}_lfp_power_coherence.png\".format(band))\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for band, frequency in BAND_TO_FREQUENCY.items(): \n",
    "    # Convert the nested dictionary to a DataFrame\n",
    "    data = []\n",
    "    for group_name, group_data in region_pair_to_outcome_to_coherence[band].items():\n",
    "        for bar_name, bar_dict in group_data.items():\n",
    "            data.append({\"Group\": group_name, \"Bar\": bar_name, \"coherence\": bar_dict[\"mean\"], \"std\": bar_dict[\"std\"]})\n",
    "    df = pd.DataFrame(data).sort_values(by=[\"Group\", \"Bar\"])\n",
    "    df[\"color\"] = df[\"Bar\"].map(BASELINE_OUTCOME_TO_COLOR)\n",
    "    \n",
    "    # Create barplot\n",
    "    ax = sns.barplot(x='Group', y='coherence', hue='Bar', data=df, palette=df[\"color\"], ci=None)\n",
    "    \n",
    "    # Adding error bars\n",
    "    groups = df['Group'].unique()\n",
    "    bars_per_group = df['Bar'].nunique()\n",
    "    bar_width = 0.8 / bars_per_group\n",
    "    x_positions = []\n",
    "    \n",
    "    for i, group in enumerate(groups):\n",
    "        num_bars = df[df['Group'] == group].shape[0]\n",
    "        group_positions = np.linspace(i - bar_width*(num_bars-1)/2, i + bar_width*(num_bars-1)/2, num_bars)\n",
    "        x_positions.extend(group_positions)\n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Brain region pairs\")\n",
    "    plt.ylabel(\"Averaged {} Coherence\".format(band))\n",
    "    plt.legend(title=\"Trial Conditions\", loc=\"lower left\", ncol=4)\n",
    "    plt.title(\"Averaged {} Coherence\".format(band))\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.ylim(0,1)\n",
    "    \n",
    "    plt.savefig(\"./proc/coherence/all_zscored_{}_lfp_power_coherence.png\".format(band))\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"LH_baseline_lfp_trace\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_COLUMNS = [\"time\",\n",
    "\"recording_dir\",\n",
    "\"recording_file\",\n",
    "\"time_stamp_index\",\n",
    "\"video_file\",\n",
    "\"video_frame\",\n",
    "\"video_number\",\n",
    "\"subject_info\",\n",
    "\"competition_closeness\",\n",
    "\"video_name\",\n",
    "\"all_subjects\",\n",
    "\"current_subject\",\n",
    "\"trial_outcome\",\n",
    "\"lfp_index\",\n",
    "\"baseline_lfp_timestamp_range\",\n",
    "\"trial_lfp_timestamp_range\",\n",
    "\"baseline_ephys_timestamp_range\",\n",
    "\"trial_ephys_timestamp_range\",\n",
    "\"baseline_videoframe_range\",\n",
    "\"trial_videoframe_range\",\n",
    "\"trial_number\",\n",
    "\"Cohort\",\n",
    "\"spike_interface_mPFC\",\n",
    "\"spike_interface_vHPC\",\n",
    "\"spike_interface_BLA\",\n",
    "\"spike_interface_LH\",\n",
    "\"spike_interface_MD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_COLUMNS += [col for col in channel_map_and_all_trials_df.columns if \"coherence_magnitude\" in col]\n",
    "KEEP_COLUMNS += [col for col in channel_map_and_all_trials_df.columns if \"averaged\" in col]\n",
    "KEEP_COLUMNS += [col for col in channel_map_and_all_trials_df.columns if \"frequencies\" in col]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"LH_MD_baseline_coherence_magnitude\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[KEEP_COLUMNS].to_pickle(\"./proc/rce_lfp_power_coherence.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = channel_map_and_all_trials_df[KEEP_COLUMNS].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coherence_col = [col for col in channel_map_and_all_trials_df.columns if \"baseline_coherence_magnitude\" in col]\n",
    "for band, frequency in BAND_TO_FREQUENCY.items():\n",
    "    for col in all_coherence_col:\n",
    "        BAND_COL = \"{}_averaged_{}_coherence\".format(col.strip(\"_coherence_magnitude\"), band)\n",
    "        BAND_TO_ALL_COL[band].append(BAND_COL)\n",
    "        print(BAND_COL)\n",
    "        channel_map_and_all_trials_df[BAND_COL] = channel_map_and_all_trials_df[col].apply(lambda x: np.mean(x[frequency[0]:frequency[1]]))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_TO_ALL_COL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_pair_to_outcome_to_coherence = {k: defaultdict(nested_dict) for k,v in BAND_TO_FREQUENCY.items()}\n",
    "\n",
    "for band, frequency in BAND_TO_FREQUENCY.items():\n",
    "    for outcome in channel_map_and_all_trials_df[GROUPINGS].unique():\n",
    "        outcome_df = channel_map_and_all_trials_df[channel_map_and_all_trials_df[GROUPINGS] == outcome].copy()\n",
    "        for band_col in BAND_TO_ALL_COL[band]:\n",
    "            band_col.strip(\"_averaged_{}_coherence\".format(band))\n",
    "            region_pair_to_outcome_to_coherence[band][band_col.strip(\"_averaged_{}_coherence\".format(band))][outcome][\"mean\"] = outcome_df[band_col].mean() \n",
    "            region_pair_to_outcome_to_coherence[band][band_col.strip(\"_averaged_{}_coherence\".format(band))][outcome][\"std\"] = outcome_df[band_col].sem() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band, frequency in BAND_TO_FREQUENCY.items(): \n",
    "    # Convert the nested dictionary to a DataFrame\n",
    "    data = []\n",
    "    for group_name, group_data in region_pair_to_outcome_to_coherence[band].items():\n",
    "        for bar_name, bar_dict in group_data.items():\n",
    "            data.append({\"Group\": group_name, \"Bar\": bar_name, \"coherence\": bar_dict[\"mean\"], \"std\": bar_dict[\"std\"]})\n",
    "    df = pd.DataFrame(data).sort_values(by=[\"Group\", \"Bar\"])\n",
    "    df[\"color\"] = df[\"Bar\"].map(BASELINE_OUTCOME_TO_COLOR)\n",
    "    \n",
    "    # Create barplot\n",
    "    ax = sns.barplot(x='Group', y='coherence', hue='Bar', data=df, palette=df[\"color\"], ci=None)\n",
    "    \n",
    "    # Adding error bars\n",
    "    groups = df['Group'].unique()\n",
    "    bars_per_group = df['Bar'].nunique()\n",
    "    bar_width = 0.8 / bars_per_group\n",
    "    x_positions = []\n",
    "    \n",
    "    for i, group in enumerate(groups):\n",
    "        num_bars = df[df['Group'] == group].shape[0]\n",
    "        group_positions = np.linspace(i - bar_width*(num_bars-1)/2, i + bar_width*(num_bars-1)/2, num_bars)\n",
    "        x_positions.extend(group_positions)\n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Brain region pairs\")\n",
    "    plt.ylabel(\"Averaged {} Coherence\".format(band))\n",
    "    plt.legend(title=\"Trial Conditions\", loc=\"lower left\", ncol=3)\n",
    "    plt.title(\"Averaged {} Coherence\".format(band))\n",
    "    plt.tight_layout()\n",
    "    plt.grid()\n",
    "    plt.ylim(0,1)\n",
    "    \n",
    "    # plt.savefig(\"./proc/coherence/all_zscored_lfp_power_coherence.png\")\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
