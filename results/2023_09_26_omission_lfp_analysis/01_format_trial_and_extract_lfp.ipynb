{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Trial formatting and LFP extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.cm as cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as sp\n",
    "from spectral_connectivity import Multitaper, Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set('notebook', 'ticks', font_scale=1.2)\n",
    "mpl.rcParams['figure.figsize'] = [15,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "THORAX_INDEX = 1\n",
    "CHANNEL_MAPPING_DF = pd.read_excel(\"./channel_mapping.xlsx\")\n",
    "TONE_TIMESTAMP_DF = pd.read_excel(\"./rce_tone_timestamp.xlsx\", index_col=0)\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = pd.read_excel(\"./video_to_frame_and_subject.xlsx\")\n",
    "SLEAP_DIR = \"/scratch/back_up/reward_competition_extention/proc/id_corrected\"\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs\n",
    "MED_PC_WIDTH = 29.5\n",
    "MED_PC_HEIGHT = 24\n",
    "FRAME_RATE = 22\n",
    "VELOCITY_WINDOW_SIZE = FRAME_RATE\n",
    "ROLLING_AVERAGE_WINDOW_SIZE = FRAME_RATE // 2\n",
    "TRIAL_DURATION = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SESSION_DIR = list(set(['/scratch/back_up/reward_competition_extention/data/omission/2023_06_17/20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2.rec',\n",
    "'/scratch/back_up/reward_competition_extention/data/omission/2023_06_18/20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1.rec',\n",
    "'/scratch/back_up/reward_competition_extention/data/omission/2023_06_19/20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4.rec',\n",
    "'/scratch/back_up/reward_competition_extention/data/omission/2023_06_20/20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1.rec',\n",
    "'/scratch/back_up/reward_competition_extention/data/omission/2023_06_21/20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2.rec'\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPHYS_SAMPLING_RATE = 20000\n",
    "LFP_SAMPLING_RATE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleap_tracks_from_h5(filename):\n",
    "    \"\"\"\n",
    "    Retrieve pose tracking data (tracks) from a SLEAP-generated h5 file.\n",
    "    \n",
    "    This function is intended for use with Pandas' apply method on columns containing filenames.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the SLEAP h5 file containing pose tracking data.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A transposed version of the 'tracks' dataset in the provided h5 file.\n",
    "        \n",
    "    Example:\n",
    "    --------\n",
    "    df['tracks'] = df['filename_column'].apply(get_sleap_tracks_from_h5)\n",
    "    \n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        return f[\"tracks\"][:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleap_track_names_from_h5(filename):\n",
    "    \"\"\"\n",
    "    Retrieve the names of tracked features from a SLEAP-generated h5 file.\n",
    "    \n",
    "    This function is intended for use with Pandas' apply method on columns containing filenames.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the SLEAP h5 file containing pose tracking data.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    h5py.Dataset\n",
    "        The 'track_names' dataset in the provided h5 file, representing the names of the tracked features.\n",
    "        \n",
    "    Example:\n",
    "    --------\n",
    "    df['track_names'] = df['filename_column'].apply(get_sleap_track_names_from_h5)\n",
    "    \n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        return [item.tobytes().decode('utf-8') for item in f[\"track_names\"][:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_names_from_sleap(filename):\n",
    "    \"\"\"\n",
    "    Retrieve node names from a SLEAP h5 file.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): Path to the SLEAP h5 file.\n",
    "\n",
    "    Returns:\n",
    "    - list of str: List of node names.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        return [n.decode() for n in f[\"node_names\"][:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_missing(Y, kind=\"linear\"):\n",
    "    \"\"\"Fills missing values independently along each dimension after the first.\"\"\"\n",
    "\n",
    "    # Store initial shape.\n",
    "    initial_shape = Y.shape\n",
    "\n",
    "    # Flatten after first dim.\n",
    "    Y = Y.reshape((initial_shape[0], -1))\n",
    "\n",
    "    # Interpolate along each slice.\n",
    "    for i in range(Y.shape[-1]):\n",
    "        y = Y[:, i]\n",
    "\n",
    "        # Build interpolant.\n",
    "        x = np.flatnonzero(~np.isnan(y))\n",
    "        f = interp1d(x, y[x], kind=kind, fill_value=np.nan, bounds_error=False)\n",
    "\n",
    "        # Fill missing\n",
    "        xq = np.flatnonzero(np.isnan(y))\n",
    "        y[xq] = f(xq)\n",
    "        \n",
    "        # Fill leading or trailing NaNs with the nearest non-NaN values\n",
    "        mask = np.isnan(y)\n",
    "        y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), y[~mask])\n",
    "\n",
    "        # Save slice\n",
    "        Y[:, i] = y\n",
    "\n",
    "    # Restore to initial shape.\n",
    "    Y = Y.reshape(initial_shape)\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_velocity(node_loc, window_size=25, polynomial_order=3):\n",
    "    \"\"\"\n",
    "    Calculate the velocity of tracked nodes from pose data.\n",
    "    \n",
    "    The function utilizes the Savitzky-Golay filter to smooth the data and compute the velocity.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    node_loc : numpy.ndarray\n",
    "        The location of nodes, represented as an array of shape [frames, 2]. \n",
    "        Each row represents x and y coordinates for a particular frame.\n",
    "        \n",
    "    window_size : int, optional\n",
    "        The size of the window used for the Savitzky-Golay filter. \n",
    "        Represents the number of consecutive data points used when smoothing the data.\n",
    "        Default is 25.\n",
    "        \n",
    "    polynomial_order : int, optional\n",
    "        The order of the polynomial fit to the data within the Savitzky-Golay filter window.\n",
    "        Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The velocity for each frame, calculated from the smoothed x and y coordinates.\n",
    "    \n",
    "    \"\"\"\n",
    "    node_loc_vel = np.zeros_like(node_loc)\n",
    "    \n",
    "    # For each coordinate (x and y), smooth the data and calculate the derivative (velocity)\n",
    "    for c in range(node_loc.shape[-1]):\n",
    "        node_loc_vel[:, c] = savgol_filter(node_loc[:, c], window_size, polynomial_order, deriv=1)\n",
    "    \n",
    "    # Calculate the magnitude of the velocity vectors for each frame\n",
    "    node_vel = np.linalg.norm(node_loc_vel, axis=1)\n",
    "\n",
    "    return node_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sleap_data(filename):\n",
    "    \"\"\"\n",
    "    Extracts coordinates, names of body parts, and track names from a SLEAP file.\n",
    "    \n",
    "    Parameters:\n",
    "    - filename (str): Path to the SLEAP file.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: A tuple containing the following elements:\n",
    "        * locations (numpy.ndarray): Array containing the coordinates.\n",
    "        * node_names (list of str): List of body part names.\n",
    "        * track_names (list of str): List of track names.\n",
    "    \n",
    "    Example:\n",
    "    >>> locations, node_names, track_names = extract_sleap_data(\"path/to/sleap/file.h5\")\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        result[\"locations\"] = f[\"tracks\"][:].T\n",
    "        result[\"node_names\"] = [n.decode() for n in f[\"node_names\"][:]]\n",
    "        result[\"track_names\"] = [n.decode() for n in f[\"track_names\"][:]]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_dimension_in_array(arr, dimension=0, ratio=1):\n",
    "    \"\"\"\n",
    "    Rescale values of a specified dimension in a 3D numpy array for the entire array.\n",
    "    \n",
    "    Parameters:\n",
    "    - arr (numpy.ndarray): A 3D numpy array where the third dimension is being rescaled.\n",
    "    - dimension (int, default=0): Specifies which dimension (0 or 1) of the third \n",
    "                                  dimension in the array should be rescaled. \n",
    "                                  For instance, in many contexts:\n",
    "                                  0 represents the x-coordinate, \n",
    "                                  1 represents the y-coordinate.\n",
    "    - ratio (float, default=1): The scaling factor to be applied.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: The rescaled array.\n",
    "    \"\"\"\n",
    "    \n",
    "    arr[:,:,dimension] *= ratio\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_average(arr, window_size):\n",
    "    \"\"\"\n",
    "    Computes the rolling average using a specified window size.\n",
    "    \n",
    "    Parameters:\n",
    "        arr (numpy.array): The input array to compute the rolling average for.\n",
    "        window_size (int): The size of the rolling window.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: The rolling average of the input array.\n",
    "    \"\"\"\n",
    "    if window_size < 1:\n",
    "       raise ValueError(\"Window size must be at least 1.\")\n",
    "    \n",
    "    # Create a uniform window of given window size\n",
    "    window = np.ones(window_size) / window_size\n",
    "\n",
    "    # Use numpy's convolve function to compute the rolling average\n",
    "    return np.convolve(arr, window, mode='valid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked_average(arr, chunk_size):\n",
    "    \"\"\"\n",
    "    Computes the average for non-overlapping chunks of the input array.\n",
    "    \n",
    "    Parameters:\n",
    "        arr (numpy.array): The input array.\n",
    "        chunk_size (int): The size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: The averages of the non-overlapping chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of chunks\n",
    "    num_chunks = len(arr) // chunk_size\n",
    "    \n",
    "    # Reshape the array into a 2D array of shape (num_chunks, chunk_size)\n",
    "    reshaped_arr = arr[:num_chunks * chunk_size].reshape(num_chunks, chunk_size)\n",
    "    \n",
    "    # Compute the mean along the second axis (i.e., for each chunk)\n",
    "    return reshaped_arr.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sorted_index(group, value_column='Value', index_column='SortedIndex'):\n",
    "    \"\"\" \n",
    "    Computes the index of each row's value within its sorted group.\n",
    "\n",
    "    Parameters:\n",
    "    - group (pd.DataFrame): A group of data.\n",
    "    - value_column (str): Name of the column containing the values to be sorted.\n",
    "    - index_column (str): Name of the new column that will contain the indices.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The group with an additional column containing the indices.\n",
    "    \"\"\"\n",
    "    sorted_values = sorted(list(set(group[value_column].tolist())))\n",
    "    group[index_column] = group[value_column].apply(lambda x: sorted_values.index(x))\n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in trial information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping all rows that have not been labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = TONE_TIMESTAMP_DF.dropna(subset=\"condition\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20221202_134600_omission_and_competition_subject_6_1_and_6_2',\n",
       " '20221203_154800_omission_and_competition_subject_6_4_and_6_1',\n",
       " '20221214_125409_om_and_comp_6_1_and_6_3',\n",
       " '20221215_145401_comp_amd_om_6_1_and_6_3',\n",
       " '20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3',\n",
       " '20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2',\n",
       " '20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1',\n",
       " '20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4',\n",
       " '20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1',\n",
       " '20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(all_trials_df[\"recording_dir\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making the video frame number usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"video_frame\"] = all_trials_df[\"video_frame\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the name of the video so that we can sync it up with the ephys recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"video_name\"]  = all_trials_df[\"video_file\"].apply(lambda x: x.strip(\".videoTimeStamps.cameraHWSync\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting all subject IDs for a given recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using different id extractions for different file formats\n",
    "all_trials_df[\"all_subjects\"] = all_trials_df[\"recording_dir\"].apply(lambda x: x if \"2023\" in x else \"subj\" + \"_\".join(x.split(\"_\")[-5:]))\n",
    "all_trials_df[\"all_subjects\"] = all_trials_df[\"all_subjects\"].apply(lambda x: tuple(sorted([num.strip(\"_\").replace(\"_\",\".\") for num in x.replace(\"-\", \"_\").split(\"subj\")[-1].strip(\"_\").split(\"and\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('6.1', '6.2'), ('6.1', '6.4'), ('6.1', '6.3'), ('1.3', '1.4'),\n",
       "       ('1.1', '1.2'), ('1.1', '1.4'), ('1.2', '1.4')], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df[\"all_subjects\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"current_subject\"] = all_trials_df[\"subject_info\"].apply(lambda x: \".\".join(x.replace(\"-\",\"_\").split(\"_\")[:2])).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6.1', '1.3', '1.4', '1.1', '1.2'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df[\"current_subject\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the trial label to win or lose based on who won the trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_outcome\"] = all_trials_df.apply(\n",
    "    lambda x: \"win\" if str(x[\"condition\"]).strip() == str(x[\"current_subject\"]) \n",
    "             else (\"lose\" if str(x[\"condition\"]) in x[\"all_subjects\"] \n",
    "                   else x[\"condition\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rewarded', 'omission', 'win', 'lose'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df[\"trial_outcome\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the competition closeness as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_closeness_map = {k: \"non_comp\" if \"only\" in str(k).lower() else \"comp\" if type(k) is str else np.nan for k in all_trials_df[\"competition_closeness\"].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: nan,\n",
       " 'Subj 1 Only': 'non_comp',\n",
       " 'Subj 2 blocking Subj 1': 'comp',\n",
       " 'Subj 1 then Subj 2': 'comp',\n",
       " 'Subj 1 blocking Subj 2': 'comp',\n",
       " 'Subj 2 Only': 'non_comp',\n",
       " 'Subj 2 then Subj 1': 'comp',\n",
       " 'Close Call': 'comp'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition_closeness_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"competition_closeness\"] = all_trials_df[\"competition_closeness\"].map(competition_closeness_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"competition_closeness\"] = all_trials_df.apply(lambda x: \"_\".join([str(x[\"trial_outcome\"]), str(x[\"competition_closeness\"])]).strip(\"nan\").strip(\"_\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rewarded', 'omission', 'win_non_comp', 'win_comp',\n",
       "       'lose_non_comp', 'lose_comp'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df[\"competition_closeness\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the LFP index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"lfp_index\"] = (all_trials_df[\"time_stamp_index\"] // (EPHYS_SAMPLING_RATE/LFP_SAMPLING_RATE)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"time\"] = all_trials_df[\"time\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"time_stamp_index\"] = all_trials_df[\"time_stamp_index\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df.drop(columns=[\"state\", \"din\", \"condition\", \"Unnamed: 13\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>time_stamp_index</th>\n",
       "      <th>video_file</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>video_number</th>\n",
       "      <th>subject_info</th>\n",
       "      <th>competition_closeness</th>\n",
       "      <th>video_name</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>trial_outcome</th>\n",
       "      <th>lfp_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6310663</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>1390826</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>1734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>69541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7910662</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>2990825</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>3728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>149541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9710660</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>4790823</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>5972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>239541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11310658</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>6390821</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>7966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>omission</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>omission</td>\n",
       "      <td>319541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12810657</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>7890820</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>9836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>394541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time                                      recording_dir  \\\n",
       "0   6310663  20221202_134600_omission_and_competition_subje...   \n",
       "1   7910662  20221202_134600_omission_and_competition_subje...   \n",
       "2   9710660  20221202_134600_omission_and_competition_subje...   \n",
       "3  11310658  20221202_134600_omission_and_competition_subje...   \n",
       "4  12810657  20221202_134600_omission_and_competition_subje...   \n",
       "\n",
       "                                      recording_file  time_stamp_index  \\\n",
       "0  20221202_134600_omission_and_competition_subje...           1390826   \n",
       "1  20221202_134600_omission_and_competition_subje...           2990825   \n",
       "2  20221202_134600_omission_and_competition_subje...           4790823   \n",
       "3  20221202_134600_omission_and_competition_subje...           6390821   \n",
       "4  20221202_134600_omission_and_competition_subje...           7890820   \n",
       "\n",
       "                                          video_file  video_frame  \\\n",
       "0  20221202_134600_omission_and_competition_subje...         1734   \n",
       "1  20221202_134600_omission_and_competition_subje...         3728   \n",
       "2  20221202_134600_omission_and_competition_subje...         5972   \n",
       "3  20221202_134600_omission_and_competition_subje...         7966   \n",
       "4  20221202_134600_omission_and_competition_subje...         9836   \n",
       "\n",
       "   video_number      subject_info competition_closeness  \\\n",
       "0           1.0  6_1_top_2_base_3              rewarded   \n",
       "1           1.0  6_1_top_2_base_3              rewarded   \n",
       "2           1.0  6_1_top_2_base_3              rewarded   \n",
       "3           1.0  6_1_top_2_base_3              omission   \n",
       "4           1.0  6_1_top_2_base_3              rewarded   \n",
       "\n",
       "                                          video_name all_subjects  \\\n",
       "0  20221202_134600_omission_and_competition_subje...   (6.1, 6.2)   \n",
       "1  20221202_134600_omission_and_competition_subje...   (6.1, 6.2)   \n",
       "2  20221202_134600_omission_and_competition_subje...   (6.1, 6.2)   \n",
       "3  20221202_134600_omission_and_competition_subje...   (6.1, 6.2)   \n",
       "4  20221202_134600_omission_and_competition_subje...   (6.1, 6.2)   \n",
       "\n",
       "  current_subject trial_outcome  lfp_index  \n",
       "0             6.1      rewarded      69541  \n",
       "1             6.1      rewarded     149541  \n",
       "2             6.1      rewarded     239541  \n",
       "3             6.1      omission     319541  \n",
       "4             6.1      rewarded     394541  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df.to_csv(\"./proc/all_region_trial_metadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230619_115321_standard_comp_to_omission_D3_subj_1-4_t3b3L_box2_merged\n",
      "20230621_111240_standard_comp_to_omission_D5_subj_1-4_t3b3L_box1_merged\n",
      "20230617_115521_standard_comp_to_omission_D1_subj_1-2_t2b2L_box2_merged\n",
      "20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged\n",
      "20230620_114347_standard_comp_to_omission_D4_subj_1-1_t1b2L_box_2_merged\n",
      "20230620_114347_standard_comp_to_omission_D4_subj_1-2_t3b3L_box_1_merged\n",
      "20230618_100636_standard_comp_to_omission_D2_subj_1_4_t4b3L_box1_merged\n",
      "20230618_100636_standard_comp_to_omission_D2_subj_1_1_t1b2L_box2_merged\n"
     ]
    }
   ],
   "source": [
    "recording_name_to_all_ch_lfp = {}\n",
    "# Going through all the recording sessions \n",
    "for session_dir in ALL_SESSION_DIR:\n",
    "    # Going through all the recordings in each session\n",
    "    for recording_path in glob.glob(os.path.join(session_dir, \"*.rec\")):\n",
    "        try:\n",
    "            recording_basename = os.path.splitext(os.path.basename(recording_path))[0]\n",
    "            # checking to see if the recording has an ECU component\n",
    "            # if it doesn't, then the next one be extracted\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=\"ECU\")\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=\"trodes\")\n",
    "            print(recording_basename)\n",
    "            # Preprocessing the LFP\n",
    "            current_recording = sp.bandpass_filter(current_recording, freq_min=0.5, freq_max=300)\n",
    "            current_recording = sp.notch_filter(current_recording, freq=60)\n",
    "            current_recording = sp.resample(current_recording, resample_rate=1000)\n",
    "            current_recording = sp.zscore(current_recording)\n",
    "            recording_name_to_all_ch_lfp[recording_basename] = current_recording\n",
    "        except:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtering for all trials that have labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df[all_trials_df[\"recording_file\"].isin(recording_name_to_all_ch_lfp.keys())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>time_stamp_index</th>\n",
       "      <th>video_file</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>video_number</th>\n",
       "      <th>subject_info</th>\n",
       "      <th>competition_closeness</th>\n",
       "      <th>video_name</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>trial_outcome</th>\n",
       "      <th>lfp_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4509412</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>1030879</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>1029</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-1_t1b3L_box1</td>\n",
       "      <td>lose_comp</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>(1.1, 1.2)</td>\n",
       "      <td>1.1</td>\n",
       "      <td>lose</td>\n",
       "      <td>51543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6909411</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>3430878</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>3425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-1_t1b3L_box1</td>\n",
       "      <td>win_comp</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>(1.1, 1.2)</td>\n",
       "      <td>1.1</td>\n",
       "      <td>win</td>\n",
       "      <td>171543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9209413</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>5730880</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>5720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-1_t1b3L_box1</td>\n",
       "      <td>win_comp</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>(1.1, 1.2)</td>\n",
       "      <td>1.1</td>\n",
       "      <td>win</td>\n",
       "      <td>286544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11009410</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>7530877</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>7516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-1_t1b3L_box1</td>\n",
       "      <td>lose_non_comp</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>(1.1, 1.2)</td>\n",
       "      <td>1.1</td>\n",
       "      <td>lose</td>\n",
       "      <td>376543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12109413</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>8630880</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>8615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-1_t1b3L_box1</td>\n",
       "      <td>win_non_comp</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>(1.1, 1.2)</td>\n",
       "      <td>1.1</td>\n",
       "      <td>win</td>\n",
       "      <td>431544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time                                      recording_dir  \\\n",
       "0   4509412  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "1   6909411  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "2   9209413  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "3  11009410  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "4  12109413  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "\n",
       "                                      recording_file  time_stamp_index  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...           1030879   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...           3430878   \n",
       "2  20230617_115521_standard_comp_to_omission_D1_s...           5730880   \n",
       "3  20230617_115521_standard_comp_to_omission_D1_s...           7530877   \n",
       "4  20230617_115521_standard_comp_to_omission_D1_s...           8630880   \n",
       "\n",
       "                                          video_file  video_frame  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...         1029   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...         3425   \n",
       "2  20230617_115521_standard_comp_to_omission_D1_s...         5720   \n",
       "3  20230617_115521_standard_comp_to_omission_D1_s...         7516   \n",
       "4  20230617_115521_standard_comp_to_omission_D1_s...         8615   \n",
       "\n",
       "   video_number    subject_info competition_closeness  \\\n",
       "0           1.0  1-1_t1b3L_box1             lose_comp   \n",
       "1           1.0  1-1_t1b3L_box1              win_comp   \n",
       "2           1.0  1-1_t1b3L_box1              win_comp   \n",
       "3           1.0  1-1_t1b3L_box1         lose_non_comp   \n",
       "4           1.0  1-1_t1b3L_box1          win_non_comp   \n",
       "\n",
       "                                          video_name all_subjects  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...   (1.1, 1.2)   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...   (1.1, 1.2)   \n",
       "2  20230617_115521_standard_comp_to_omission_D1_s...   (1.1, 1.2)   \n",
       "3  20230617_115521_standard_comp_to_omission_D1_s...   (1.1, 1.2)   \n",
       "4  20230617_115521_standard_comp_to_omission_D1_s...   (1.1, 1.2)   \n",
       "\n",
       "  current_subject trial_outcome  lfp_index  \n",
       "0             1.1          lose      51543  \n",
       "1             1.1           win     171543  \n",
       "2             1.1           win     286544  \n",
       "3             1.1          lose     376543  \n",
       "4             1.1           win     431544  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding trial numbers based on timestamp ordering for each recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df.groupby('recording_file').apply(lambda g: compute_sorted_index(g, value_column='time', index_column='trial_number')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials_df[\"trial_number\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the LFP trace information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF = CHANNEL_MAPPING_DF[CHANNEL_MAPPING_DF[\"Cohort\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>eib_mPFC</th>\n",
       "      <th>eib_vHPC</th>\n",
       "      <th>eib_BLA</th>\n",
       "      <th>eib_LH</th>\n",
       "      <th>eib_MD</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cohort  Subject  eib_mPFC  eib_vHPC  eib_BLA  eib_LH  eib_MD  \\\n",
       "4       2      1.1       NaN        16       17      18      19   \n",
       "5       2      1.2       NaN        31       30      29      28   \n",
       "6       2      1.3       NaN        15       14      13      12   \n",
       "7       2      1.4       NaN        15       14      13      12   \n",
       "\n",
       "   spike_interface_mPFC  spike_interface_vHPC  spike_interface_BLA  \\\n",
       "4                   5.0                  31.0                 30.0   \n",
       "5                  10.0                  31.0                 30.0   \n",
       "6                   NaN                   NaN                  NaN   \n",
       "7                   2.0                  31.0                 30.0   \n",
       "\n",
       "   spike_interface_LH  spike_interface_MD  \n",
       "4                29.0                28.0  \n",
       "5                29.0                28.0  \n",
       "6                 NaN                 NaN  \n",
       "7                29.0                28.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHANNEL_MAPPING_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding all the brain region to ch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF[\"Subject\"] = CHANNEL_MAPPING_DF[\"Subject\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = all_trials_df.merge(CHANNEL_MAPPING_DF, left_on=\"current_subject\", right_on=\"Subject\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.drop(columns=[col for col in channel_map_and_all_trials_df.columns if \"eib\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.drop(columns=[\"Subject\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>time_stamp_index</th>\n",
       "      <th>video_file</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>video_number</th>\n",
       "      <th>subject_info</th>\n",
       "      <th>competition_closeness</th>\n",
       "      <th>video_name</th>\n",
       "      <th>...</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>trial_outcome</th>\n",
       "      <th>lfp_index</th>\n",
       "      <th>trial_number</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4509412</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>1030879</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>1029</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-1_t1b3L_box1</td>\n",
       "      <td>lose_comp</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>lose</td>\n",
       "      <td>51543</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6909411</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>3430878</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>3425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-1_t1b3L_box1</td>\n",
       "      <td>win_comp</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>win</td>\n",
       "      <td>171543</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9209413</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>5730880</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>5720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-1_t1b3L_box1</td>\n",
       "      <td>win_comp</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>win</td>\n",
       "      <td>286544</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11009410</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>7530877</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>7516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-1_t1b3L_box1</td>\n",
       "      <td>lose_non_comp</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>lose</td>\n",
       "      <td>376543</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12109413</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>8630880</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>8615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-1_t1b3L_box1</td>\n",
       "      <td>win_non_comp</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>win</td>\n",
       "      <td>431544</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time                                      recording_dir  \\\n",
       "0   4509412  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "1   6909411  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "2   9209413  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "3  11009410  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "4  12109413  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "\n",
       "                                      recording_file  time_stamp_index  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...           1030879   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...           3430878   \n",
       "2  20230617_115521_standard_comp_to_omission_D1_s...           5730880   \n",
       "3  20230617_115521_standard_comp_to_omission_D1_s...           7530877   \n",
       "4  20230617_115521_standard_comp_to_omission_D1_s...           8630880   \n",
       "\n",
       "                                          video_file  video_frame  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...         1029   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...         3425   \n",
       "2  20230617_115521_standard_comp_to_omission_D1_s...         5720   \n",
       "3  20230617_115521_standard_comp_to_omission_D1_s...         7516   \n",
       "4  20230617_115521_standard_comp_to_omission_D1_s...         8615   \n",
       "\n",
       "   video_number    subject_info competition_closeness  \\\n",
       "0           1.0  1-1_t1b3L_box1             lose_comp   \n",
       "1           1.0  1-1_t1b3L_box1              win_comp   \n",
       "2           1.0  1-1_t1b3L_box1              win_comp   \n",
       "3           1.0  1-1_t1b3L_box1         lose_non_comp   \n",
       "4           1.0  1-1_t1b3L_box1          win_non_comp   \n",
       "\n",
       "                                          video_name  ... current_subject  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...  ...             1.1   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...  ...             1.1   \n",
       "2  20230617_115521_standard_comp_to_omission_D1_s...  ...             1.1   \n",
       "3  20230617_115521_standard_comp_to_omission_D1_s...  ...             1.1   \n",
       "4  20230617_115521_standard_comp_to_omission_D1_s...  ...             1.1   \n",
       "\n",
       "  trial_outcome lfp_index  trial_number  Cohort  spike_interface_mPFC  \\\n",
       "0          lose     51543             0       2                   5.0   \n",
       "1           win    171543             1       2                   5.0   \n",
       "2           win    286544             2       2                   5.0   \n",
       "3          lose    376543             3       2                   5.0   \n",
       "4           win    431544             4       2                   5.0   \n",
       "\n",
       "   spike_interface_vHPC  spike_interface_BLA  spike_interface_LH  \\\n",
       "0                  31.0                 30.0                29.0   \n",
       "1                  31.0                 30.0                29.0   \n",
       "2                  31.0                 30.0                29.0   \n",
       "3                  31.0                 30.0                29.0   \n",
       "4                  31.0                 30.0                29.0   \n",
       "\n",
       "   spike_interface_MD  \n",
       "0                28.0  \n",
       "1                28.0  \n",
       "2                28.0  \n",
       "3                28.0  \n",
       "4                28.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_map_and_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linking up all LFP calculations with all the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"all_ch_lfp\"] = channel_map_and_all_trials_df[\"recording_file\"].map(recording_name_to_all_ch_lfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a new row for each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_region_col = [col for col in CHANNEL_MAPPING_DF if \"spike_interface\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [col for col in channel_map_and_all_trials_df.columns if col not in brain_region_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spike_interface_mPFC',\n",
       " 'spike_interface_vHPC',\n",
       " 'spike_interface_BLA',\n",
       " 'spike_interface_LH',\n",
       " 'spike_interface_MD']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_region_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in brain_region_col:\n",
    "    channel_map_and_all_trials_df[col] = channel_map_and_all_trials_df[col].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'recording_dir', 'recording_file', 'time_stamp_index',\n",
       "       'video_file', 'video_frame', 'video_number', 'subject_info',\n",
       "       'competition_closeness', 'video_name', 'all_subjects',\n",
       "       'current_subject', 'trial_outcome', 'lfp_index', 'trial_number',\n",
       "       'Cohort', 'spike_interface_mPFC', 'spike_interface_vHPC',\n",
       "       'spike_interface_BLA', 'spike_interface_LH', 'spike_interface_MD',\n",
       "       'all_ch_lfp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"baseline_lfp_timestamp_range\"] = channel_map_and_all_trials_df[\"lfp_index\"].apply(lambda x: (x - TRIAL_DURATION * LFP_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"trial_lfp_timestamp_range\"] = channel_map_and_all_trials_df[\"lfp_index\"].apply(lambda x: (x, x + TRIAL_DURATION * LFP_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"baseline_ephys_timestamp_range\"] = channel_map_and_all_trials_df[\"time_stamp_index\"].apply(lambda x: (x - TRIAL_DURATION * EPHYS_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"trial_ephys_timestamp_range\"] = channel_map_and_all_trials_df[\"time_stamp_index\"].apply(lambda x: (x, x + TRIAL_DURATION * EPHYS_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"baseline_videoframe_range\"] = channel_map_and_all_trials_df[\"video_frame\"].apply(lambda x: (x - TRIAL_DURATION * FRAME_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"trial_videoframe_range\"] = channel_map_and_all_trials_df[\"video_frame\"].apply(lambda x: (x, x + TRIAL_DURATION * FRAME_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spike_interface_mPFC\n",
      "spike_interface_vHPC\n",
      "spike_interface_BLA\n",
      "spike_interface_LH\n",
      "spike_interface_MD\n"
     ]
    }
   ],
   "source": [
    "for col in brain_region_col:\n",
    "    print(col)\n",
    "    channel_map_and_all_trials_df[\"{}_baseline_lfp_trace\".format(col.strip(\"spike_interface\").strip(\"_\"))] = channel_map_and_all_trials_df.apply(lambda row: row[\"all_ch_lfp\"].get_traces(channel_ids=row[col], start_frame=row[\"baseline_lfp_timestamp_range\"][0], end_frame=row[\"baseline_lfp_timestamp_range\"][1]).T[0], axis=1)\n",
    "\n",
    "    channel_map_and_all_trials_df[\"{}_trial_lfp_trace\".format(col.strip(\"spike_interface\").strip(\"_\"))] = channel_map_and_all_trials_df.apply(lambda row: row[\"all_ch_lfp\"].get_traces(channel_ids=row[col], start_frame=row[\"trial_lfp_timestamp_range\"][0], end_frame=row[\"trial_lfp_timestamp_range\"][1]).T[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.to_pickle(\"./proc/lfp_traces_with_trial_info.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD code below for melting the dataframe into multiple rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df = channel_map_and_all_trials_df.melt(id_vars=id_cols ,value_vars=brain_region_col, var_name='brain_region', value_name='channel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_DURATION * LFP_SAMPLING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df[\"baseline_lfp_timestamp_range\"] = melted_channel_map_and_all_trials_df[\"lfp_index\"].apply(lambda x: (x - TRIAL_DURATION * LFP_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df[\"trial_lfp_timestamp_range\"] = melted_channel_map_and_all_trials_df[\"lfp_index\"].apply(lambda x: (x, x + TRIAL_DURATION * LFP_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the traces for each trial for each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df[\"channel\"] = melted_channel_map_and_all_trials_df[\"channel\"].astype(int).astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df.drop(columns=[\"all_ch_lfp\"], errors=\"ignore\").to_csv(\"./proc/per_brain_region_trial_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df[\"baseline_lfp_trace\"] = melted_channel_map_and_all_trials_df.apply(lambda row: \n",
    "row[\"all_ch_lfp\"].get_traces(channel_ids=[row[\"channel\"]], start_frame=row[\"baseline_lfp_timestamp_range\"][0], end_frame=row[\"baseline_lfp_timestamp_range\"][1]).T[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df[\"trial_lfp_trace\"] = melted_channel_map_and_all_trials_df.apply(lambda row: \n",
    "row[\"all_ch_lfp\"].get_traces(channel_ids=[row[\"channel\"]], start_frame=row[\"trial_lfp_timestamp_range\"][0], end_frame=row[\"trial_lfp_timestamp_range\"][1]).T[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_channel_map_and_all_trials_df.to_pickle(\"./proc/lfp_traces_with_trial_info.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
