{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Time Stamp Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notebook that extracts the timestamps and gets the time that tones played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path\n",
    "sys.path.append('../../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trodes.read_exported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "- Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs and Required data loading\n",
    "- input variable names are in all caps snake case\n",
    "- Whenever an input changes or is used for processing \n",
    "- The variables are all lower in snake case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Path of the directory that contains the Spike Gadgets recording and the exported timestamp files\n",
    "# Exported with this tool https://docs.spikegadgets.com/en/latest/basic/ExportFunctions.html\n",
    "# Export these files:\n",
    "    # -raw – Continuous raw band export.\n",
    "    # -dio – Digital IO channel state change export.\n",
    "    # -analogio – Continuous analog IO export.\n",
    "INPUT_DIR = \"/scratch/back_up/reward_competition_extention/data\"\n",
    "INPUT_GLOB = \"/scratch/back_up/reward_competition_extention/data/*/*/*.rec\"\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs\n",
    "TONE_DIN = \"dio_ECU_Din1\"\n",
    "TONE_STATE = 1\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_PREFIX = \"pilot2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw directory\n",
    "- raw_group0.dat\n",
    "    - voltage_value: Array with voltage measurement for each channel at each timestamp\n",
    "- timestamps.dat\n",
    "    - voltage_time_stamp: The time stamp of each voltage measurement\n",
    "\n",
    "parent directory\n",
    "- 1.videoTimeStamps.cameraHWSync\n",
    "    - frame_number: Calculated by getting the index of each video time stamp tuple \n",
    "    - PosTimestamp: The time stamp of each video frame\n",
    "    - HWframeCount: Unknown value. Starts at 30742 and increases by 1 for each tuple  \n",
    "    - HWTimestamp: Unknown value. All zeroes\n",
    "    - video_time: Calculated by dividing the frame number by the fps(frames per second) \n",
    "    - video_seconds: video_time, but rounded to seconds  \t\n",
    "    - These are filled in versions of the above collumns with the value from the most recent previous cell\n",
    "        - filled_PosTimestamp \t\n",
    "        - filledHWframeCount \t\n",
    "        - filled_frame_number \t\n",
    "        - filled_video_time \t\n",
    "        - filled_video_seconds \t\n",
    "\n",
    "DIO directory\n",
    "- dio_ECU_Din1.dat\n",
    "    - time: The time stamp the corresponds to the DIN input\n",
    "    - state: Binary state of whether there is input from DIN or not \t\n",
    "    - trial_number: Calculated by adding 1 to every time there is a DIN input\n",
    "    - These are filled in versions of the above collumns with the value from the most recent previous cell\n",
    "        - filled_state \t\n",
    "        - filled_trial_number\n",
    "\n",
    "ss_output directory (Spike sorting with Spike interface)\n",
    "- firings.npz\n",
    "    - unit_id: All the units that had a spike train for the given timestamp \t\n",
    "    - number_of_units: Calculated by counting the number of units that had a spike train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- function names are short and in snake case all lowercase\n",
    "- a function name should be unique but does not have to describe the function\n",
    "- doc strings describe functions not function names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_index(sorted_list=None, target=0):\n",
    "    \"\"\"\n",
    "    Returns the index of the number in the sorted list that is closest to the target.\n",
    "\n",
    "    This function performs a binary search on a sorted list to find the closest number to \n",
    "    a given target. If the target exists in the list, its index is returned. If not, the \n",
    "    function will return the index of the number that's closest to the target.\n",
    "\n",
    "    Parameters:\n",
    "    - sorted_list (list[int or float]): A sorted list of numbers.\n",
    "    - target (int or float): The target number to find the closest value to.\n",
    "\n",
    "    Returns:\n",
    "    - int: The index of the closest number in the sorted list to the target. \n",
    "           If the sorted list is empty, returns None.\n",
    "\n",
    "    Example:\n",
    "    >>> sorted_nums = [1, 3, 5, 8, 10, 15, 18, 20, 24, 27, 30]\n",
    "    >>> find_closest_index(sorted_nums, 6)\n",
    "    2\n",
    "\n",
    "    Note:\n",
    "    The list should be sorted in ascending order.\n",
    "    \"\"\"\n",
    "    \n",
    "    if sorted_list is None:\n",
    "        return None\n",
    "    if target <= sorted_list[0]:\n",
    "        return 0\n",
    "    if target >= sorted_list[-1]:\n",
    "        return len(sorted_list) - 1\n",
    "\n",
    "    # Binary search\n",
    "    left, right = 0, len(sorted_list) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "\n",
    "        if sorted_list[mid] == target:\n",
    "            return mid\n",
    "        elif sorted_list[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "\n",
    "    # After binary search, the target will be between sorted_list[right] and sorted_list[left]\n",
    "    # We compare the two to see which one is closer to the target and return its index\n",
    "    if abs(sorted_list[left] - target) < abs(sorted_list[right] - target):\n",
    "        return left\n",
    "    else:\n",
    "        return right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_session_files = glob.glob(INPUT_GLOB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/back_up/reward_competition_extention/data/novel_agent/2023_06_29/20230629_111937_standard_comp_to_novel_agent_D2_subj_1-1vs2-1and1-4vs2-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/novel_agent/2023_06_30/20230630_115506_standard_comp_to_novel_agent_D3_subj_1-4vs2-1and1-2vs2-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/novel_agent/2023_06_28/20230628_111202_standard_comp_to_novel_agent_D1_subj_1-1vs2-2and1-2vs2-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/standard/2023_06_14/20230614_114041_standard_comp_to_training_D3_subj_1-1_and_1-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/standard/2023_06_14/20230614_115827_standard_comp_to_training_D3_subj_2-1_and_2-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/standard/2023_06_13/20230613_110126_standard_comp_to_training_D2_subj_2-4_and_2-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/standard/2023_06_13/20230613_105657_standard_comp_to_training_D2_subj_1-1_and_1-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/standard/2023_06_12/20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/standard/2023_06_12/20230612_101935_standard_comp_to_training_D1_subj_2-2_and_2-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/standard/2023_06_12/20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/standard/2023_06_16/20230616_111904_standard_comp_to_training_D4_subj_1-4_and_1-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/standard/2023_06_16/20230616_111904_standard_comp_to_training_D4_subj_2-1_and_2-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221203_154800_omission_and_competition_subject_6_4_and_6_1.rec/20221203_154800_omission_and_competition_subject_6_4_and_6_1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221203_154800_omission_and_competition_subject_6_4_and_6_1.rec/20221203_154800_omission_and_competition_subject_6_1_top_1_base_3_merged.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221122_161341_omission_subject_6_1_and_6_3.rec/20221122_161341_omission_subject_6_1_and_6_3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221122_161341_omission_subject_6_1_and_6_3.rec/20221122_161341_omission_subject_6_1_top_4_base_2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221125_152723_competition_subject_6_1_and_6_2.rec/20221125_152723_competition_subject_6_1_top_3_base_2_merged.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221125_152723_competition_subject_6_1_and_6_2.rec/20221125_152723_competition_subject_6_1_and_6_2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221125_144832_omission_subject_6_1_and_6_2.rec/20221125_144832_omission_subject_6_1_and_6_2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221125_144832_omission_subject_6_1_and_6_2.rec/20221125_144832_omission_subject_6_1_top_1_base_2_merged.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221122_164720_competition_subject_6_1_and_6_3.rec/20221122_164720_competition_6_1_and_6_3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221122_164720_competition_subject_6_1_and_6_3.rec/20221122_164720_competition_6_1_top_3__base_3_merged.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221215_145401_comp_amd_om_6_1_and_6_3.rec/20221215_145401_comp_amd_om_6_1_and_6_3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221215_145401_comp_amd_om_6_1_and_6_3.rec/20221215_145401_comp_amd_om_6_1_top_4_base_3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221202_134600_omission_and_competition_subject_6_1_and_6_2.rec/20221202_134600_omission_and_competition_subject_6_1_top_2_base_3_merged.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221202_134600_omission_and_competition_subject_6_1_and_6_2.rec/20221202_134600_omission_and_competition_subject_6_1_and_6_2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221123_113957_omission_subject_6_1_and_6_4.rec/20221123_113957_omission_subject_6_1_top_4_base_2_merged.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221123_113957_omission_subject_6_1_and_6_4.rec/20221123_113957_omission_subject_6_1_and_6_4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221214_125409_om_and_comp_6_1_and_6_3.rec/20221214_125409_om_and_comp_6_1_top_1_base_2_vs_6_3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221214_125409_om_and_comp_6_1_and_6_3.rec/20221214_125409_om_and_comp_6_1_and_6_3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221123_122652_competition_subject_6_1_and_6_4.rec/20221123_122652_competition_subject_6_1_top_3_base_3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/pilot/20221123_122652_competition_subject_6_1_and_6_4.rec/20221123_122652_competition_subject_6_1_and_6_4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_17/20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_17/20230617_115641_standard_comp_to_omission_D1_subj_2-2_and_2-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_21/20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_20/20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_18/20230618_100646_standard_comp_to_omission_D2_subj_2-4_and_2-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_18/20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_19/20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_19/20230619_115334_standard_comp_to_omission_D3_subj_2-2_and_2-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/both_rewarded/2023_06_25/20230625_112913_standard_comp_to_both_rewarded_D4_subj_1-1_and_1-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/both_rewarded/2023_06_24/20230624_110052_standard_comp_to_alone_D3_subj_2-2_and_2-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/both_rewarded/2023_06_24/20230624_105855_standard_comp_to_both_rewarded_D3_subj_1-2_and_1-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/both_rewarded/2023_06_22/20230622_111445_standard_comp_to_alone_D1_subj_2-4_and_2-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/both_rewarded/2023_06_22/20230622_110832_standard_comp_to_both_rewarded_D1_subj_1-1_and_1-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/both_rewarded/2023_06_23/20230623_115501_standard_comp_to_alone_D2_subj_2-1_and_2-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/both_rewarded/2023_06_23/20230623_114932_standard_comp_to_both_rewarded_D2_subj_1-4_and_1-1.rec']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_session_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP 1: Extracting all the Trodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting all the data from all the exported Trodes files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Session: 20230629_111937_standard_comp_to_novel_agent_D2_subj_1-1vs2-1and1-4vs2-2\n",
      "Skipping file 20230629_111937_standard_comp_to_novel_agent_D2_subj_1-1v1-4and2-1_merged.timestampoffset.txt due to error: Settings format not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nancy/projects/reward_competition_extention/results/2023_08_08_trial_labeling/../../src/trodes/read_exported.py:62: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  return np.dtype(dtype_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Session: 20230630_115506_standard_comp_to_novel_agent_D3_subj_1-4vs2-1and1-2vs2-2\n",
      "Skipping file 20230630_115506_standard_comp_to_novel_agent_D3_subj_1-2vs1-4and2-2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230628_111202_standard_comp_to_novel_agent_D1_subj_1-1vs2-2and1-2vs2-1\n",
      "Skipping file 20230628_111202_standard_comp_to_novel_agent_D1_subj_1-2vs1-1and2-1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230628_111202_standard_comp_to_novel_agent_D1_subj_1-1vs1-2and2-2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230614_114041_standard_comp_to_training_D3_subj_1-1_and_1-2\n",
      "Skipping file 20230614_114041_standard_comp_to_training_D3_subj_1-2_t2b2L_box2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230614_114041_standard_comp_to_training_D3_subj_1-1_t1b3L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230614_115827_standard_comp_to_training_D3_subj_2-1_and_2-4\n",
      "Current Session: 20230613_110126_standard_comp_to_training_D2_subj_2-4_and_2-2\n",
      "Current Session: 20230613_105657_standard_comp_to_training_D2_subj_1-1_and_1-4\n",
      "Skipping file 20230613_105657_standard_comp_to_training_D2_subj_1-4_t4b3L_box2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230613_105657_standard_comp_to_training_D2_subj_1-1_t1b2L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3\n",
      "Skipping file 20230612_101430_standard_comp_to_training_D1_subj_1-3_t3b3L_box2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230612_101430_standard_comp_to_training_D1_subj_1-4_t4b2L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230612_101935_standard_comp_to_training_D1_subj_2-2_and_2-1\n",
      "Current Session: 20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230616_111904_standard_comp_to_training_D4_subj_1-4_and_1-2\n",
      "Skipping file 20230616_111904_standard_comp_to_training_D4_subj_1-4_t4b3L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230616_111904_standard_comp_to_training_D4_subj_1-2_t2b2L_box2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230616_111904_standard_comp_to_training_D4_subj_2-1_and_2-2\n",
      "Current Session: 20221203_154800_omission_and_competition_subject_6_4_and_6_1\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221203_154800_omission_and_competition_subject_6_4_and_6_1.rec/20221203_154800_omission_and_competition_subject_6_4_and_6_1.rec'\n",
      "Current Session: 20221203_154800_omission_and_competition_subject_6_1_top_1_base_3_merged\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221203_154800_omission_and_competition_subject_6_4_and_6_1.rec/20221203_154800_omission_and_competition_subject_6_1_top_1_base_3_merged.rec'\n",
      "Current Session: 20221122_161341_omission_subject_6_1_and_6_3\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221122_161341_omission_subject_6_1_and_6_3.rec/20221122_161341_omission_subject_6_1_and_6_3.rec'\n",
      "Current Session: 20221122_161341_omission_subject_6_1_top_4_base_2\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221122_161341_omission_subject_6_1_and_6_3.rec/20221122_161341_omission_subject_6_1_top_4_base_2.rec'\n",
      "Current Session: 20221125_152723_competition_subject_6_1_top_3_base_2_merged\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221125_152723_competition_subject_6_1_and_6_2.rec/20221125_152723_competition_subject_6_1_top_3_base_2_merged.rec'\n",
      "Current Session: 20221125_152723_competition_subject_6_1_and_6_2\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221125_152723_competition_subject_6_1_and_6_2.rec/20221125_152723_competition_subject_6_1_and_6_2.rec'\n",
      "Current Session: 20221125_144832_omission_subject_6_1_and_6_2\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221125_144832_omission_subject_6_1_and_6_2.rec/20221125_144832_omission_subject_6_1_and_6_2.rec'\n",
      "Current Session: 20221125_144832_omission_subject_6_1_top_1_base_2_merged\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221125_144832_omission_subject_6_1_and_6_2.rec/20221125_144832_omission_subject_6_1_top_1_base_2_merged.rec'\n",
      "Current Session: 20221122_164720_competition_6_1_and_6_3\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221122_164720_competition_subject_6_1_and_6_3.rec/20221122_164720_competition_6_1_and_6_3.rec'\n",
      "Current Session: 20221122_164720_competition_6_1_top_3__base_3_merged\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221122_164720_competition_subject_6_1_and_6_3.rec/20221122_164720_competition_6_1_top_3__base_3_merged.rec'\n",
      "Current Session: 20221215_145401_comp_amd_om_6_1_and_6_3\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221215_145401_comp_amd_om_6_1_and_6_3.rec/20221215_145401_comp_amd_om_6_1_and_6_3.rec'\n",
      "Current Session: 20221215_145401_comp_amd_om_6_1_top_4_base_3\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221215_145401_comp_amd_om_6_1_and_6_3.rec/20221215_145401_comp_amd_om_6_1_top_4_base_3.rec'\n",
      "Current Session: 20221202_134600_omission_and_competition_subject_6_1_top_2_base_3_merged\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221202_134600_omission_and_competition_subject_6_1_and_6_2.rec/20221202_134600_omission_and_competition_subject_6_1_top_2_base_3_merged.rec'\n",
      "Current Session: 20221202_134600_omission_and_competition_subject_6_1_and_6_2\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221202_134600_omission_and_competition_subject_6_1_and_6_2.rec/20221202_134600_omission_and_competition_subject_6_1_and_6_2.rec'\n",
      "Current Session: 20221123_113957_omission_subject_6_1_top_4_base_2_merged\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221123_113957_omission_subject_6_1_and_6_4.rec/20221123_113957_omission_subject_6_1_top_4_base_2_merged.rec'\n",
      "Current Session: 20221123_113957_omission_subject_6_1_and_6_4\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221123_113957_omission_subject_6_1_and_6_4.rec/20221123_113957_omission_subject_6_1_and_6_4.rec'\n",
      "Current Session: 20221214_125409_om_and_comp_6_1_top_1_base_2_vs_6_3\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221214_125409_om_and_comp_6_1_and_6_3.rec/20221214_125409_om_and_comp_6_1_top_1_base_2_vs_6_3.rec'\n",
      "Current Session: 20221214_125409_om_and_comp_6_1_and_6_3\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221214_125409_om_and_comp_6_1_and_6_3.rec/20221214_125409_om_and_comp_6_1_and_6_3.rec'\n",
      "Current Session: 20221123_122652_competition_subject_6_1_top_3_base_3\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221123_122652_competition_subject_6_1_and_6_4.rec/20221123_122652_competition_subject_6_1_top_3_base_3.rec'\n",
      "Current Session: 20221123_122652_competition_subject_6_1_and_6_4\n",
      "[Errno 20] Not a directory: '/scratch/back_up/reward_competition_extention/data/pilot/20221123_122652_competition_subject_6_1_and_6_4.rec/20221123_122652_competition_subject_6_1_and_6_4.rec'\n",
      "Current Session: 20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2\n",
      "Skipping file 20230617_115521_standard_comp_to_omission_D1_subj_1-2_t2b2L_box2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230617_115641_standard_comp_to_omission_D1_subj_2-2_and_2-4\n",
      "Current Session: 20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2\n",
      "Skipping file 20230621_111240_standard_comp_to_omission_D5_subj_1-4_t3b3L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1\n",
      "Skipping file 20230620_114347_standard_comp_to_omission_D4_subj_1-1_t1b2L_box_2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230620_114347_standard_comp_to_omission_D4_subj_1-2_t3b3L_box_1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230618_100646_standard_comp_to_omission_D2_subj_2-4_and_2-1\n",
      "Current Session: 20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1\n",
      "Skipping file 20230618_100636_standard_comp_to_omission_D2_subj_1_4_t4b3L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230618_100636_standard_comp_to_omission_D2_subj_1_1_t1b2L_box2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4\n",
      "Skipping file 20230619_115321_standard_comp_to_omission_D3_subj_1-4_t3b3L_box2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230619_115334_standard_comp_to_omission_D3_subj_2-2_and_2-1\n",
      "Current Session: 20230625_112913_standard_comp_to_both_rewarded_D4_subj_1-1_and_1-4\n",
      "Skipping file 20230625_112913_standard_comp_to_both_rewarded_D4_subj_1-4_t3b3L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230625_112913_standard_comp_to_both_rewarded_D4_subj_1-1_t1b2L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Current Session: 20230624_110052_standard_comp_to_alone_D3_subj_2-2_and_2-1\n",
      "Current Session: 20230624_105855_standard_comp_to_both_rewarded_D3_subj_1-2_and_1-4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     session_basename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(session_path))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent Session: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(session_basename))\n\u001b[0;32m----> 9\u001b[0m     session_to_dir[session_basename] \u001b[38;5;241m=\u001b[39m \u001b[43mtrodes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_exported\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morganize_all_trodes_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "File \u001b[0;32m/nancy/projects/reward_competition_extention/results/2023_08_08_trial_labeling/../../src/trodes/read_exported.py:177\u001b[0m, in \u001b[0;36morganize_all_trodes_export\u001b[0;34m(dir_path)\u001b[0m\n\u001b[1;32m    175\u001b[0m     sub_dir_name_suffix \u001b[38;5;241m=\u001b[39m sub_dir_name_parts[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# Organize the Trodes files in the subdirectory and store the results\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m     result[sub_dir_name_prefix][sub_dir_name_suffix] \u001b[38;5;241m=\u001b[39m \u001b[43morganize_single_trodes_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_dir_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing subdirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msub_dir_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/nancy/projects/reward_competition_extention/results/2023_08_08_trial_labeling/../../src/trodes/read_exported.py:142\u001b[0m, in \u001b[0;36morganize_single_trodes_export\u001b[0;34m(dir_path, skip_raw_group0)\u001b[0m\n\u001b[1;32m    140\u001b[0m     sub_dir_name \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# Parse Trodes file and store the data\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     result[sub_dir_name] \u001b[38;5;241m=\u001b[39m \u001b[43mread_trodes_extracted_data_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Skip files that cause errors during parsing\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/nancy/projects/reward_competition_extention/results/2023_08_08_trial_labeling/../../src/trodes/read_exported.py:113\u001b[0m, in \u001b[0;36mread_trodes_extracted_data_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Read the remaining data from the file using the parsed data type\u001b[39;00m\n\u001b[1;32m    112\u001b[0m dt \u001b[38;5;241m=\u001b[39m parse_fields(fields_text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfields\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 113\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m fields_text\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: data})\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fields_text\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "session_to_dir = {}\n",
    "# Going through each session recording\n",
    "# Which includes all the recordings from all the miniloggers and cameras\n",
    "for session_path in all_session_files:   \n",
    "    try:\n",
    "        session_basename = os.path.splitext(os.path.basename(session_path))[0]\n",
    "        print(\"Current Session: {}\".format(session_basename))\n",
    "\n",
    "        session_to_dir[session_basename] = trodes.read_exported.organize_all_trodes_export(session_path)\n",
    "    except Exception as e: \n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP 2: Extracting the timestamps for the raw ephys recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_to_din_state_df = {}\n",
    "for session, file_to_data in filtered_session_to_dir.items():\n",
    "    all_recording_din_state_df = []\n",
    "    for recording_name, subdir_dict in file_to_data.items():\n",
    "        print(recording_name)\n",
    "        current_recording_din_state_df = []\n",
    "\n",
    "        try:\n",
    "            voltage_timestamp_array = file_to_data[recording_name][\"raw\"][\"timestamps\"][\"data\"]\n",
    "            for key, value in file_to_data[recording_name][\"DIO\"].items():\n",
    "                if \"in\" in key:\n",
    "                    print(key)\n",
    "                    din_state_array = file_to_data[recording_name][\"DIO\"][key][\"data\"]\n",
    "                    current_din_state_df = pd.DataFrame(din_state_array)\n",
    "                    current_din_state_df[\"recording_dir\"] = session\n",
    "                    current_din_state_df[\"recording_file\"] = recording_name\n",
    "                    current_din_state_df[\"din\"] = key\n",
    "                    current_recording_din_state_df.append(current_din_state_df)\n",
    "                    plt.plot([tup[0] for tup in din_state_array], [tup[1] for tup in din_state_array])\n",
    "                    plt.xlabel(\"Timestamp\")\n",
    "                    plt.ylabel(\"State\")\n",
    "                    plt.title(\"Din State Change against Timestamps for {} in {}\".format(key, recording_name))\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "            concatted_per_recording_din_state_df = pd.concat(current_recording_din_state_df).sort_values(by=[\"recording_file\", \"din\"]).reset_index(drop=True)\n",
    "            concatted_per_recording_din_state_df[\"time_stamp_index\"] = concatted_per_recording_din_state_df[\"time\"] - voltage_timestamp_array[0][0]\n",
    "            all_recording_din_state_df.append(concatted_per_recording_din_state_df)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    concatted_all_recording_din_state_df = pd.concat(all_recording_din_state_df)\n",
    "    session_to_din_state_df[session] = concatted_all_recording_din_state_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP 3 Adding the video timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_din_state_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_to_din_with_frames_df = {}\n",
    "for session_path in all_session_files:   \n",
    "    try:\n",
    "        session_basename = os.path.splitext(os.path.basename(session_path))[0]\n",
    "        print(\"Current Session: {}\".format(session_basename))\n",
    "        file_to_video_timestamps = {}\n",
    "        for video_timestamps in glob.glob(os.path.join(session_path, \"*cameraHWSync\")):\n",
    "            video_basename = os.path.basename(video_timestamps)\n",
    "            print(\"Current Video Name: {}\".format(video_basename))\n",
    "            timestamp_array = trodes.read_exported.read_trodes_extracted_data_file(video_timestamps)[\"data\"][\"PosTimestamp\"]\n",
    "            file_to_video_timestamps[video_basename] = timestamp_array\n",
    "            session_to_din_state_df[session_basename][os.path.basename(video_timestamps)] = session_to_din_state_df[session_basename][\"time\"].apply(lambda x: find_closest_index(sorted_list=timestamp_array, target=x))        \n",
    "        \n",
    "        # Find the maximum length of the arrays in the dictionary\n",
    "        max_length = max(map(len, file_to_video_timestamps.values()))\n",
    "        \n",
    "        # Pad each array with NaN values to make them all the same length\n",
    "        padded_data = {k: np.pad(v, (0, max_length - len(v)), mode='constant', constant_values=np.nan) for k, v in file_to_video_timestamps.items()}\n",
    "        \n",
    "        # Convert the padded data to a dataframe\n",
    "        session_to_din_with_frames_df[session_basename] = pd.DataFrame(padded_data)\n",
    "        session_to_din_with_frames_df[session_basename].to_csv(os.path.join(OUTPUT_DIR, \"{}.frame_to_timestamps.csv\".format(session_basename)))\n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_din_state_df['20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_din_with_frames_df['20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP 4: Combining the video columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_tone_stamp_df = {}\n",
    "for session, timestamps_df in session_to_din_state_df.items():\n",
    "    current_timestamps_df = timestamps_df[(timestamps_df[\"din\"] == TONE_DIN) & (timestamps_df[\"state\"] == TONE_STATE)].reset_index(drop=True)\n",
    "    camera_col = [col for col in current_timestamps_df.columns if \"cameraHWSync\" in col]\n",
    "    id_col = [col for col in current_timestamps_df.columns if \"cameraHWSync\" not in col]\n",
    "    \n",
    "    current_timestamps_df = current_timestamps_df.melt(id_vars=id_col, value_vars=camera_col, var_name='video_file', value_name='video_frame')\n",
    "    current_timestamps_df[\"video_number\"] = current_timestamps_df[\"video_file\"].apply(lambda x: x.strip(\"videoTimeStamps.cameraHWSync\").split(\".\")[-1])\n",
    "    current_timestamps_df[\"subject_info\"] = current_timestamps_df[\"recording_file\"].apply(lambda x: x.split(\"subj\")[-1].strip(\"merged\").strip(\"_\"))\n",
    "    current_timestamps_df[\"condition\"] = np.nan\n",
    "    session_to_tone_stamp_df[session]  = current_timestamps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_tone_stamp_df[session]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df = pd.concat(session_to_tone_stamp_df.values()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df.to_csv(os.path.join(OUTPUT_DIR, \"{}_tone_timestamp.csv\".format(OUTPUT_PREFIX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatted_all_recording_din_state_df"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
