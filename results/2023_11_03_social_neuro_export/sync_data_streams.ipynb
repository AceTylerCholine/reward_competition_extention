{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Notebook 1: Extract Z-scored LFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import os\n",
    "import glob\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.cm as cm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path\n",
    "sys.path.append('../../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trodes.read_exported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF = pd.read_excel(\"../../data/channel_mapping.xlsx\")\n",
    "TONE_TIMESTAMP_DF = pd.read_excel(\"../../data/rce_tone_timestamp.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_DIN = \"dio_ECU_Din1\"\n",
    "TONE_STATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPHYS_SAMPLING_RATE = 20000\n",
    "LFP_SAMPLING_RATE = 1000\n",
    "TRIAL_DURATION = 10\n",
    "FRAME_RATE = 22\n",
    "ECU_STREAM_ID = \"ECU\"\n",
    "TRODES_STREAM_ID = \"trodes\"\n",
    "LFP_FREQ_MIN = 0.5\n",
    "LFP_FREQ_MAX = 300\n",
    "ELECTRIC_NOISE_FREQ = 60\n",
    "RECORDING_EXTENTION = \"*.rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SESSION_DIR = glob.glob(\"/scratch/back_up/reward_competition_extention/data/omission/2023_06_18/*.rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = pd.read_excel(\"../../data/video_to_frame_and_subject.xlsx\")\n",
    "SLEAP_DIR = \"/scratch/back_up/reward_competition_extention/proc/id_corrected\"\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs\n",
    "MED_PC_WIDTH = 29.5\n",
    "MED_PC_HEIGHT = 24\n",
    "FRAME_RATE = 22"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "TONE_TIMESTAMP_DF = pd.read_pickle(\"./proc/trial_metadata.pkl\")\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = pd.read_excel(\"../../data/video_to_frame_and_subject.xlsx\")\n",
    "SLEAP_DIR = \"/scratch/back_up/reward_competition_extention/proc/id_corrected\"\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs\n",
    "MED_PC_WIDTH = 29.5\n",
    "MED_PC_HEIGHT = 24\n",
    "FRAME_RATE = 22\n",
    "VELOCITY_WINDOW_SIZE = FRAME_RATE\n",
    "ROLLING_AVERAGE_WINDOW_SIZE = FRAME_RATE // 2\n",
    "TRIAL_DURATION = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sorted_index(group, value_column='Value', index_column='SortedIndex'):\n",
    "    \"\"\" \n",
    "    Computes the index of each row's value within its sorted group.\n",
    "\n",
    "    Parameters:\n",
    "    - group (pd.DataFrame): A group of data.\n",
    "    - value_column (str): Name of the column containing the values to be sorted.\n",
    "    - index_column (str): Name of the new column that will contain the indices.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The group with an additional column containing the indices.\n",
    "    \"\"\"\n",
    "    sorted_values = sorted(list(set(group[value_column].tolist())))\n",
    "    group[index_column] = group[value_column].apply(lambda x: sorted_values.index(x))\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_index(sorted_list=None, target=0):\n",
    "    \"\"\"\n",
    "    Returns the index of the number in the sorted list that is closest to the target.\n",
    "\n",
    "    This function performs a binary search on a sorted list to find the closest number to \n",
    "    a given target. If the target exists in the list, its index is returned. If not, the \n",
    "    function will return the index of the number that's closest to the target.\n",
    "\n",
    "    Parameters:\n",
    "    - sorted_list (list[int or float]): A sorted list of numbers.\n",
    "    - target (int or float): The target number to find the closest value to.\n",
    "\n",
    "    Returns:\n",
    "    - int: The index of the closest number in the sorted list to the target. \n",
    "           If the sorted list is empty, returns None.\n",
    "\n",
    "    Example:\n",
    "    >>> sorted_nums = [1, 3, 5, 8, 10, 15, 18, 20, 24, 27, 30]\n",
    "    >>> find_closest_index(sorted_nums, 6)\n",
    "    2\n",
    "\n",
    "    Note:\n",
    "    The list should be sorted in ascending order.\n",
    "    \"\"\"\n",
    "    \n",
    "    if sorted_list is None:\n",
    "        return None\n",
    "    if target <= sorted_list[0]:\n",
    "        return 0\n",
    "    if target >= sorted_list[-1]:\n",
    "        return len(sorted_list) - 1\n",
    "\n",
    "    # Binary search\n",
    "    left, right = 0, len(sorted_list) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "\n",
    "        if sorted_list[mid] == target:\n",
    "            return mid\n",
    "        elif sorted_list[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "\n",
    "    # After binary search, the target will be between sorted_list[right] and sorted_list[left]\n",
    "    # We compare the two to see which one is closer to the target and return its index\n",
    "    if abs(sorted_list[left] - target) < abs(sorted_list[right] - target):\n",
    "        return left\n",
    "    else:\n",
    "        return right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleap_tracks_from_h5(filename):\n",
    "    \"\"\"\n",
    "    Retrieve pose tracking data (tracks) from a SLEAP-generated h5 file.\n",
    "    \n",
    "    This function is intended for use with Pandas' apply method on columns containing filenames.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the SLEAP h5 file containing pose tracking data.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A transposed version of the 'tracks' dataset in the provided h5 file.\n",
    "        \n",
    "    Example:\n",
    "    --------\n",
    "    df['tracks'] = df['filename_column'].apply(get_sleap_tracks_from_h5)\n",
    "    \n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        return f[\"tracks\"][:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleap_track_names_from_h5(filename):\n",
    "    \"\"\"\n",
    "    Retrieve the names of tracked features from a SLEAP-generated h5 file.\n",
    "    \n",
    "    This function is intended for use with Pandas' apply method on columns containing filenames.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    filename : str\n",
    "        Path to the SLEAP h5 file containing pose tracking data.\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    h5py.Dataset\n",
    "        The 'track_names' dataset in the provided h5 file, representing the names of the tracked features.\n",
    "        \n",
    "    Example:\n",
    "    --------\n",
    "    df['track_names'] = df['filename_column'].apply(get_sleap_track_names_from_h5)\n",
    "    \n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        return [item.tobytes().decode('utf-8') for item in f[\"track_names\"][:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_names_from_sleap(filename):\n",
    "    \"\"\"\n",
    "    Retrieve node names from a SLEAP h5 file.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): Path to the SLEAP h5 file.\n",
    "\n",
    "    Returns:\n",
    "    - list of str: List of node names.\n",
    "    \"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        return [n.decode() for n in f[\"node_names\"][:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_missing(Y, kind=\"linear\"):\n",
    "    \"\"\"Fills missing values independently along each dimension after the first.\"\"\"\n",
    "\n",
    "    # Store initial shape.\n",
    "    initial_shape = Y.shape\n",
    "\n",
    "    # Flatten after first dim.\n",
    "    Y = Y.reshape((initial_shape[0], -1))\n",
    "\n",
    "    # Interpolate along each slice.\n",
    "    for i in range(Y.shape[-1]):\n",
    "        y = Y[:, i]\n",
    "\n",
    "        # Build interpolant.\n",
    "        x = np.flatnonzero(~np.isnan(y))\n",
    "        f = interp1d(x, y[x], kind=kind, fill_value=np.nan, bounds_error=False)\n",
    "\n",
    "        # Fill missing\n",
    "        xq = np.flatnonzero(np.isnan(y))\n",
    "        y[xq] = f(xq)\n",
    "        \n",
    "        # Fill leading or trailing NaNs with the nearest non-NaN values\n",
    "        mask = np.isnan(y)\n",
    "        y[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), y[~mask])\n",
    "\n",
    "        # Save slice\n",
    "        Y[:, i] = y\n",
    "\n",
    "    # Restore to initial shape.\n",
    "    Y = Y.reshape(initial_shape)\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_velocity(node_loc, window_size=25, polynomial_order=3):\n",
    "    \"\"\"\n",
    "    Calculate the velocity of tracked nodes from pose data.\n",
    "    \n",
    "    The function utilizes the Savitzky-Golay filter to smooth the data and compute the velocity.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    node_loc : numpy.ndarray\n",
    "        The location of nodes, represented as an array of shape [frames, 2]. \n",
    "        Each row represents x and y coordinates for a particular frame.\n",
    "        \n",
    "    window_size : int, optional\n",
    "        The size of the window used for the Savitzky-Golay filter. \n",
    "        Represents the number of consecutive data points used when smoothing the data.\n",
    "        Default is 25.\n",
    "        \n",
    "    polynomial_order : int, optional\n",
    "        The order of the polynomial fit to the data within the Savitzky-Golay filter window.\n",
    "        Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The velocity for each frame, calculated from the smoothed x and y coordinates.\n",
    "    \n",
    "    \"\"\"\n",
    "    node_loc_vel = np.zeros_like(node_loc)\n",
    "    \n",
    "    # For each coordinate (x and y), smooth the data and calculate the derivative (velocity)\n",
    "    for c in range(node_loc.shape[-1]):\n",
    "        node_loc_vel[:, c] = savgol_filter(node_loc[:, c], window_size, polynomial_order, deriv=1)\n",
    "    \n",
    "    # Calculate the magnitude of the velocity vectors for each frame\n",
    "    node_vel = np.linalg.norm(node_loc_vel, axis=1)\n",
    "\n",
    "    return node_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sleap_data(filename):\n",
    "    \"\"\"\n",
    "    Extracts coordinates, names of body parts, and track names from a SLEAP file.\n",
    "    \n",
    "    Parameters:\n",
    "    - filename (str): Path to the SLEAP file.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: A tuple containing the following elements:\n",
    "        * location (numpy.ndarray): Array containing the coordinates.\n",
    "        * node_names (list of str): List of body part names.\n",
    "        * track_names (list of str): List of track names.\n",
    "    \n",
    "    Example:\n",
    "    >>> location, node_names, track_names = extract_sleap_data(\"path/to/sleap/file.h5\")\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        result[\"location\"] = f[\"tracks\"][:].T\n",
    "        result[\"node_names\"] = [n.decode() for n in f[\"node_names\"][:]]\n",
    "        result[\"track_names\"] = [n.decode() for n in f[\"track_names\"][:]]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_dimension_in_array(arr, dimension=0, ratio=1):\n",
    "    \"\"\"\n",
    "    Rescale values of a specified dimension in a 3D numpy array for the entire array.\n",
    "    \n",
    "    Parameters:\n",
    "    - arr (numpy.ndarray): A 3D numpy array where the third dimension is being rescaled.\n",
    "    - dimension (int, default=0): Specifies which dimension (0 or 1) of the third \n",
    "                                  dimension in the array should be rescaled. \n",
    "                                  For instance, in many contexts:\n",
    "                                  0 represents the x-coordinate, \n",
    "                                  1 represents the y-coordinate.\n",
    "    - ratio (float, default=1): The scaling factor to be applied.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: The rescaled array.\n",
    "    \"\"\"\n",
    "    \n",
    "    arr[:,:,dimension] *= ratio\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_average(arr, window_size):\n",
    "    \"\"\"\n",
    "    Computes the rolling average using a specified window size.\n",
    "    \n",
    "    Parameters:\n",
    "        arr (numpy.array): The input array to compute the rolling average for.\n",
    "        window_size (int): The size of the rolling window.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: The rolling average of the input array.\n",
    "    \"\"\"\n",
    "    if window_size < 1:\n",
    "       raise ValueError(\"Window size must be at least 1.\")\n",
    "    \n",
    "    # Create a uniform window of given window size\n",
    "    window = np.ones(window_size) / window_size\n",
    "\n",
    "    # Use numpy's convolve function to compute the rolling average\n",
    "    return np.convolve(arr, window, mode='valid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked_average(arr, chunk_size):\n",
    "    \"\"\"\n",
    "    Computes the average for non-overlapping chunks of the input array.\n",
    "    \n",
    "    Parameters:\n",
    "        arr (numpy.array): The input array.\n",
    "        chunk_size (int): The size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: The averages of the non-overlapping chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of chunks\n",
    "    num_chunks = len(arr) // chunk_size\n",
    "    \n",
    "    # Reshape the array into a 2D array of shape (num_chunks, chunk_size)\n",
    "    reshaped_arr = arr[:num_chunks * chunk_size].reshape(num_chunks, chunk_size)\n",
    "    \n",
    "    # Compute the mean along the second axis (i.e., for each chunk)\n",
    "    return reshaped_arr.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_average(arr, window_size, step=1):\n",
    "    \"\"\"\n",
    "    Apply a sliding window to a 1D numpy array, returning the average of windows of a specified size.\n",
    "\n",
    "    :param arr: Input 1D numpy array.\n",
    "    :param window_size: Size of the window.\n",
    "    :param step: The step size or number of elements to slide the window by. Default is 1.\n",
    "    :return: A 1D numpy array where each element is the average of a window from the input.\n",
    "    \"\"\"\n",
    "    # Number of windows\n",
    "    num_windows = ((arr.size - window_size) // step) + 1\n",
    "    \n",
    "    # Output array for averages\n",
    "    averages = np.zeros(num_windows)\n",
    "    \n",
    "    for i in range(num_windows):\n",
    "        # Calculate the start and end index for the window\n",
    "        start = i * step\n",
    "        end = start + window_size\n",
    "        # Calculate the average of the window\n",
    "        averages[i] = np.mean(arr[start:end])\n",
    "\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all_window_indices(original_index, window_size, step, array_length):\n",
    "    \"\"\"\n",
    "    Calculate all the start and stop indices for sliding windows based on an original start index.\n",
    "\n",
    "    :param original_index: The original index from which the first window should start.\n",
    "    :param window_size: The size of each sliding window.\n",
    "    :param step: The step size or number of elements to slide the window by.\n",
    "    :param array_length: The total number of elements in the array.\n",
    "    :return: A list of tuples, each containing the start and stop indices for a sliding window.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the list to hold the start and stop indices for all windows\n",
    "    windows = []\n",
    "\n",
    "    # Initialize the current start index with the original index\n",
    "    current_start_index = original_index\n",
    "\n",
    "    # Loop through the array until the end is reached\n",
    "    while current_start_index + window_size <= original_index + array_length:\n",
    "        # Calculate the stop index based on the window size\n",
    "        stop_index = current_start_index + window_size\n",
    "\n",
    "        # Add the start and stop indices to the list\n",
    "        windows.append((current_start_index, stop_index))\n",
    "\n",
    "        # Update the current start index by adding the step size\n",
    "        current_start_index += step\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electrophysiology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting timestamps for each spikegadgets sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Session: 20230618_100646_standard_comp_to_omission_D2_subj_2-4_and_2-1\n",
      "Current Session: 20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1\n",
      "Skipping file 20230618_100636_standard_comp_to_omission_D2_subj_1_4_t4b3L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nancy/projects/reward_competition_extention/results/2023_11_03_social_neuro_export/../../src/trodes/read_exported.py:62: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  return np.dtype(dtype_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file 20230618_100636_standard_comp_to_omission_D2_subj_1_1_t1b2L_box2_merged.timestampoffset.txt due to error: Settings format not supported\n"
     ]
    }
   ],
   "source": [
    "session_to_dir = {}\n",
    "# Going through each session recording\n",
    "# Which includes all the recordings from all the miniloggers and cameras\n",
    "for session_path in ALL_SESSION_DIR:   \n",
    "    try:\n",
    "        session_basename = os.path.splitext(os.path.basename(session_path))[0]\n",
    "        print(\"Current Session: {}\".format(session_basename))\n",
    "\n",
    "        session_to_dir[session_basename] = trodes.read_exported.organize_all_trodes_export(session_path)\n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_recording_to_timestamps = []\n",
    "for dir, rec_dict in session_to_dir.items():\n",
    "    for rec_file, value in rec_dict.items():\n",
    "        voltage_timestamp_array = np.array([lst[0] for lst in np.array(value[\"raw\"][\"timestamps\"][\"data\"])])\n",
    "        voltage_index_array = voltage_timestamp_array - voltage_timestamp_array[0]\n",
    "        \n",
    "        session_to_recording_to_timestamps.append({\"recording_session\": dir, \"ephys_name\": rec_file, \"voltage_timestamps\": voltage_timestamp_array, \"voltage_indexes\": voltage_index_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df = pd.DataFrame(session_to_recording_to_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_session</th>\n",
       "      <th>ephys_name</th>\n",
       "      <th>voltage_timestamps</th>\n",
       "      <th>voltage_indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>[835680, 835681, 835682, 835683, 835684, 83568...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>[835680, 835681, 835682, 835683, 835684, 83568...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   recording_session  \\\n",
       "0  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "1  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "\n",
       "                                          ephys_name  \\\n",
       "0  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "1  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "\n",
       "                                  voltage_timestamps  \\\n",
       "0  [835680, 835681, 835682, 835683, 835684, 83568...   \n",
       "1  [835680, 835681, 835682, 835683, 835684, 83568...   \n",
       "\n",
       "                                     voltage_indexes  \n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230618_100636_standard_comp_to_omission_D2_subj_1_1_t1b2L_box2_merged'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"ephys_name\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"subject_id\"] = recording_sessions_df[\"ephys_name\"].apply(lambda x: x.split(\"subj\")[-1].strip(\"_\").split(\"t\")[0].strip(\"_\").replace(\"-\", \".\").replace(\"_\", \".\"))\n",
    "                                                                                # .split(\"_\")[0].replace(\"-\", \".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.1\n",
       "1    1.4\n",
       "Name: subject_id, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"subject_id\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'recording_session': '20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1',\n",
       "  'ephys_name': '20230618_100636_standard_comp_to_omission_D2_subj_1_1_t1b2L_box2_merged',\n",
       "  'voltage_timestamps': array([  835680,   835681,   835682, ..., 66439619, 66439620, 66439621],\n",
       "        dtype=uint32),\n",
       "  'voltage_indexes': array([       0,        1,        2, ..., 65603939, 65603940, 65603941],\n",
       "        dtype=uint32)},\n",
       " {'recording_session': '20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1',\n",
       "  'ephys_name': '20230618_100636_standard_comp_to_omission_D2_subj_1_4_t4b3L_box1_merged',\n",
       "  'voltage_timestamps': array([  835680,   835681,   835682, ..., 69429290, 69429291, 69429292],\n",
       "        dtype=uint32),\n",
       "  'voltage_indexes': array([       0,        1,        2, ..., 68593610, 68593611, 68593612],\n",
       "        dtype=uint32)}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_to_recording_to_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230618_100636_standard_comp_to_omission_D2_subj_1_1_t1b2L_box2_merged'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"ephys_name\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the ephys channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>eib_mPFC</th>\n",
       "      <th>eib_vHPC</th>\n",
       "      <th>eib_BLA</th>\n",
       "      <th>eib_LH</th>\n",
       "      <th>eib_MD</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cohort  Subject  eib_mPFC  eib_vHPC  eib_BLA  eib_LH  eib_MD  \\\n",
       "0       1      6.1       NaN        15       14      13      31   \n",
       "1       1      6.2       NaN        15       14      13      31   \n",
       "2       1      6.3       NaN        15       14      13      31   \n",
       "3       1      6.4       NaN        15       14      13      31   \n",
       "4       2      1.1       NaN        16       17      18      19   \n",
       "5       2      1.2       NaN        31       30      29      28   \n",
       "6       2      1.3       NaN        15       14      13      12   \n",
       "7       2      1.4       NaN        15       14      13      12   \n",
       "\n",
       "   spike_interface_mPFC  spike_interface_vHPC  spike_interface_BLA  \\\n",
       "0                  21.0                  15.0                 14.0   \n",
       "1                   NaN                   NaN                  NaN   \n",
       "2                   NaN                   NaN                  NaN   \n",
       "3                   NaN                   NaN                  NaN   \n",
       "4                   5.0                  31.0                 30.0   \n",
       "5                  10.0                  31.0                 30.0   \n",
       "6                   9.0                  31.0                 30.0   \n",
       "7                  15.0                  31.0                 30.0   \n",
       "\n",
       "   spike_interface_LH  spike_interface_MD  \n",
       "0                13.0                16.0  \n",
       "1                 NaN                 NaN  \n",
       "2                 NaN                 NaN  \n",
       "3                 NaN                 NaN  \n",
       "4                29.0                28.0  \n",
       "5                29.0                28.0  \n",
       "6                29.0                28.0  \n",
       "7                29.0                28.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHANNEL_MAPPING_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF = CHANNEL_MAPPING_DF.drop(columns=[col for col in CHANNEL_MAPPING_DF if \"eib\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding all the brain region to ch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF[\"Subject\"] = CHANNEL_MAPPING_DF[\"Subject\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df = pd.merge(left=recording_sessions_df, left_on=\"subject_id\", right=CHANNEL_MAPPING_DF, right_on=\"Subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_session</th>\n",
       "      <th>ephys_name</th>\n",
       "      <th>voltage_timestamps</th>\n",
       "      <th>voltage_indexes</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>[835680, 835681, 835682, 835683, 835684, 83568...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>[835680, 835681, 835682, 835683, 835684, 83568...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   recording_session  \\\n",
       "0  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "1  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "\n",
       "                                          ephys_name  \\\n",
       "0  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "1  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "\n",
       "                                  voltage_timestamps  \\\n",
       "0  [835680, 835681, 835682, 835683, 835684, 83568...   \n",
       "1  [835680, 835681, 835682, 835683, 835684, 83568...   \n",
       "\n",
       "                                     voltage_indexes subject_id  Cohort  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        1.1       2   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        1.4       2   \n",
       "\n",
       "  Subject  spike_interface_mPFC  spike_interface_vHPC  spike_interface_BLA  \\\n",
       "0     1.1                   5.0                  31.0                 30.0   \n",
       "1     1.4                  15.0                  31.0                 30.0   \n",
       "\n",
       "   spike_interface_LH  spike_interface_MD  \n",
       "0                29.0                28.0  \n",
       "1                29.0                28.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230618_100636_standard_comp_to_omission_D2_subj_1_1_t1b2L_box2_merged'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"ephys_name\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65603942,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"voltage_timestamps\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred: stream_id trodes is not in ['ECU']\n",
      "20230618_100636_standard_comp_to_omission_D2_subj_1_4_t4b3L_box1_merged\n",
      "20230618_100636_standard_comp_to_omission_D2_subj_1_1_t1b2L_box2_merged\n",
      "An exception occurred: stream_id trodes is not in ['ECU']\n"
     ]
    }
   ],
   "source": [
    "recording_name_to_all_ch_lfp = {}\n",
    "# Going through all the recording sessions \n",
    "for session_dir in ALL_SESSION_DIR:\n",
    "    # Going through all the recordings in each session\n",
    "    for recording_path in glob.glob(os.path.join(session_dir, RECORDING_EXTENTION)):\n",
    "        try:\n",
    "            recording_basename = os.path.splitext(os.path.basename(recording_path))[0]\n",
    "            # checking to see if the recording has an ECU component\n",
    "            # if it doesn't, then the next one be extracted\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=ECU_STREAM_ID)\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=TRODES_STREAM_ID)\n",
    "            print(recording_basename)\n",
    "            # Preprocessing the LFP\n",
    "            current_recording = sp.bandpass_filter(current_recording, freq_min=LFP_FREQ_MIN, freq_max=LFP_FREQ_MAX)\n",
    "            current_recording = sp.notch_filter(current_recording, freq=ELECTRIC_NOISE_FREQ)\n",
    "            current_recording = sp.resample(current_recording, resample_rate=LFP_SAMPLING_RATE)\n",
    "            current_recording = sp.zscore(current_recording)\n",
    "            recording_name_to_all_ch_lfp[recording_basename] = current_recording\n",
    "        except Exception as error:\n",
    "            # handle the exception\n",
    "            print(\"An exception occurred:\", error) # An exception occurred: division by zero\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"all_ch_lfp\"] = recording_sessions_df[\"ephys_name\"].map(recording_name_to_all_ch_lfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_session</th>\n",
       "      <th>ephys_name</th>\n",
       "      <th>voltage_timestamps</th>\n",
       "      <th>voltage_indexes</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "      <th>all_ch_lfp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>[835680, 835681, 835682, 835683, 835684, 83568...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>20230618_100636_standard_comp_to_omission_D2_s...</td>\n",
       "      <td>[835680, 835681, 835682, 835683, 835684, 83568...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   recording_session  \\\n",
       "0  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "1  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "\n",
       "                                          ephys_name  \\\n",
       "0  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "1  20230618_100636_standard_comp_to_omission_D2_s...   \n",
       "\n",
       "                                  voltage_timestamps  \\\n",
       "0  [835680, 835681, 835682, 835683, 835684, 83568...   \n",
       "1  [835680, 835681, 835682, 835683, 835684, 83568...   \n",
       "\n",
       "                                     voltage_indexes subject_id  Cohort  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        1.1       2   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        1.4       2   \n",
       "\n",
       "  Subject  spike_interface_mPFC  spike_interface_vHPC  spike_interface_BLA  \\\n",
       "0     1.1                   5.0                  31.0                 30.0   \n",
       "1     1.4                  15.0                  31.0                 30.0   \n",
       "\n",
       "   spike_interface_LH  spike_interface_MD  \\\n",
       "0                29.0                28.0   \n",
       "1                29.0                28.0   \n",
       "\n",
       "                                          all_ch_lfp  \n",
       "0  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...  \n",
       "1  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the LFP for each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_columns = [col for col in recording_sessions_df if \"spike_interface\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in region_columns:\n",
    "    recording_sessions_df[col] = recording_sessions_df[col].astype(int).astype(str)\n",
    "    region = col.split(\"_\")[-1]\n",
    "    print(region)\n",
    "    recording_sessions_df[\"{}_lfp_trace\".format(region)] = recording_sessions_df.apply(lambda row: row[\"all_ch_lfp\"].get_traces(channel_ids=[row[col]]).T[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df = recording_sessions_df.drop(columns=[\"all_ch_lfp\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_columns = [col for col in recording_sessions_df if \"trace\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"lfp_indexes\"] = recording_sessions_df[trace_columns[0]].apply(lambda x: np.arange(0, 20 * x.shape[0] + 1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"lfp_indexes\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"voltage_indexes\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the timestamps of each LFP sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"lfp_timestamps\"] = recording_sessions_df.apply(lambda x: x[\"voltage_timestamps\"][0:20 * x[\"mPFC_lfp_trace\"].shape[0]:20], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the h5 files between recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = VIDEO_TO_FRAME_AND_SUBJECT_DF.dropna(subset=\"start_frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>stop_frame</th>\n",
       "      <th>individual_subj</th>\n",
       "      <th>all_subj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.1_6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>27500.0</td>\n",
       "      <td>73601.0</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>6.1_6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>51500.0</td>\n",
       "      <td>76455.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.1_6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48500.0</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>6.1_6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>79051.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1_1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  start_frame  stop_frame  \\\n",
       "1  /scratch/back_up/reward_competition_extention/...          1.0     25000.0   \n",
       "2  /scratch/back_up/reward_competition_extention/...      27500.0     73601.0   \n",
       "3  /scratch/back_up/reward_competition_extention/...      51500.0     76455.0   \n",
       "4  /scratch/back_up/reward_competition_extention/...          1.0     48500.0   \n",
       "5  /scratch/back_up/reward_competition_extention/...      41000.0     79051.0   \n",
       "\n",
       "  individual_subj all_subj  \n",
       "1             6.3  6.1_6.3  \n",
       "2         6.1_6.3  6.1_6.3  \n",
       "3             6.3  6.1_6.3  \n",
       "4         6.1_6.3  6.1_6.3  \n",
       "5             1.1  1.1_1.2  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be indexing for the frames, so they must be integers and not floats\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"start_frame\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"start_frame\"].astype(int)\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"stop_frame\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"stop_frame\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the basename of the file which corresponds to the ephys recording that the h5 file came from\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"video_name\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].apply(lambda x: \".\".join(os.path.basename(x).split(\".\")[:2]))\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"recording_name\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].apply(lambda x: os.path.basename(x).split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"all_sleap_data\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].apply(lambda x: extract_sleap_data(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"location\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"all_sleap_data\"].apply(lambda x: x[\"location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"track_names\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"all_sleap_data\"].apply(lambda x: x[\"track_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the coordinates of all the body parts for all the animals for the entire recording\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"location\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].apply(lambda x: get_sleap_tracks_from_h5(x))\n",
    "# Getting the name of the tracks which correspond to the animal id\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"track_names\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].apply(lambda x: get_sleap_track_names_from_h5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"location\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure all the subject IDs are strings instead of floating point numbers\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"individual_subj\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"individual_subj\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the indexes of each subject from the track list\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_index\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: {k: x[\"track_names\"].index(k) for k in x[\"individual_subj\"].split(\"_\")}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_index\"].copy()#.apply(lambda x: {k:v for k, v in x[\"subject_to_index\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: {k: x[\"location\"][:,:,:,v] for k, v in x[\"subject_to_index\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary items to list of items\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_and_tracks_list\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_to_tracks\"].apply(lambda x: list(x.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode based on the lists\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = VIDEO_TO_FRAME_AND_SUBJECT_DF.explode([\"subject_and_tracks_list\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split tuple of (key, value) into separate columns\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[['subject_id', \"full-recording_subject_location_all-frames_original\"]] = pd.DataFrame(VIDEO_TO_FRAME_AND_SUBJECT_DF[\"subject_and_tracks_list\"].tolist(), index=VIDEO_TO_FRAME_AND_SUBJECT_DF.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"agent_id\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: [subj for subj in x[\"individual_subj\"].split(\"_\") if x[\"subject_id\"] != subj], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"agent_id\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"agent_id\"].apply(lambda x: x[0] if x else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_agent_location_all-frames_original\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: x[\"subject_to_tracks\"].get(x[\"agent_id\"], np.nan), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = VIDEO_TO_FRAME_AND_SUBJECT_DF.drop(columns=[\"subject_to_tracks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the coordinates of the corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each corner file is the in the same folder and has the same basename of the pose tracking file \n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_path\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].apply(lambda x: \"{}.fixed.corner.h5\".format(x.split(\"fixed\")[0].strip(\".\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the indexes of each corner location\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_parts\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_path\"].apply(lambda x: get_node_names_from_sleap(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_parts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"video_name\"].iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the coordinates of all the corners\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_path\"].apply(lambda x: get_sleap_tracks_from_h5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing out each corner and creating a dictionary of name to coordinates\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: {part: x[\"corner_to_coordinate\"][:,index,:,:] for index, part in enumerate(x[\"corner_parts\"])}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out all the Nans because there's only one labeled frame\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: {k: v[~np.isnan(v)] for k, v in x[\"corner_to_coordinate\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].iloc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the distances between corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the average width and height so that we can convert pixels to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the x-coordinates for the width\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"bottom_width\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_right\"][0] - x[\"box_bottom_left\"][0])\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"top_width\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_top_right\"][0] - x[\"box_top_left\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the y-coordinates for the height\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"right_height\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_right\"][1] - x[\"box_top_right\"][1])\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"left_height\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_left\"][1] - x[\"box_top_left\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging the width and height by adding both sides and then getting the mean\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"average_height\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda row: (row[\"right_height\"] + row[\"left_height\"])/2, axis=1)\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"average_width\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda row: (row[\"bottom_width\"] + row[\"top_width\"])/2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getthing the pixel to cm ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"width_ratio\"] = MED_PC_WIDTH / VIDEO_TO_FRAME_AND_SUBJECT_DF[\"average_width\"]\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"height_ratio\"] = MED_PC_HEIGHT / VIDEO_TO_FRAME_AND_SUBJECT_DF[\"average_height\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"height_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"width_ratio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Pixels to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_original\"][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the X-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_original\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy is required so that we don't accidently over write the same item in the list\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_rescaled\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: rescale_dimension_in_array(x[\"full-recording_subject_location_all-frames_original\"].copy(), dimension=0, ratio=x[\"width_ratio\"]), axis=1)\n",
    "\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_agent_location_all-frames_rescaled\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: rescale_dimension_in_array(x[\"full-recording_agent_location_all-frames_original\"].copy(), dimension=0, ratio=x[\"width_ratio\"]) if x[\"full-recording_agent_location_all-frames_original\"] is not np.nan else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the Y-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_rescaled\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: rescale_dimension_in_array(x[\"full-recording_subject_location_all-frames_rescaled\"].copy(), dimension=1, ratio=x[\"height_ratio\"]), axis=1)\n",
    "\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_agent_location_all-frames_rescaled\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: rescale_dimension_in_array(x[\"full-recording_agent_location_all-frames_rescaled\"].copy(), dimension=1, ratio=x[\"height_ratio\"]) if x[\"full-recording_agent_location_all-frames_original\"] is not np.nan else np.nan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_original\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_rescaled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize dictionary column\n",
    "normalized = pd.json_normalize(VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_to_coordinate\"])\n",
    "\n",
    "# Drop the original column and concat the normalized DataFrame\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = pd.concat([VIDEO_TO_FRAME_AND_SUBJECT_DF.drop([\"corner_to_coordinate\"], axis=1), normalized], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corner in VIDEO_TO_FRAME_AND_SUBJECT_DF[\"corner_parts\"].iloc[0]:\n",
    "    VIDEO_TO_FRAME_AND_SUBJECT_DF[corner] = VIDEO_TO_FRAME_AND_SUBJECT_DF.apply(lambda x: [x[corner][0]*x[\"width_ratio\"], x[corner][1]*x[\"height_ratio\"]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking over the tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_INDEX = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].iloc[FILE_INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(VIDEO_TO_FRAME_AND_SUBJECT_DF[\"file_path\"].iloc[FILE_INDEX], \"r\") as f:\n",
    "    dset_names = list(f.keys())\n",
    "    location = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_rescaled\"].iloc[FILE_INDEX]\n",
    "    node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "    \n",
    "print(\"===HDF5 datasets===\")\n",
    "print(dset_names)\n",
    "print()\n",
    "\n",
    "print(\"===location data shape===\")\n",
    "print(location.shape)\n",
    "print()\n",
    "\n",
    "print(\"===nodes===\")\n",
    "for i, name in enumerate(node_names):\n",
    "    print(f\"{i}: {name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thorax_loc = location[:, THORAX_INDEX, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(thorax_loc[:,0],label='X-coordinates')\n",
    "# Converting to negative so that we can see both x and y track\n",
    "plt.plot(-1*thorax_loc[:,1], label='Y-coordinates')\n",
    "\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.title('Thorax location')\n",
    "plt.xlabel(\"Time in frames\")\n",
    "plt.ylabel(\"Coordinate Position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(thorax_loc[:,0],thorax_loc[:,1])\n",
    "\n",
    "\n",
    "plt.title('Thorax tracks')\n",
    "plt.xlabel(\"X-Coordinates\")\n",
    "plt.ylabel(\"Y-Coordinates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_rescaled\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_rescaled\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_rescaled\"].apply(lambda x: fill_missing(x))\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_agent_location_all-frames_rescaled\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_agent_location_all-frames_rescaled\"].apply(lambda x: fill_missing(x) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"full-recording_subject_location_all-frames_rescaled\"].iloc[FILE_INDEX]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thorax_loc = location[:, THORAX_INDEX, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(thorax_loc[:,0],label='X-coordinates')\n",
    "# Converting to negative so that we can see both x and y track\n",
    "plt.plot(-1*thorax_loc[:,1], label='Y-coordinates')\n",
    "\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.title('Thorax location')\n",
    "plt.xlabel(\"Time in frames\")\n",
    "plt.ylabel(\"Coordinate Position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(thorax_loc[:,0],thorax_loc[:,1])\n",
    "\n",
    "\n",
    "plt.title('Thorax tracks')\n",
    "plt.xlabel(\"X-Coordinates\")\n",
    "plt.ylabel(\"Y-Coordinates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD Code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtering for all trials that we got the LFP for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df[all_trials_df[\"recording_file\"].isin(recording_name_to_all_ch_lfp.keys())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_trials_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding trial numbers based on timestamp ordering for each recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df.groupby('recording_file').apply(lambda g: compute_sorted_index(g, value_column='time', index_column='trial_number')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_number\"] = all_trials_df[\"trial_number\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the LFP trace information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = all_trials_df.merge(CHANNEL_MAPPING_DF, left_on=\"current_subject\", right_on=\"Subject\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.drop(columns=[col for col in channel_map_and_all_trials_df.columns if \"eib\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.drop(columns=[\"Subject\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.to_csv(\"./proc/trial_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.to_pickle(\"./proc/trial_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linking up all LFP calculations with all the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"all_ch_lfp\"] = channel_map_and_all_trials_df[\"recording_file\"].map(recording_name_to_all_ch_lfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a new row for each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_region_col = [col for col in CHANNEL_MAPPING_DF if \"spike_interface\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [col for col in channel_map_and_all_trials_df.columns if col not in brain_region_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_region_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in brain_region_col:\n",
    "    channel_map_and_all_trials_df[col] = channel_map_and_all_trials_df[col].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in brain_region_col:\n",
    "    print(col)\n",
    "    channel_map_and_all_trials_df[\"{}_baseline_lfp_trace\".format(col.strip(\"spike_interface\").strip(\"_\"))] = channel_map_and_all_trials_df.apply(lambda row: row[\"all_ch_lfp\"].get_traces(channel_ids=[row[col]], start_frame=row[\"baseline_lfp_timestamp_range\"][0], end_frame=row[\"baseline_lfp_timestamp_range\"][1]).T[0], axis=1)\n",
    "\n",
    "    channel_map_and_all_trials_df[\"{}_trial_lfp_trace\".format(col.strip(\"spike_interface\").strip(\"_\"))] = channel_map_and_all_trials_df.apply(lambda row: row[\"all_ch_lfp\"].get_traces(channel_ids=[row[col]], start_frame=row[\"trial_lfp_timestamp_range\"][0], end_frame=row[\"trial_lfp_timestamp_range\"][1]).T[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.drop(columns=[\"all_ch_lfp\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.to_pickle(\"./proc/full_baseline_and_trial_lfp_traces.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(83177118-3478533)/20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP 2: Extracting the timestamps for the raw ephys recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_to_din_state_df = {}\n",
    "for session, file_to_data in session_to_dir.items():\n",
    "    all_recording_din_state_df = []\n",
    "    for recording_name, subdir_dict in file_to_data.items():\n",
    "        print(recording_name)\n",
    "        current_recording_din_state_df = []\n",
    "\n",
    "        try:\n",
    "            voltage_timestamp_array = file_to_data[recording_name][\"raw\"][\"timestamps\"][\"data\"]\n",
    "            for key, value in file_to_data[recording_name][\"DIO\"].items():\n",
    "                if \"in\" in key:\n",
    "                    print(key)\n",
    "                    din_state_array = file_to_data[recording_name][\"DIO\"][key][\"data\"]\n",
    "                    current_din_state_df = pd.DataFrame(din_state_array)\n",
    "                    current_din_state_df[\"recording_dir\"] = session\n",
    "                    current_din_state_df[\"recording_file\"] = recording_name\n",
    "                    current_din_state_df[\"din\"] = key\n",
    "                    current_recording_din_state_df.append(current_din_state_df)\n",
    "                    if key == TONE_DIN:\n",
    "                        plt.plot([tup[0] for tup in din_state_array], [tup[1] for tup in din_state_array])\n",
    "                        plt.xlabel(\"Timestamp\")\n",
    "                        plt.ylabel(\"State\")\n",
    "                        plt.title(\"Din State Change against Timestamps for {} in {}\".format(key, recording_name))\n",
    "                        plt.show()\n",
    "                        plt.close()\n",
    "            concatted_per_recording_din_state_df = pd.concat(current_recording_din_state_df).sort_values(by=[\"recording_file\", \"din\"]).reset_index(drop=True)\n",
    "            concatted_per_recording_din_state_df[\"time_stamp_index\"] = concatted_per_recording_din_state_df[\"time\"] - voltage_timestamp_array[0][0]\n",
    "            all_recording_din_state_df.append(concatted_per_recording_din_state_df)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    concatted_all_recording_din_state_df = pd.concat(all_recording_din_state_df)\n",
    "    session_to_din_state_df[session] = concatted_all_recording_din_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voltage_timestamp_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "79698586//20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatted_per_recording_din_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recording_din_state_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP 3 Adding the video timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_din_state_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_to_din_with_frames_df = {}\n",
    "for session_path in all_session_files:   \n",
    "    try:\n",
    "        session_basename = os.path.splitext(os.path.basename(session_path))[0]\n",
    "        print(\"Current Session: {}\".format(session_basename))\n",
    "        file_to_video_timestamps = {}\n",
    "        for video_timestamps in glob.glob(os.path.join(session_path, \"*cameraHWSync\")):\n",
    "            video_basename = os.path.basename(video_timestamps)\n",
    "            print(\"Current Video Name: {}\".format(video_basename))\n",
    "            timestamp_array = trodes.read_exported.read_trodes_extracted_data_file(video_timestamps)[\"data\"][\"PosTimestamp\"]\n",
    "            file_to_video_timestamps[video_basename] = timestamp_array\n",
    "            session_to_din_state_df[session_basename][os.path.basename(video_timestamps)] = session_to_din_state_df[session_basename][\"time\"].apply(lambda x: find_closest_index(sorted_list=timestamp_array, target=x))        \n",
    "        \n",
    "        # Find the maximum length of the arrays in the dictionary\n",
    "        max_length = max(map(len, file_to_video_timestamps.values()))\n",
    "        \n",
    "        # Pad each array with NaN values to make them all the same length\n",
    "        padded_data = {k: np.pad(v, (0, max_length - len(v)), mode='constant', constant_values=np.nan) for k, v in file_to_video_timestamps.items()}\n",
    "        \n",
    "        # Convert the padded data to a dataframe\n",
    "        session_to_din_with_frames_df[session_basename] = pd.DataFrame(padded_data)\n",
    "        session_to_din_with_frames_df[session_basename].to_csv(os.path.join(OUTPUT_DIR, \"{}.frame_to_timestamps.csv\".format(session_basename)))\n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "session_to_din_state_df['20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "session_to_din_with_frames_df['20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP 4: Combining the video columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_tone_stamp_df = {}\n",
    "for session, timestamps_df in session_to_din_state_df.items():\n",
    "    current_timestamps_df = timestamps_df[(timestamps_df[\"din\"] == TONE_DIN) & (timestamps_df[\"state\"] == TONE_STATE)].reset_index(drop=True)\n",
    "    camera_col = [col for col in current_timestamps_df.columns if \"cameraHWSync\" in col]\n",
    "    id_col = [col for col in current_timestamps_df.columns if \"cameraHWSync\" not in col]\n",
    "    \n",
    "    current_timestamps_df = current_timestamps_df.melt(id_vars=id_col, value_vars=camera_col, var_name='video_file', value_name='video_frame')\n",
    "    current_timestamps_df[\"video_number\"] = current_timestamps_df[\"video_file\"].apply(lambda x: x.strip(\"videoTimeStamps.cameraHWSync\").split(\".\")[-1])\n",
    "    current_timestamps_df[\"subject_info\"] = current_timestamps_df[\"recording_file\"].apply(lambda x: x.split(\"subject\")[-1].strip(\"merged\").strip(\"_\"))\n",
    "    current_timestamps_df[\"condition\"] = np.nan\n",
    "    session_to_tone_stamp_df[session]  = current_timestamps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_tone_stamp_df[session]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df = pd.concat(session_to_tone_stamp_df.values()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df.to_csv(os.path.join(OUTPUT_DIR, \"{}_tone_timestamp.csv\".format(OUTPUT_PREFIX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping all rows that have not been labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = TONE_TIMESTAMP_DF.dropna(subset=\"condition\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_trials_df[\"recording_dir\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making the video frame number usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"video_frame\"] = all_trials_df[\"video_frame\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the name of the video so that we can sync it up with the ephys recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"video_name\"]  = all_trials_df[\"video_file\"].apply(lambda x: x.strip(\".videoTimeStamps.cameraHWSync\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting all subject IDs for a given recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using different id extractions for different file formats\n",
    "all_trials_df[\"all_subjects\"] = all_trials_df[\"recording_dir\"].apply(lambda x: x if \"2023\" in x else \"subj\" + \"_\".join(x.split(\"_\")[-5:]))\n",
    "all_trials_df[\"all_subjects\"] = all_trials_df[\"all_subjects\"].apply(lambda x: tuple(sorted([num.strip(\"_\").replace(\"_\",\".\") for num in x.replace(\"-\", \"_\").split(\"subj\")[-1].strip(\"_\").split(\"and\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_trials_df[\"all_subjects\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"current_subject\"] = all_trials_df[\"subject_info\"].apply(lambda x: \".\".join(x.replace(\"-\",\"_\").split(\"_\")[:2])).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"current_subject\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the trial label to win or lose based on who won the trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_outcome\"] = all_trials_df.apply(\n",
    "    lambda x: \"win\" if str(x[\"condition\"]).strip() == str(x[\"current_subject\"]) \n",
    "             else (\"lose\" if str(x[\"condition\"]) in x[\"all_subjects\"] \n",
    "                   else x[\"condition\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_outcome\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the competition closeness as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_closeness_map = {k: \"non_comp\" if \"only\" in str(k).lower() else \"comp\" if type(k) is str else np.nan for k in all_trials_df[\"competition_closeness\"].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "competition_closeness_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"competition_closeness\"] = all_trials_df[\"competition_closeness\"].map(competition_closeness_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"competition_closeness\"] = all_trials_df.apply(lambda x: \"_\".join([str(x[\"trial_outcome\"]), str(x[\"competition_closeness\"])]).strip(\"nan\").strip(\"_\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"competition_closeness\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the LFP index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"lfp_index\"] = (all_trials_df[\"time_stamp_index\"] // (EPHYS_SAMPLING_RATE/LFP_SAMPLING_RATE)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"time\"] = all_trials_df[\"time\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"time_stamp_index\"] = all_trials_df[\"time_stamp_index\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df.drop(columns=[\"state\", \"din\", \"condition\", \"Unnamed: 13\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df.groupby([\"competition_closeness\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making columns of the different timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"baseline_lfp_timestamp_range\"] = all_trials_df[\"lfp_index\"].apply(lambda x: (x - TRIAL_DURATION * LFP_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_lfp_timestamp_range\"] = all_trials_df[\"lfp_index\"].apply(lambda x: (x, x + TRIAL_DURATION * LFP_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"baseline_ephys_timestamp_range\"] = all_trials_df[\"time_stamp_index\"].apply(lambda x: (x - TRIAL_DURATION * EPHYS_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_ephys_timestamp_range\"] = all_trials_df[\"time_stamp_index\"].apply(lambda x: (x, x + TRIAL_DURATION * EPHYS_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"baseline_videoframe_range\"] = all_trials_df[\"video_frame\"].apply(lambda x: (x - TRIAL_DURATION * FRAME_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_videoframe_range\"] = all_trials_df[\"video_frame\"].apply(lambda x: (x, x + TRIAL_DURATION * FRAME_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding the SLEAP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"lfp_timestamps\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"mPFC_lfp_trace\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, 20 * recording_sessions_df[\"mPFC_lfp_trace\"].iloc[0].shape[0] + 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"voltage_timestamps\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"voltage_timestamps\"].iloc[0][0:20 * recording_sessions_df[\"mPFC_lfp_trace\"].iloc[0].shape[0]:20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "83177118-3478533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"voltage_timestamps\"].iloc[0][::20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"mPFC_lfp_trace\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(recording_name_to_all_ch_lfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "79698586/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
