{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Notebook 1: Extract Z-scored LFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import os\n",
    "import glob\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting path\n",
    "sys.path.append('../../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trodes.read_exported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF = pd.read_excel(\"../../data/channel_mapping.xlsx\")\n",
    "TONE_TIMESTAMP_DF = pd.read_excel(\"../../data/rce_tone_timestamp.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_DIN = \"dio_ECU_Din1\"\n",
    "TONE_STATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPHYS_SAMPLING_RATE = 20000\n",
    "LFP_SAMPLING_RATE = 1000\n",
    "TRIAL_DURATION = 10\n",
    "FRAME_RATE = 22\n",
    "ECU_STREAM_ID = \"ECU\"\n",
    "TRODES_STREAM_ID = \"trodes\"\n",
    "LFP_FREQ_MIN = 0.5\n",
    "LFP_FREQ_MAX = 300\n",
    "ELECTRIC_NOISE_FREQ = 60\n",
    "RECORDING_EXTENTION = \"*.rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_SESSION_DIR = glob.glob(\"/scratch/back_up/reward_competition_extention/data/omission/2023_06_17/*.rec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sorted_index(group, value_column='Value', index_column='SortedIndex'):\n",
    "    \"\"\" \n",
    "    Computes the index of each row's value within its sorted group.\n",
    "\n",
    "    Parameters:\n",
    "    - group (pd.DataFrame): A group of data.\n",
    "    - value_column (str): Name of the column containing the values to be sorted.\n",
    "    - index_column (str): Name of the new column that will contain the indices.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The group with an additional column containing the indices.\n",
    "    \"\"\"\n",
    "    sorted_values = sorted(list(set(group[value_column].tolist())))\n",
    "    group[index_column] = group[value_column].apply(lambda x: sorted_values.index(x))\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_index(sorted_list=None, target=0):\n",
    "    \"\"\"\n",
    "    Returns the index of the number in the sorted list that is closest to the target.\n",
    "\n",
    "    This function performs a binary search on a sorted list to find the closest number to \n",
    "    a given target. If the target exists in the list, its index is returned. If not, the \n",
    "    function will return the index of the number that's closest to the target.\n",
    "\n",
    "    Parameters:\n",
    "    - sorted_list (list[int or float]): A sorted list of numbers.\n",
    "    - target (int or float): The target number to find the closest value to.\n",
    "\n",
    "    Returns:\n",
    "    - int: The index of the closest number in the sorted list to the target. \n",
    "           If the sorted list is empty, returns None.\n",
    "\n",
    "    Example:\n",
    "    >>> sorted_nums = [1, 3, 5, 8, 10, 15, 18, 20, 24, 27, 30]\n",
    "    >>> find_closest_index(sorted_nums, 6)\n",
    "    2\n",
    "\n",
    "    Note:\n",
    "    The list should be sorted in ascending order.\n",
    "    \"\"\"\n",
    "    \n",
    "    if sorted_list is None:\n",
    "        return None\n",
    "    if target <= sorted_list[0]:\n",
    "        return 0\n",
    "    if target >= sorted_list[-1]:\n",
    "        return len(sorted_list) - 1\n",
    "\n",
    "    # Binary search\n",
    "    left, right = 0, len(sorted_list) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "\n",
    "        if sorted_list[mid] == target:\n",
    "            return mid\n",
    "        elif sorted_list[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "\n",
    "    # After binary search, the target will be between sorted_list[right] and sorted_list[left]\n",
    "    # We compare the two to see which one is closer to the target and return its index\n",
    "    if abs(sorted_list[left] - target) < abs(sorted_list[right] - target):\n",
    "        return left\n",
    "    else:\n",
    "        return right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electrophysiology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting timestamps for each spikegadgets sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Session: 20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2\n",
      "Skipping file 20230617_115521_standard_comp_to_omission_D1_subj_1-2_t2b2L_box2_merged.timestampoffset.txt due to error: Settings format not supported\n",
      "Skipping file 20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged.timestampoffset.txt due to error: Settings format not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nancy/projects/reward_competition_extention/results/2023_11_03_social_neuro_export/../../src/trodes/read_exported.py:62: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  return np.dtype(dtype_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Session: 20230617_115641_standard_comp_to_omission_D1_subj_2-2_and_2-4\n"
     ]
    }
   ],
   "source": [
    "session_to_dir = {}\n",
    "# Going through each session recording\n",
    "# Which includes all the recordings from all the miniloggers and cameras\n",
    "for session_path in ALL_SESSION_DIR:   \n",
    "    try:\n",
    "        session_basename = os.path.splitext(os.path.basename(session_path))[0]\n",
    "        print(\"Current Session: {}\".format(session_basename))\n",
    "\n",
    "        session_to_dir[session_basename] = trodes.read_exported.organize_all_trodes_export(session_path)\n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_recording_to_timestamps = []\n",
    "for dir, rec_dict in session_to_dir.items():\n",
    "    for rec_file, value in rec_dict.items():\n",
    "        voltage_timestamp_array = np.array([lst[0] for lst in np.array(value[\"raw\"][\"timestamps\"][\"data\"])])\n",
    "        voltage_index_array = voltage_timestamp_array - voltage_timestamp_array[0]\n",
    "        \n",
    "        session_to_recording_to_timestamps.append({\"recording_session\": dir, \"ephys_name\": rec_file, \"voltage_timestamps\": voltage_timestamp_array, \"voltage_indexes\": voltage_index_array})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df = pd.DataFrame(session_to_recording_to_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"subject_id\"] = recording_sessions_df[\"ephys_name\"].apply(lambda x: x.split(\"subj\")[-1].strip(\"_\").split(\"_\")[0].replace(\"-\", \".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.1\n",
       "1    1.2\n",
       "Name: subject_id, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"subject_id\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"ephys_name\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the ephys channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>eib_mPFC</th>\n",
       "      <th>eib_vHPC</th>\n",
       "      <th>eib_BLA</th>\n",
       "      <th>eib_LH</th>\n",
       "      <th>eib_MD</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cohort Subject  eib_mPFC  eib_vHPC  eib_BLA  eib_LH  eib_MD  \\\n",
       "0       1     6.1       NaN        15       14      13      31   \n",
       "1       1     6.2       NaN        15       14      13      31   \n",
       "2       1     6.3       NaN        15       14      13      31   \n",
       "3       1     6.4       NaN        15       14      13      31   \n",
       "4       2     1.1       NaN        16       17      18      19   \n",
       "5       2     1.2       NaN        31       30      29      28   \n",
       "6       2     1.3       NaN        15       14      13      12   \n",
       "7       2     1.4       NaN        15       14      13      12   \n",
       "\n",
       "   spike_interface_mPFC  spike_interface_vHPC  spike_interface_BLA  \\\n",
       "0                  21.0                  15.0                 14.0   \n",
       "1                   NaN                   NaN                  NaN   \n",
       "2                   NaN                   NaN                  NaN   \n",
       "3                   NaN                   NaN                  NaN   \n",
       "4                   5.0                  31.0                 30.0   \n",
       "5                  10.0                  31.0                 30.0   \n",
       "6                   9.0                  31.0                 30.0   \n",
       "7                  15.0                  31.0                 30.0   \n",
       "\n",
       "   spike_interface_LH  spike_interface_MD  \n",
       "0                13.0                16.0  \n",
       "1                 NaN                 NaN  \n",
       "2                 NaN                 NaN  \n",
       "3                 NaN                 NaN  \n",
       "4                29.0                28.0  \n",
       "5                29.0                28.0  \n",
       "6                29.0                28.0  \n",
       "7                29.0                28.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHANNEL_MAPPING_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding all the brain region to ch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF[\"Subject\"] = CHANNEL_MAPPING_DF[\"Subject\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df = pd.merge(left=recording_sessions_df, left_on=\"subject_id\", right=CHANNEL_MAPPING_DF, right_on=\"Subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_session</th>\n",
       "      <th>ephys_name</th>\n",
       "      <th>voltage_timestamps</th>\n",
       "      <th>voltage_indexes</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>eib_mPFC</th>\n",
       "      <th>eib_vHPC</th>\n",
       "      <th>eib_BLA</th>\n",
       "      <th>eib_LH</th>\n",
       "      <th>eib_MD</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>[3478533, 3478534, 3478535, 3478536, 3478537, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>[3478533, 3478534, 3478535, 3478536, 3478537, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   recording_session  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "\n",
       "                                          ephys_name  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "\n",
       "                                  voltage_timestamps  \\\n",
       "0  [3478533, 3478534, 3478535, 3478536, 3478537, ...   \n",
       "1  [3478533, 3478534, 3478535, 3478536, 3478537, ...   \n",
       "\n",
       "                                     voltage_indexes subject_id  Cohort  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        1.1       2   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        1.2       2   \n",
       "\n",
       "  Subject  eib_mPFC  eib_vHPC  eib_BLA  eib_LH  eib_MD  spike_interface_mPFC  \\\n",
       "0     1.1       NaN        16       17      18      19                   5.0   \n",
       "1     1.2       NaN        31       30      29      28                  10.0   \n",
       "\n",
       "   spike_interface_vHPC  spike_interface_BLA  spike_interface_LH  \\\n",
       "0                  31.0                 30.0                29.0   \n",
       "1                  31.0                 30.0                29.0   \n",
       "\n",
       "   spike_interface_MD  \n",
       "0                28.0  \n",
       "1                28.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"ephys_name\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred: stream_id trodes is not in ['ECU']\n",
      "20230617_115521_standard_comp_to_omission_D1_subj_1-2_t2b2L_box2_merged\n",
      "20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged\n",
      "An exception occurred: stream_id trodes is not in ['ECU']\n"
     ]
    }
   ],
   "source": [
    "recording_name_to_all_ch_lfp = {}\n",
    "# Going through all the recording sessions \n",
    "for session_dir in ALL_SESSION_DIR:\n",
    "    # Going through all the recordings in each session\n",
    "    for recording_path in glob.glob(os.path.join(session_dir, RECORDING_EXTENTION)):\n",
    "        try:\n",
    "            recording_basename = os.path.splitext(os.path.basename(recording_path))[0]\n",
    "            # checking to see if the recording has an ECU component\n",
    "            # if it doesn't, then the next one be extracted\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=ECU_STREAM_ID)\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=TRODES_STREAM_ID)\n",
    "            print(recording_basename)\n",
    "            # Preprocessing the LFP\n",
    "            current_recording = sp.bandpass_filter(current_recording, freq_min=LFP_FREQ_MIN, freq_max=LFP_FREQ_MAX)\n",
    "            current_recording = sp.notch_filter(current_recording, freq=ELECTRIC_NOISE_FREQ)\n",
    "            current_recording = sp.resample(current_recording, resample_rate=LFP_SAMPLING_RATE)\n",
    "            current_recording = sp.zscore(current_recording)\n",
    "            recording_name_to_all_ch_lfp[recording_basename] = current_recording\n",
    "        except Exception as error:\n",
    "            # handle the exception\n",
    "            print(\"An exception occurred:\", error) # An exception occurred: division by zero\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"all_ch_lfp\"] = recording_sessions_df[\"ephys_name\"].map(recording_name_to_all_ch_lfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_session</th>\n",
       "      <th>ephys_name</th>\n",
       "      <th>voltage_timestamps</th>\n",
       "      <th>voltage_indexes</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>eib_mPFC</th>\n",
       "      <th>eib_vHPC</th>\n",
       "      <th>eib_BLA</th>\n",
       "      <th>eib_LH</th>\n",
       "      <th>eib_MD</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "      <th>all_ch_lfp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>[3478533, 3478534, 3478535, 3478536, 3478537, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>[3478533, 3478534, 3478535, 3478536, 3478537, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   recording_session  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "\n",
       "                                          ephys_name  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "\n",
       "                                  voltage_timestamps  \\\n",
       "0  [3478533, 3478534, 3478535, 3478536, 3478537, ...   \n",
       "1  [3478533, 3478534, 3478535, 3478536, 3478537, ...   \n",
       "\n",
       "                                     voltage_indexes subject_id  Cohort  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        1.1       2   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        1.2       2   \n",
       "\n",
       "  Subject  eib_mPFC  eib_vHPC  eib_BLA  eib_LH  eib_MD  spike_interface_mPFC  \\\n",
       "0     1.1       NaN        16       17      18      19                   5.0   \n",
       "1     1.2       NaN        31       30      29      28                  10.0   \n",
       "\n",
       "   spike_interface_vHPC  spike_interface_BLA  spike_interface_LH  \\\n",
       "0                  31.0                 30.0                29.0   \n",
       "1                  31.0                 30.0                29.0   \n",
       "\n",
       "   spike_interface_MD                                         all_ch_lfp  \n",
       "0                28.0  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...  \n",
       "1                28.0  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the LFP for each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_columns = [col for col in recording_sessions_df if \"spike_interface\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spike_interface_mPFC',\n",
       " 'spike_interface_vHPC',\n",
       " 'spike_interface_BLA',\n",
       " 'spike_interface_LH',\n",
       " 'spike_interface_MD']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mPFC\n",
      "vHPC\n",
      "BLA\n",
      "LH\n",
      "MD\n"
     ]
    }
   ],
   "source": [
    "for col in region_columns:\n",
    "    recording_sessions_df[col] = recording_sessions_df[col].astype(int).astype(str)\n",
    "    region = col.split(\"_\")[-1]\n",
    "    print(region)\n",
    "    recording_sessions_df[\"{}_lfp_trace\".format(region)] = recording_sessions_df.apply(lambda row: row[\"all_ch_lfp\"].get_traces(channel_ids=[row[col]]).T[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_columns = [col for col in recording_sessions_df if \"trace\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_sessions_df[\"lfp_indexes\"] = recording_sessions_df[trace_columns[0]].apply(lambda x: np.arange(0, 20 * x.shape[0] + 1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,       20,       40, ..., 79697460, 79697480, 79697500])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"lfp_indexes\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,        1,        2, ..., 79698583, 79698584, 79698585],\n",
       "      dtype=uint32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"voltage_indexes\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_session</th>\n",
       "      <th>ephys_name</th>\n",
       "      <th>voltage_timestamps</th>\n",
       "      <th>voltage_indexes</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>eib_mPFC</th>\n",
       "      <th>eib_vHPC</th>\n",
       "      <th>eib_BLA</th>\n",
       "      <th>...</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "      <th>all_ch_lfp</th>\n",
       "      <th>mPFC_lfp_trace</th>\n",
       "      <th>vHPC_lfp_trace</th>\n",
       "      <th>BLA_lfp_trace</th>\n",
       "      <th>LH_lfp_trace</th>\n",
       "      <th>MD_lfp_trace</th>\n",
       "      <th>lfp_indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>[3478533, 3478534, 3478535, 3478536, 3478537, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "      <td>[0.07365118, 0.11047677, 0.18994251, 0.2364590...</td>\n",
       "      <td>[-0.26256362, -0.19967411, -0.015722372, 0.150...</td>\n",
       "      <td>[0.28542638, 0.8104071, 1.2419446, 1.0261759, ...</td>\n",
       "      <td>[0.0040029064, -0.11808574, -0.052037787, 0.17...</td>\n",
       "      <td>[0.103898674, -0.011922799, 0.020439083, 0.136...</td>\n",
       "      <td>[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>20230617_115521_standard_comp_to_omission_D1_s...</td>\n",
       "      <td>[3478533, 3478534, 3478535, 3478536, 3478537, ...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "      <td>[0.9489666, 1.1787612, 1.587285, 1.6766496, 1....</td>\n",
       "      <td>[-0.59670866, -0.5804559, -0.500353, -0.304158...</td>\n",
       "      <td>[0.57716405, 1.2267566, 1.8559785, 1.9170899, ...</td>\n",
       "      <td>[1.0252244, 1.567814, 1.8645895, 1.6457549, 1....</td>\n",
       "      <td>[0.8103085, 0.9092951, 0.8448387, 0.6675837, 0...</td>\n",
       "      <td>[0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   recording_session  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "\n",
       "                                          ephys_name  \\\n",
       "0  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "1  20230617_115521_standard_comp_to_omission_D1_s...   \n",
       "\n",
       "                                  voltage_timestamps  \\\n",
       "0  [3478533, 3478534, 3478535, 3478536, 3478537, ...   \n",
       "1  [3478533, 3478534, 3478535, 3478536, 3478537, ...   \n",
       "\n",
       "                                     voltage_indexes subject_id  Cohort  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        1.1       2   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...        1.2       2   \n",
       "\n",
       "  Subject  eib_mPFC  eib_vHPC  eib_BLA  ...  spike_interface_BLA  \\\n",
       "0     1.1       NaN        16       17  ...                   30   \n",
       "1     1.2       NaN        31       30  ...                   30   \n",
       "\n",
       "   spike_interface_LH spike_interface_MD  \\\n",
       "0                  29                 28   \n",
       "1                  29                 28   \n",
       "\n",
       "                                          all_ch_lfp  \\\n",
       "0  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...   \n",
       "1  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...   \n",
       "\n",
       "                                      mPFC_lfp_trace  \\\n",
       "0  [0.07365118, 0.11047677, 0.18994251, 0.2364590...   \n",
       "1  [0.9489666, 1.1787612, 1.587285, 1.6766496, 1....   \n",
       "\n",
       "                                      vHPC_lfp_trace  \\\n",
       "0  [-0.26256362, -0.19967411, -0.015722372, 0.150...   \n",
       "1  [-0.59670866, -0.5804559, -0.500353, -0.304158...   \n",
       "\n",
       "                                       BLA_lfp_trace  \\\n",
       "0  [0.28542638, 0.8104071, 1.2419446, 1.0261759, ...   \n",
       "1  [0.57716405, 1.2267566, 1.8559785, 1.9170899, ...   \n",
       "\n",
       "                                        LH_lfp_trace  \\\n",
       "0  [0.0040029064, -0.11808574, -0.052037787, 0.17...   \n",
       "1  [1.0252244, 1.567814, 1.8645895, 1.6457549, 1....   \n",
       "\n",
       "                                        MD_lfp_trace  \\\n",
       "0  [0.103898674, -0.011922799, 0.020439083, 0.136...   \n",
       "1  [0.8103085, 0.9092951, 0.8448387, 0.6675837, 0...   \n",
       "\n",
       "                                         lfp_indexes  \n",
       "0  [0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...  \n",
       "1  [0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 2...  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3984875,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_sessions_df[\"mPFC_lfp_trace\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       0,       20,       40, ..., 79697460, 79697480, 79697500])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 20 * recording_sessions_df[\"mPFC_lfp_trace\"].iloc[0].shape[0] + 1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the timestamps of each LFP sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(recording_name_to_all_ch_lfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "79698586/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_name_to_all_ch_lfp[\"20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged\"].get_traces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtering for all trials that we got the LFP for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df[all_trials_df[\"recording_file\"].isin(recording_name_to_all_ch_lfp.keys())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_trials_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding trial numbers based on timestamp ordering for each recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df.groupby('recording_file').apply(lambda g: compute_sorted_index(g, value_column='time', index_column='trial_number')).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_number\"] = all_trials_df[\"trial_number\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the LFP trace information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = all_trials_df.merge(CHANNEL_MAPPING_DF, left_on=\"current_subject\", right_on=\"Subject\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.drop(columns=[col for col in channel_map_and_all_trials_df.columns if \"eib\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.drop(columns=[\"Subject\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.to_csv(\"./proc/trial_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.to_pickle(\"./proc/trial_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linking up all LFP calculations with all the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df[\"all_ch_lfp\"] = channel_map_and_all_trials_df[\"recording_file\"].map(recording_name_to_all_ch_lfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a new row for each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_region_col = [col for col in CHANNEL_MAPPING_DF if \"spike_interface\" in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [col for col in channel_map_and_all_trials_df.columns if col not in brain_region_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_region_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in brain_region_col:\n",
    "    channel_map_and_all_trials_df[col] = channel_map_and_all_trials_df[col].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in brain_region_col:\n",
    "    print(col)\n",
    "    channel_map_and_all_trials_df[\"{}_baseline_lfp_trace\".format(col.strip(\"spike_interface\").strip(\"_\"))] = channel_map_and_all_trials_df.apply(lambda row: row[\"all_ch_lfp\"].get_traces(channel_ids=[row[col]], start_frame=row[\"baseline_lfp_timestamp_range\"][0], end_frame=row[\"baseline_lfp_timestamp_range\"][1]).T[0], axis=1)\n",
    "\n",
    "    channel_map_and_all_trials_df[\"{}_trial_lfp_trace\".format(col.strip(\"spike_interface\").strip(\"_\"))] = channel_map_and_all_trials_df.apply(lambda row: row[\"all_ch_lfp\"].get_traces(channel_ids=[row[col]], start_frame=row[\"trial_lfp_timestamp_range\"][0], end_frame=row[\"trial_lfp_timestamp_range\"][1]).T[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df = channel_map_and_all_trials_df.drop(columns=[\"all_ch_lfp\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.to_pickle(\"./proc/full_baseline_and_trial_lfp_traces.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_and_all_trials_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(83177118-3478533)/20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP 2: Extracting the timestamps for the raw ephys recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_to_din_state_df = {}\n",
    "for session, file_to_data in session_to_dir.items():\n",
    "    all_recording_din_state_df = []\n",
    "    for recording_name, subdir_dict in file_to_data.items():\n",
    "        print(recording_name)\n",
    "        current_recording_din_state_df = []\n",
    "\n",
    "        try:\n",
    "            voltage_timestamp_array = file_to_data[recording_name][\"raw\"][\"timestamps\"][\"data\"]\n",
    "            for key, value in file_to_data[recording_name][\"DIO\"].items():\n",
    "                if \"in\" in key:\n",
    "                    print(key)\n",
    "                    din_state_array = file_to_data[recording_name][\"DIO\"][key][\"data\"]\n",
    "                    current_din_state_df = pd.DataFrame(din_state_array)\n",
    "                    current_din_state_df[\"recording_dir\"] = session\n",
    "                    current_din_state_df[\"recording_file\"] = recording_name\n",
    "                    current_din_state_df[\"din\"] = key\n",
    "                    current_recording_din_state_df.append(current_din_state_df)\n",
    "                    if key == TONE_DIN:\n",
    "                        plt.plot([tup[0] for tup in din_state_array], [tup[1] for tup in din_state_array])\n",
    "                        plt.xlabel(\"Timestamp\")\n",
    "                        plt.ylabel(\"State\")\n",
    "                        plt.title(\"Din State Change against Timestamps for {} in {}\".format(key, recording_name))\n",
    "                        plt.show()\n",
    "                        plt.close()\n",
    "            concatted_per_recording_din_state_df = pd.concat(current_recording_din_state_df).sort_values(by=[\"recording_file\", \"din\"]).reset_index(drop=True)\n",
    "            concatted_per_recording_din_state_df[\"time_stamp_index\"] = concatted_per_recording_din_state_df[\"time\"] - voltage_timestamp_array[0][0]\n",
    "            all_recording_din_state_df.append(concatted_per_recording_din_state_df)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    concatted_all_recording_din_state_df = pd.concat(all_recording_din_state_df)\n",
    "    session_to_din_state_df[session] = concatted_all_recording_din_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voltage_timestamp_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "79698586//20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatted_per_recording_din_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recording_din_state_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP 3 Adding the video timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_din_state_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session_to_din_with_frames_df = {}\n",
    "for session_path in all_session_files:   \n",
    "    try:\n",
    "        session_basename = os.path.splitext(os.path.basename(session_path))[0]\n",
    "        print(\"Current Session: {}\".format(session_basename))\n",
    "        file_to_video_timestamps = {}\n",
    "        for video_timestamps in glob.glob(os.path.join(session_path, \"*cameraHWSync\")):\n",
    "            video_basename = os.path.basename(video_timestamps)\n",
    "            print(\"Current Video Name: {}\".format(video_basename))\n",
    "            timestamp_array = trodes.read_exported.read_trodes_extracted_data_file(video_timestamps)[\"data\"][\"PosTimestamp\"]\n",
    "            file_to_video_timestamps[video_basename] = timestamp_array\n",
    "            session_to_din_state_df[session_basename][os.path.basename(video_timestamps)] = session_to_din_state_df[session_basename][\"time\"].apply(lambda x: find_closest_index(sorted_list=timestamp_array, target=x))        \n",
    "        \n",
    "        # Find the maximum length of the arrays in the dictionary\n",
    "        max_length = max(map(len, file_to_video_timestamps.values()))\n",
    "        \n",
    "        # Pad each array with NaN values to make them all the same length\n",
    "        padded_data = {k: np.pad(v, (0, max_length - len(v)), mode='constant', constant_values=np.nan) for k, v in file_to_video_timestamps.items()}\n",
    "        \n",
    "        # Convert the padded data to a dataframe\n",
    "        session_to_din_with_frames_df[session_basename] = pd.DataFrame(padded_data)\n",
    "        session_to_din_with_frames_df[session_basename].to_csv(os.path.join(OUTPUT_DIR, \"{}.frame_to_timestamps.csv\".format(session_basename)))\n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "session_to_din_state_df['20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "session_to_din_with_frames_df['20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOP 4: Combining the video columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_tone_stamp_df = {}\n",
    "for session, timestamps_df in session_to_din_state_df.items():\n",
    "    current_timestamps_df = timestamps_df[(timestamps_df[\"din\"] == TONE_DIN) & (timestamps_df[\"state\"] == TONE_STATE)].reset_index(drop=True)\n",
    "    camera_col = [col for col in current_timestamps_df.columns if \"cameraHWSync\" in col]\n",
    "    id_col = [col for col in current_timestamps_df.columns if \"cameraHWSync\" not in col]\n",
    "    \n",
    "    current_timestamps_df = current_timestamps_df.melt(id_vars=id_col, value_vars=camera_col, var_name='video_file', value_name='video_frame')\n",
    "    current_timestamps_df[\"video_number\"] = current_timestamps_df[\"video_file\"].apply(lambda x: x.strip(\"videoTimeStamps.cameraHWSync\").split(\".\")[-1])\n",
    "    current_timestamps_df[\"subject_info\"] = current_timestamps_df[\"recording_file\"].apply(lambda x: x.split(\"subject\")[-1].strip(\"merged\").strip(\"_\"))\n",
    "    current_timestamps_df[\"condition\"] = np.nan\n",
    "    session_to_tone_stamp_df[session]  = current_timestamps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_to_tone_stamp_df[session]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df = pd.concat(session_to_tone_stamp_df.values()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_tone_stamp_df.to_csv(os.path.join(OUTPUT_DIR, \"{}_tone_timestamp.csv\".format(OUTPUT_PREFIX)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping all rows that have not been labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = TONE_TIMESTAMP_DF.dropna(subset=\"condition\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_trials_df[\"recording_dir\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making the video frame number usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"video_frame\"] = all_trials_df[\"video_frame\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the name of the video so that we can sync it up with the ephys recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"video_name\"]  = all_trials_df[\"video_file\"].apply(lambda x: x.strip(\".videoTimeStamps.cameraHWSync\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting all subject IDs for a given recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using different id extractions for different file formats\n",
    "all_trials_df[\"all_subjects\"] = all_trials_df[\"recording_dir\"].apply(lambda x: x if \"2023\" in x else \"subj\" + \"_\".join(x.split(\"_\")[-5:]))\n",
    "all_trials_df[\"all_subjects\"] = all_trials_df[\"all_subjects\"].apply(lambda x: tuple(sorted([num.strip(\"_\").replace(\"_\",\".\") for num in x.replace(\"-\", \"_\").split(\"subj\")[-1].strip(\"_\").split(\"and\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_trials_df[\"all_subjects\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"current_subject\"] = all_trials_df[\"subject_info\"].apply(lambda x: \".\".join(x.replace(\"-\",\"_\").split(\"_\")[:2])).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"current_subject\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the trial label to win or lose based on who won the trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_outcome\"] = all_trials_df.apply(\n",
    "    lambda x: \"win\" if str(x[\"condition\"]).strip() == str(x[\"current_subject\"]) \n",
    "             else (\"lose\" if str(x[\"condition\"]) in x[\"all_subjects\"] \n",
    "                   else x[\"condition\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_outcome\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the competition closeness as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_closeness_map = {k: \"non_comp\" if \"only\" in str(k).lower() else \"comp\" if type(k) is str else np.nan for k in all_trials_df[\"competition_closeness\"].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "competition_closeness_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"competition_closeness\"] = all_trials_df[\"competition_closeness\"].map(competition_closeness_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"competition_closeness\"] = all_trials_df.apply(lambda x: \"_\".join([str(x[\"trial_outcome\"]), str(x[\"competition_closeness\"])]).strip(\"nan\").strip(\"_\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"competition_closeness\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the LFP index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"lfp_index\"] = (all_trials_df[\"time_stamp_index\"] // (EPHYS_SAMPLING_RATE/LFP_SAMPLING_RATE)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"time\"] = all_trials_df[\"time\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"time_stamp_index\"] = all_trials_df[\"time_stamp_index\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df = all_trials_df.drop(columns=[\"state\", \"din\", \"condition\", \"Unnamed: 13\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_trials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df.groupby([\"competition_closeness\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making columns of the different timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"baseline_lfp_timestamp_range\"] = all_trials_df[\"lfp_index\"].apply(lambda x: (x - TRIAL_DURATION * LFP_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_lfp_timestamp_range\"] = all_trials_df[\"lfp_index\"].apply(lambda x: (x, x + TRIAL_DURATION * LFP_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"baseline_ephys_timestamp_range\"] = all_trials_df[\"time_stamp_index\"].apply(lambda x: (x - TRIAL_DURATION * EPHYS_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_ephys_timestamp_range\"] = all_trials_df[\"time_stamp_index\"].apply(lambda x: (x, x + TRIAL_DURATION * EPHYS_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"baseline_videoframe_range\"] = all_trials_df[\"video_frame\"].apply(lambda x: (x - TRIAL_DURATION * FRAME_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials_df[\"trial_videoframe_range\"] = all_trials_df[\"video_frame\"].apply(lambda x: (x, x + TRIAL_DURATION * FRAME_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
