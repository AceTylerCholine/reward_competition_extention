{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Notebook 0: Setup LFP trial dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "---------\n",
    "This notebook is dedicated to extracting local field potential (LFP) traces from Spikegadgets .rec files \n",
    "for the purpose of analyzing social competition trials in neuroscience research. The notebook processes \n",
    "the raw electrophysiology data, synchronizes it with corresponding video data, and computes various metrics.\n",
    "\n",
    "Dataframe Columns Description:\n",
    "------------------------------\n",
    "- time: Spikegadgets timestamp used during recording.\n",
    "- state: The state of the environmental control unit's (ECU) input for Spikegadgets recordings.\n",
    "- recording_dir: Directory path where the recording file is located.\n",
    "- recording_file: Base name of the recording file without the extension.\n",
    "- din: Identifier of the input from the Spikegadgets ECU.\n",
    "- time_stamp_index: Index representing the specific timestamp of the recording.\n",
    "- video_file: Basename of the associated video file for the trial.\n",
    "- video_frame: Specific video frame number corresponding to the trial.\n",
    "- video_number: Unique number identifying the video associated with the trial.\n",
    "- subject_info: Information about the subject, such as ID, age, or other relevant details.\n",
    "- condition: Label categorizing the trial, typically based on experimental conditions.\n",
    "- competition_closeness: Secondary label detailing the competitive closeness of the trial.\n",
    "- lfp_index: Index associated with the LFP data for the trial.\n",
    "- video_name: Basename of the video file associated with the LFP recording.\n",
    "- baseline_lfp_index_range: Range of LFP indices representing the baseline period of the trial.\n",
    "- trial_lfp_index_range: Range of LFP indices corresponding to the actual trial period.\n",
    "- baseline_ephys_index_range: Range of electrophysiology (ephys) indices representing the baseline period.\n",
    "- trial_ephys_index_range: Range of ephys indices corresponding to the trial period.\n",
    "- baseline_videoframe_range: Range of video frames representing the baseline period of the trial.\n",
    "- trial_videoframe_range: Range of video frames corresponding to the trial period.\n",
    "- all_subjects: List or array of all subjects involved in the trials.\n",
    "- current_subject: ID number or identifier of the subject for the current row in the DataFrame.\n",
    "- trial_outcome: Updated trial label based on the \"condition\" column.\n",
    "\n",
    "Processing Steps:\n",
    "-----------------\n",
    "1. Importing necessary libraries and setting up the environment.\n",
    "2. Loading and preprocessing the tone timestamp data from an Excel file.\n",
    "3. Identifying and processing all session directories containing .rec files.\n",
    "4. Reformatting the DataFrame for analysis, including dropping unnecessary rows and columns.\n",
    "5. Adding columns for different timestamps and ranges (LFP, ephys, video frames).\n",
    "6. Converting trial labels to 'win' or 'lose' based on trial outcomes.\n",
    "7. Adding a column for competition closeness and reformatting it.\n",
    "8. Saving the processed DataFrame to a specified output directory.\n",
    "\n",
    "Outputs:\n",
    "--------\n",
    "- Processed DataFrame saved as a CSV file, containing synchronized and labeled LFP and video data.\n",
    "- Plots or other outputs can be added as per the project's specific analysis requirements.\n",
    "\n",
    "Usage:\n",
    "------\n",
    "- Run the cells in order as they appear.\n",
    "- Ensure that the file paths and directory names match your project's structure.\n",
    "- Customize processing steps according to your project's specific needs.\n",
    "\n",
    "Note:\n",
    "-----\n",
    "- This notebook is part of a larger research project. Ensure compatibility with other components of the project.\n",
    "- The notebook is configured for a specific dataset structure and might require modifications for different data formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_repo = git.Repo(\".\", search_parent_directories=True)\n",
    "git_root = git_repo.git.rev_parse(\"--show-toplevel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nancy/projects/reward_competition_extention'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(git_root, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPHYS_SAMPLING_RATE = 20000\n",
    "LFP_SAMPLING_RATE = 1000\n",
    "TRIAL_DURATION = 10\n",
    "FRAME_RATE = 22\n",
    "ECU_STREAM_ID = \"ECU\"\n",
    "TRODES_STREAM_ID = \"trodes\"\n",
    "LFP_FREQ_MIN = 0.5\n",
    "LFP_FREQ_MAX = 300\n",
    "ELECTRIC_NOISE_FREQ = 60\n",
    "RECORDING_EXTENTION = \"*.rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPHYS_INDEX_COL = \"time_stamp_index\"\n",
    "LFP_INDEX_COL = \"lfp_index\"\n",
    "EPHYS_TIMESTAMP_COL = \"time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_TRIAL_COL = \"condition\"\n",
    "TRIAL_OUTCOME_COL = \"trial_outcome\"\n",
    "RECORDING_DIR_COL = \"recording_dir\"\n",
    "VIDEO_FRAME_COL = \"video_frame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_COL = \"state\"\n",
    "RECORDING_FILE_COL = \"recording_file\"\n",
    "DIN_COL = \"din\"\n",
    "TIME_STAMP_INDEX_COL = \"time_stamp_index\"\n",
    "VIDEO_FILE_COL = \"video_file\"\n",
    "VIDEO_NUMBER_COL = \"video_number\"\n",
    "SUBJECT_INFO_COL = \"subject_info\"\n",
    "COMPETITION_CLOSENESS_COL = \"competition_closeness\"\n",
    "VIDEO_NAME_COL = \"video_name\"\n",
    "BASELINE_LFP_INDEX_RANGE_COL = \"baseline_lfp_index_range\"\n",
    "TRIAL_LFP_INDEX_RANGE_COL = \"trial_lfp_index_range\"\n",
    "BASELINE_EPHYS_INDEX_RANGE_COL = \"baseline_ephys_index_range\"\n",
    "TRIAL_EPHYS_INDEX_RANGE_COL = \"trial_ephys_index_range\"\n",
    "BASELINE_VIDEOFRAME_RANGE_COL = \"baseline_videoframe_range\"\n",
    "TRIAL_VIDEOFRAME_RANGE_COL = \"trial_videoframe_range\"\n",
    "ALL_SUBJECTS_COL = \"all_subjects\"\n",
    "CURRENT_SUBJECT_COL = \"current_subject\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Change based on individual project data location\n",
    "\n",
    "# Spreadsheet of tone time\n",
    "TONE_TIMESTAMP_DF = pd.read_excel(\"../../data/rce_tone_timestamp.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>state</th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>din</th>\n",
       "      <th>time_stamp_index</th>\n",
       "      <th>video_file</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>video_number</th>\n",
       "      <th>subject_info</th>\n",
       "      <th>condition</th>\n",
       "      <th>competition_closeness</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2299.0</th>\n",
       "      <td>3772337.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_and_6_3</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_top_4_base_2</td>\n",
       "      <td>dio_ECU_Din1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_and_6_3.1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_4_base_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300.0</th>\n",
       "      <td>5204112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_and_6_3</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_top_4_base_2</td>\n",
       "      <td>dio_ECU_Din1</td>\n",
       "      <td>1431775.0</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_and_6_3.1...</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_4_base_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301.0</th>\n",
       "      <td>6804107.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_and_6_3</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_top_4_base_2</td>\n",
       "      <td>dio_ECU_Din1</td>\n",
       "      <td>3031770.0</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_and_6_3.1...</td>\n",
       "      <td>3779.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_4_base_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302.0</th>\n",
       "      <td>8604101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_and_6_3</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_top_4_base_2</td>\n",
       "      <td>dio_ECU_Din1</td>\n",
       "      <td>4831764.0</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_and_6_3.1...</td>\n",
       "      <td>6021.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_4_base_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303.0</th>\n",
       "      <td>10204096.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_and_6_3</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_top_4_base_2</td>\n",
       "      <td>dio_ECU_Din1</td>\n",
       "      <td>6431759.0</td>\n",
       "      <td>20221122_161341_omission_subject_6_1_and_6_3.1...</td>\n",
       "      <td>8015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_4_base_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              time  state                                 recording_dir  \\\n",
       "2299.0   3772337.0    1.0  20221122_161341_omission_subject_6_1_and_6_3   \n",
       "2300.0   5204112.0    1.0  20221122_161341_omission_subject_6_1_and_6_3   \n",
       "2301.0   6804107.0    1.0  20221122_161341_omission_subject_6_1_and_6_3   \n",
       "2302.0   8604101.0    1.0  20221122_161341_omission_subject_6_1_and_6_3   \n",
       "2303.0  10204096.0    1.0  20221122_161341_omission_subject_6_1_and_6_3   \n",
       "\n",
       "                                           recording_file           din  \\\n",
       "2299.0  20221122_161341_omission_subject_6_1_top_4_base_2  dio_ECU_Din1   \n",
       "2300.0  20221122_161341_omission_subject_6_1_top_4_base_2  dio_ECU_Din1   \n",
       "2301.0  20221122_161341_omission_subject_6_1_top_4_base_2  dio_ECU_Din1   \n",
       "2302.0  20221122_161341_omission_subject_6_1_top_4_base_2  dio_ECU_Din1   \n",
       "2303.0  20221122_161341_omission_subject_6_1_top_4_base_2  dio_ECU_Din1   \n",
       "\n",
       "        time_stamp_index                                         video_file  \\\n",
       "2299.0               0.0  20221122_161341_omission_subject_6_1_and_6_3.1...   \n",
       "2300.0         1431775.0  20221122_161341_omission_subject_6_1_and_6_3.1...   \n",
       "2301.0         3031770.0  20221122_161341_omission_subject_6_1_and_6_3.1...   \n",
       "2302.0         4831764.0  20221122_161341_omission_subject_6_1_and_6_3.1...   \n",
       "2303.0         6431759.0  20221122_161341_omission_subject_6_1_and_6_3.1...   \n",
       "\n",
       "        video_frame  video_number      subject_info condition  \\\n",
       "2299.0          0.0           1.0  6_1_top_4_base_2       NaN   \n",
       "2300.0       1784.0           1.0  6_1_top_4_base_2       NaN   \n",
       "2301.0       3779.0           1.0  6_1_top_4_base_2       NaN   \n",
       "2302.0       6021.0           1.0  6_1_top_4_base_2       NaN   \n",
       "2303.0       8015.0           1.0  6_1_top_4_base_2       NaN   \n",
       "\n",
       "       competition_closeness Unnamed: 13  \n",
       "2299.0                   NaN         NaN  \n",
       "2300.0                   NaN         NaN  \n",
       "2301.0                   NaN         NaN  \n",
       "2302.0                   NaN         NaN  \n",
       "2303.0                   NaN         NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TONE_TIMESTAMP_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Change based on individual project data location\n",
    "# Where all the recording files are being saved\n",
    "ALL_SESSION_DIR = glob.glob(\"/scratch/back_up/reward_competition_extention/data/omission/*/*.rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/back_up/reward_competition_extention/data/omission/2023_06_17/20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_17/20230617_115641_standard_comp_to_omission_D1_subj_2-2_and_2-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2022_12_02/20221202_134600_omission_and_competition_subject_6_1_and_6_2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_21/20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_20/20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2022_12_03/20221203_154800_omission_and_competition_subject_6_4_and_6_1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_18/20230618_100646_standard_comp_to_omission_D2_subj_2-4_and_2-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_18/20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_19/20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2023_06_19/20230619_115334_standard_comp_to_omission_D3_subj_2-2_and_2-1.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2022_12_14/20221214_125409_om_and_comp_6_1_and_6_3.rec',\n",
       " '/scratch/back_up/reward_competition_extention/data/omission/2022_12_15/20221215_145401_comp_amd_om_6_1_and_6_3.rec']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_SESSION_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"../../proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMPS_CSV = \"rce_tone_timestamps.csv\"\n",
    "TONE_TIMESTAMPS_PKL = \"rce_tone_timestamps.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dropping all rows that have not been labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF = TONE_TIMESTAMP_DF.dropna(subset=ORIGINAL_TRIAL_COL).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20221202_134600_omission_and_competition_subject_6_1_and_6_2',\n",
       " '20221203_154800_omission_and_competition_subject_6_4_and_6_1',\n",
       " '20221214_125409_om_and_comp_6_1_and_6_3',\n",
       " '20221215_145401_comp_amd_om_6_1_and_6_3',\n",
       " '20230612_101430_standard_comp_to_training_D1_subj_1-4_and_1-3',\n",
       " '20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2',\n",
       " '20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1',\n",
       " '20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4',\n",
       " '20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1',\n",
       " '20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(TONE_TIMESTAMP_DF[RECORDING_DIR_COL].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the LFP index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[EPHYS_INDEX_COL] = TONE_TIMESTAMP_DF[EPHYS_INDEX_COL].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[EPHYS_TIMESTAMP_COL] = TONE_TIMESTAMP_DF[EPHYS_TIMESTAMP_COL].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[LFP_INDEX_COL] = (TONE_TIMESTAMP_DF[EPHYS_INDEX_COL] // (EPHYS_SAMPLING_RATE/LFP_SAMPLING_RATE)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making the video frame number usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[VIDEO_FRAME_COL] = TONE_TIMESTAMP_DF[VIDEO_FRAME_COL].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the name of the video so that we can sync it up with the ephys recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[VIDEO_NAME_COL]  = TONE_TIMESTAMP_DF[VIDEO_FILE_COL].apply(lambda x: x.strip(\".videoTimeStamps.cameraHWSync\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Making columns of the different timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[BASELINE_LFP_INDEX_RANGE_COL] = TONE_TIMESTAMP_DF[LFP_INDEX_COL].apply(lambda x: (x - TRIAL_DURATION * LFP_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[TRIAL_LFP_INDEX_RANGE_COL] = TONE_TIMESTAMP_DF[LFP_INDEX_COL].apply(lambda x: (x, x + TRIAL_DURATION * LFP_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[BASELINE_EPHYS_INDEX_RANGE_COL] = TONE_TIMESTAMP_DF[EPHYS_INDEX_COL].apply(lambda x: (x - TRIAL_DURATION * EPHYS_SAMPLING_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[TRIAL_EPHYS_INDEX_RANGE_COL] = TONE_TIMESTAMP_DF[EPHYS_INDEX_COL].apply(lambda x: (x, x + TRIAL_DURATION * EPHYS_SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[BASELINE_VIDEOFRAME_RANGE_COL] = TONE_TIMESTAMP_DF[VIDEO_FRAME_COL].apply(lambda x: (x - TRIAL_DURATION * FRAME_RATE, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[TRIAL_VIDEOFRAME_RANGE_COL] = TONE_TIMESTAMP_DF[VIDEO_FRAME_COL].apply(lambda x: (x, x + TRIAL_DURATION * FRAME_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'state', 'recording_dir', 'recording_file', 'din',\n",
       "       'time_stamp_index', 'video_file', 'video_frame', 'video_number',\n",
       "       'subject_info', 'condition', 'competition_closeness', 'Unnamed: 13',\n",
       "       'lfp_index', 'video_name', 'baseline_lfp_index_range',\n",
       "       'trial_lfp_index_range', 'baseline_ephys_index_range',\n",
       "       'trial_ephys_index_range', 'baseline_videoframe_range',\n",
       "       'trial_videoframe_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TONE_TIMESTAMP_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF = TONE_TIMESTAMP_DF.drop(columns=[\"state\", \"din\", \"Unnamed: 13\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TONE_TIMESTAMPS_FILE_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m TONE_TIMESTAMP_DF\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIR, \u001b[43mTONE_TIMESTAMPS_FILE_NAME\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TONE_TIMESTAMPS_FILE_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "TONE_TIMESTAMP_DF.to_csv(os.path.join(OUTPUT_DIR, TONE_TIMESTAMPS_FILE_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NOTE: Rest of notebook is project specific processing of collected data. Run the cells below if the format is similar to original project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting all subject IDs for a given recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using different id extractions for different file formats\n",
    "TONE_TIMESTAMP_DF[ALL_SUBJECTS_COL] = TONE_TIMESTAMP_DF[RECORDING_DIR_COL].apply(lambda x: x if \"2023\" in x else \"subj\" + \"_\".join(x.split(\"_\")[-5:]))\n",
    "TONE_TIMESTAMP_DF[ALL_SUBJECTS_COL] = TONE_TIMESTAMP_DF[ALL_SUBJECTS_COL].apply(lambda x: tuple(sorted([num.strip(\"_\").replace(\"_\",\".\") for num in x.replace(\"-\", \"_\").split(\"subj\")[-1].strip(\"_\").split(\"and\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([('6.1', '6.2'), ('6.1', '6.4'), ('6.1', '6.3'), ('1.3', '1.4'),\n",
       "       ('1.1', '1.2'), ('1.1', '1.4'), ('1.2', '1.4')], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TONE_TIMESTAMP_DF[ALL_SUBJECTS_COL].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[CURRENT_SUBJECT_COL] = TONE_TIMESTAMP_DF[SUBJECT_INFO_COL].apply(lambda x: \".\".join(x.replace(\"-\",\"_\").split(\"_\")[:2])).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6.1', '1.3', '1.4', '1.1', '1.2'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TONE_TIMESTAMP_DF[CURRENT_SUBJECT_COL].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the trial label to win or lose based on who won the trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[TRIAL_OUTCOME_COL] = TONE_TIMESTAMP_DF.apply(\n",
    "    lambda x: \"win\" if str(x[ORIGINAL_TRIAL_COL]).strip() == str(x[CURRENT_SUBJECT_COL]) \n",
    "             else (\"lose\" if str(x[ORIGINAL_TRIAL_COL]) in x[ALL_SUBJECTS_COL] \n",
    "                   else x[ORIGINAL_TRIAL_COL]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rewarded', 'omission', 'win', 'lose'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TONE_TIMESTAMP_DF[TRIAL_OUTCOME_COL].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding the competition closeness as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_closeness_map = {k: \"non_comp\" if \"only\" in str(k).lower() else \"comp\" if type(k) is str else np.nan for k in TONE_TIMESTAMP_DF[COMPETITION_CLOSENESS_COL].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan: nan,\n",
       " 'Subj 1 Only': 'non_comp',\n",
       " 'Subj 2 blocking Subj 1': 'comp',\n",
       " 'Subj 1 then Subj 2': 'comp',\n",
       " 'Subj 1 blocking Subj 2': 'comp',\n",
       " 'Subj 2 Only': 'non_comp',\n",
       " 'Subj 2 then Subj 1': 'comp',\n",
       " 'Close Call': 'comp'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competition_closeness_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[COMPETITION_CLOSENESS_COL] = TONE_TIMESTAMP_DF[COMPETITION_CLOSENESS_COL].map(competition_closeness_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF[COMPETITION_CLOSENESS_COL] = TONE_TIMESTAMP_DF.apply(lambda x: \"_\".join([str(x[TRIAL_OUTCOME_COL]), str(x[COMPETITION_CLOSENESS_COL])]).strip(\"nan\").strip(\"_\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rewarded', 'omission', 'win_non_comp', 'win_comp',\n",
       "       'lose_non_comp', 'lose_comp'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TONE_TIMESTAMP_DF[COMPETITION_CLOSENESS_COL].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF = TONE_TIMESTAMP_DF.drop(columns=[STATE_COL, DIN_COL, ORIGINAL_TRIAL_COL], errors=\"ignore\")\n",
    "TONE_TIMESTAMP_DF = TONE_TIMESTAMP_DF.drop(columns=[col for col in TONE_TIMESTAMP_DF.columns if \"unnamed\" in col.lower()], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>time_stamp_index</th>\n",
       "      <th>video_file</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>video_number</th>\n",
       "      <th>subject_info</th>\n",
       "      <th>lfp_index</th>\n",
       "      <th>video_name</th>\n",
       "      <th>baseline_lfp_index_range</th>\n",
       "      <th>trial_lfp_index_range</th>\n",
       "      <th>baseline_ephys_index_range</th>\n",
       "      <th>trial_ephys_index_range</th>\n",
       "      <th>baseline_videoframe_range</th>\n",
       "      <th>trial_videoframe_range</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>trial_outcome</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>competition_closeness</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lose_comp</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lose_non_comp</th>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omission</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rewarded</th>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win_comp</th>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win_non_comp</th>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  recording_dir  recording_file  time_stamp_index  \\\n",
       "competition_closeness                                                          \n",
       "lose_comp               105            105             105               105   \n",
       "lose_non_comp            89             89              89                89   \n",
       "omission                 48             48              48                48   \n",
       "rewarded                290            290             290               290   \n",
       "win_comp                 77             77              77                77   \n",
       "win_non_comp            134            134             134               134   \n",
       "\n",
       "                       video_file  video_frame  video_number  subject_info  \\\n",
       "competition_closeness                                                        \n",
       "lose_comp                     105          105           105           105   \n",
       "lose_non_comp                  89           89            89            89   \n",
       "omission                       48           48            48            48   \n",
       "rewarded                      290          290           290           290   \n",
       "win_comp                       77           77            77            77   \n",
       "win_non_comp                  134          134           134           134   \n",
       "\n",
       "                       lfp_index  video_name  baseline_lfp_index_range  \\\n",
       "competition_closeness                                                    \n",
       "lose_comp                    105         105                       105   \n",
       "lose_non_comp                 89          89                        89   \n",
       "omission                      48          48                        48   \n",
       "rewarded                     290         290                       290   \n",
       "win_comp                      77          77                        77   \n",
       "win_non_comp                 134         134                       134   \n",
       "\n",
       "                       trial_lfp_index_range  baseline_ephys_index_range  \\\n",
       "competition_closeness                                                      \n",
       "lose_comp                                105                         105   \n",
       "lose_non_comp                             89                          89   \n",
       "omission                                  48                          48   \n",
       "rewarded                                 290                         290   \n",
       "win_comp                                  77                          77   \n",
       "win_non_comp                             134                         134   \n",
       "\n",
       "                       trial_ephys_index_range  baseline_videoframe_range  \\\n",
       "competition_closeness                                                       \n",
       "lose_comp                                  105                        105   \n",
       "lose_non_comp                               89                         89   \n",
       "omission                                    48                         48   \n",
       "rewarded                                   290                        290   \n",
       "win_comp                                    77                         77   \n",
       "win_non_comp                               134                        134   \n",
       "\n",
       "                       trial_videoframe_range  all_subjects  current_subject  \\\n",
       "competition_closeness                                                          \n",
       "lose_comp                                 105           105              105   \n",
       "lose_non_comp                              89            89               89   \n",
       "omission                                   48            48               48   \n",
       "rewarded                                  290           290              290   \n",
       "win_comp                                   77            77               77   \n",
       "win_non_comp                              134           134              134   \n",
       "\n",
       "                       trial_outcome  \n",
       "competition_closeness                 \n",
       "lose_comp                        105  \n",
       "lose_non_comp                     89  \n",
       "omission                          48  \n",
       "rewarded                         290  \n",
       "win_comp                          77  \n",
       "win_non_comp                     134  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TONE_TIMESTAMP_DF.groupby([COMPETITION_CLOSENESS_COL]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>time_stamp_index</th>\n",
       "      <th>video_file</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>video_number</th>\n",
       "      <th>subject_info</th>\n",
       "      <th>competition_closeness</th>\n",
       "      <th>lfp_index</th>\n",
       "      <th>video_name</th>\n",
       "      <th>baseline_lfp_index_range</th>\n",
       "      <th>trial_lfp_index_range</th>\n",
       "      <th>baseline_ephys_index_range</th>\n",
       "      <th>trial_ephys_index_range</th>\n",
       "      <th>baseline_videoframe_range</th>\n",
       "      <th>trial_videoframe_range</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>trial_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6310663</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>1390826</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>1734</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>69541</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(59541, 69541)</td>\n",
       "      <td>(69541, 79541)</td>\n",
       "      <td>(1190826, 1390826)</td>\n",
       "      <td>(1390826, 1590826)</td>\n",
       "      <td>(1514, 1734)</td>\n",
       "      <td>(1734, 1954)</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7910662</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>2990825</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>3728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>149541</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(139541, 149541)</td>\n",
       "      <td>(149541, 159541)</td>\n",
       "      <td>(2790825, 2990825)</td>\n",
       "      <td>(2990825, 3190825)</td>\n",
       "      <td>(3508, 3728)</td>\n",
       "      <td>(3728, 3948)</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9710660</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>4790823</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>5972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>239541</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(229541, 239541)</td>\n",
       "      <td>(239541, 249541)</td>\n",
       "      <td>(4590823, 4790823)</td>\n",
       "      <td>(4790823, 4990823)</td>\n",
       "      <td>(5752, 5972)</td>\n",
       "      <td>(5972, 6192)</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11310658</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>6390821</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>7966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>omission</td>\n",
       "      <td>319541</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(309541, 319541)</td>\n",
       "      <td>(319541, 329541)</td>\n",
       "      <td>(6190821, 6390821)</td>\n",
       "      <td>(6390821, 6590821)</td>\n",
       "      <td>(7746, 7966)</td>\n",
       "      <td>(7966, 8186)</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>omission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12810657</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>7890820</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>9836</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6_1_top_2_base_3</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>394541</td>\n",
       "      <td>20221202_134600_omission_and_competition_subje...</td>\n",
       "      <td>(384541, 394541)</td>\n",
       "      <td>(394541, 404541)</td>\n",
       "      <td>(7690820, 7890820)</td>\n",
       "      <td>(7890820, 8090820)</td>\n",
       "      <td>(9616, 9836)</td>\n",
       "      <td>(9836, 10056)</td>\n",
       "      <td>(6.1, 6.2)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>rewarded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time                                      recording_dir  \\\n",
       "0   6310663  20221202_134600_omission_and_competition_subje...   \n",
       "1   7910662  20221202_134600_omission_and_competition_subje...   \n",
       "2   9710660  20221202_134600_omission_and_competition_subje...   \n",
       "3  11310658  20221202_134600_omission_and_competition_subje...   \n",
       "4  12810657  20221202_134600_omission_and_competition_subje...   \n",
       "\n",
       "                                      recording_file  time_stamp_index  \\\n",
       "0  20221202_134600_omission_and_competition_subje...           1390826   \n",
       "1  20221202_134600_omission_and_competition_subje...           2990825   \n",
       "2  20221202_134600_omission_and_competition_subje...           4790823   \n",
       "3  20221202_134600_omission_and_competition_subje...           6390821   \n",
       "4  20221202_134600_omission_and_competition_subje...           7890820   \n",
       "\n",
       "                                          video_file  video_frame  \\\n",
       "0  20221202_134600_omission_and_competition_subje...         1734   \n",
       "1  20221202_134600_omission_and_competition_subje...         3728   \n",
       "2  20221202_134600_omission_and_competition_subje...         5972   \n",
       "3  20221202_134600_omission_and_competition_subje...         7966   \n",
       "4  20221202_134600_omission_and_competition_subje...         9836   \n",
       "\n",
       "   video_number      subject_info competition_closeness  lfp_index  \\\n",
       "0           1.0  6_1_top_2_base_3              rewarded      69541   \n",
       "1           1.0  6_1_top_2_base_3              rewarded     149541   \n",
       "2           1.0  6_1_top_2_base_3              rewarded     239541   \n",
       "3           1.0  6_1_top_2_base_3              omission     319541   \n",
       "4           1.0  6_1_top_2_base_3              rewarded     394541   \n",
       "\n",
       "                                          video_name baseline_lfp_index_range  \\\n",
       "0  20221202_134600_omission_and_competition_subje...           (59541, 69541)   \n",
       "1  20221202_134600_omission_and_competition_subje...         (139541, 149541)   \n",
       "2  20221202_134600_omission_and_competition_subje...         (229541, 239541)   \n",
       "3  20221202_134600_omission_and_competition_subje...         (309541, 319541)   \n",
       "4  20221202_134600_omission_and_competition_subje...         (384541, 394541)   \n",
       "\n",
       "  trial_lfp_index_range baseline_ephys_index_range trial_ephys_index_range  \\\n",
       "0        (69541, 79541)         (1190826, 1390826)      (1390826, 1590826)   \n",
       "1      (149541, 159541)         (2790825, 2990825)      (2990825, 3190825)   \n",
       "2      (239541, 249541)         (4590823, 4790823)      (4790823, 4990823)   \n",
       "3      (319541, 329541)         (6190821, 6390821)      (6390821, 6590821)   \n",
       "4      (394541, 404541)         (7690820, 7890820)      (7890820, 8090820)   \n",
       "\n",
       "  baseline_videoframe_range trial_videoframe_range all_subjects  \\\n",
       "0              (1514, 1734)           (1734, 1954)   (6.1, 6.2)   \n",
       "1              (3508, 3728)           (3728, 3948)   (6.1, 6.2)   \n",
       "2              (5752, 5972)           (5972, 6192)   (6.1, 6.2)   \n",
       "3              (7746, 7966)           (7966, 8186)   (6.1, 6.2)   \n",
       "4              (9616, 9836)          (9836, 10056)   (6.1, 6.2)   \n",
       "\n",
       "  current_subject trial_outcome  \n",
       "0             6.1      rewarded  \n",
       "1             6.1      rewarded  \n",
       "2             6.1      rewarded  \n",
       "3             6.1      omission  \n",
       "4             6.1      rewarded  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TONE_TIMESTAMP_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "TONE_TIMESTAMP_DF.to_csv(os.path.join(OUTPUT_DIR, TONE_TIMESTAMPS_CSV))\n",
    "TONE_TIMESTAMP_DF.to_pickle(os.path.join(OUTPUT_DIR, TONE_TIMESTAMPS_PKL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
