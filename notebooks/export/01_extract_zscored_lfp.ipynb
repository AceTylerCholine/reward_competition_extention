{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Notebook 1: Extract Z-scored LFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This Jupyter notebook focuses on extracting local field potential (LFP) traces from Spikegadgets `.rec` files, specifically for neuroscience research related to social competition trials. The notebook includes procedures for preprocessing and synchronizing raw electrophysiology data with corresponding video data and computes various metrics, including Z-scored LFPs.\n",
    "\n",
    "### Inputs & Data Sources\n",
    "- **Electrophysiology and LFP Parameters**: Constants like `EPHYS_SAMPLING_RATE`, `LFP_SAMPLING_RATE`, `TRIAL_DURATION`, etc., define basic parameters for LFP data processing.\n",
    "- **Recording Information**: Stream IDs (`ECU_STREAM_ID`, `TRODES_STREAM_ID`), recording extension (`RECORDING_EXTENSION`), and paths to recording directories (`ALL_SESSION_DIR`).\n",
    "- **DataFrames for Mapping and Timestamps**: `CHANNEL_MAPPING_DF` for channel mapping, and `TONE_TIMESTAMP_DF` for tone timestamps, loaded from external sources.\n",
    "- **Constants for DataFrame Columns**: Names for various columns in the DataFrame, defined in an all-caps snake case format, such as `EPHYS_INDEX_COL`, `LFP_INDEX_COL`, etc.\n",
    "\n",
    "### Output & Utility\n",
    "- **Processed Data**: The notebook outputs processed data, particularly the Z-scored LFP traces, which are critical for further analysis in neuroscience research.\n",
    "- **Data Files**: Outputs are saved in various formats (`CSV`, `Pickle`) in a specified output directory (`OUTPUT_DIR`).\n",
    "- **Visualization**: While not explicitly mentioned, the notebook has the potential for data visualization (plots) based on processed LFP data.\n",
    "\n",
    "### Processing Workflow\n",
    "1. **LFP Extraction and Preprocessing**: \n",
    "    - Iterates through recording sessions to process `.rec` files.\n",
    "    - Applies a series of preprocessing steps like bandpass filtering, notch filtering, resampling, and Z-scoring on the LFP data.\n",
    "    - Exception handling for cases where the recording doesn't contain specified stream IDs.\n",
    "\n",
    "2. **DataFrame Manipulation and Merging**:\n",
    "    - Filtering `TONE_TIMESTAMP_DF` for trials with obtained LFP.\n",
    "    - Addition of trial numbers and merging with `CHANNEL_MAPPING_DF`.\n",
    "    - Dropping unnecessary columns and restructuring for analysis.\n",
    "\n",
    "3. **LFP Trace Extraction for Each Trial and Brain Region**: \n",
    "    - Linking LFP calculations with trials.\n",
    "    - Creating new rows for each brain region, extracting baseline, trial, and combined LFP traces.\n",
    "    - Results in a comprehensive DataFrame that combines trial information with corresponding LFP traces.\n",
    "\n",
    "4. **Data Storage**:\n",
    "    - Saving processed DataFrame in both `CSV` and `Pickle` formats for easy access and future use.\n",
    "\n",
    "### Usage Notes\n",
    "- The notebook is project-specific and tailored for a particular dataset structure, requiring modifications for different data formats.\n",
    "- Users should ensure file paths and directory names match their project's structure and adjust constants and parameters as needed for their specific analysis requirements.\n",
    "- The notebook forms a part of a larger research framework, thus necessitating compatibility checks with other components of the project.\n",
    "\n",
    "### Dependencies\n",
    "- Python Libraries: `sys`, `os`, `glob`, `numpy`, `pandas`, `spikeinterface`\n",
    "- External Data: Channel mapping and tone timestamp files, along with Spikegadgets `.rec` files.\n",
    "\n",
    "### Customization and Scalability\n",
    "- The notebook's modular design allows for easy adaptation to different datasets or extensions to include additional processing steps.\n",
    "- Functions and processing steps are clearly demarcated, facilitating straightforward updates or enhancements.\n",
    "\n",
    "### Conclusion\n",
    "This notebook is a vital tool in the preprocessing and analysis of LFP data from Spikegadgets recordings, integral to neuroscience research focused on social competition trials. It offers a structured approach to handle, process, and store electrophysiological data, ensuring reproducibility and efficiency in research workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "git_repo = git.Repo(\".\", search_parent_directories=True)\n",
    "git_root = git_repo.git.rev_parse(\"--show-toplevel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nancy/projects/reward_competition_extention'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(git_root, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPHYS_SAMPLING_RATE = 20000\n",
    "LFP_SAMPLING_RATE = 1000\n",
    "TRIAL_DURATION = 10\n",
    "FRAME_RATE = 22\n",
    "ECU_STREAM_ID = \"ECU\"\n",
    "TRODES_STREAM_ID = \"trodes\"\n",
    "LFP_FREQ_MIN = 0.5\n",
    "LFP_FREQ_MAX = 300\n",
    "ELECTRIC_NOISE_FREQ = 60\n",
    "RECORDING_EXTENTION = \"*.rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPHYS_INDEX_COL = \"time_stamp_index\"\n",
    "LFP_INDEX_COL = \"lfp_index\"\n",
    "EPHYS_TIMESTAMP_COL = \"time\"\n",
    "RECORDING_FILE_COL = \"recording_file\"\n",
    "RECORDING_DIR_COL = \"recording_dir\"\n",
    "BASELINE_LFP_INDEX_RANGE_COL = \"baseline_lfp_index_range\"\n",
    "TRIAL_LFP_INDEX_RANGE_COL = \"trial_lfp_index_range\"\n",
    "BASELINE_EPHYS_INDEX_RANGE_COL = \"baseline_ephys_index_range\"\n",
    "TRIAL_EPHYS_INDEX_RANGE_COL = \"trial_ephys_index_range\"\n",
    "BASELINE_VIDEOFRAME_RANGE_COL = \"baseline_videoframe_range\"\n",
    "TRIAL_VIDEOFRAME_RANGE_COL = \"trial_videoframe_range\"\n",
    "CURRENT_SUBJECT_COL = \"current_subject\"\n",
    "ALL_CH_LFP_COL = \"all_ch_lfp\"\n",
    "SUBJECT_COL = \"Subject\"\n",
    "TRIAL_NUMBER_COL = \"trial_number\"\n",
    "SPIKE_INTERFACE_COL = \"spike_interface\"\n",
    "EIB_COL = \"eib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: Change based on individual project data location\n",
    "\n",
    "# Spreadsheet of channel mapping\n",
    "CHANNEL_MAPPING_DF = pd.read_excel(os.path.join(git_root, \"data/channel_mapping.xlsx\"))\n",
    "# Spreadsheet of tone time\n",
    "SPIKEGADGETS_EXTRACTED_DF = pd.read_pickle(\"./proc/rce_pilot_2_trodes_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>eib_mPFC</th>\n",
       "      <th>eib_vHPC</th>\n",
       "      <th>eib_BLA</th>\n",
       "      <th>eib_LH</th>\n",
       "      <th>eib_MD</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cohort  Subject  eib_mPFC  eib_vHPC  eib_BLA  eib_LH  eib_MD  \\\n",
       "0       1      6.1       NaN        15       14      13      31   \n",
       "1       1      6.2       NaN        15       14      13      31   \n",
       "2       1      6.3       NaN        15       14      13      31   \n",
       "3       1      6.4       NaN        15       14      13      31   \n",
       "4       2      1.1       NaN        16       17      18      19   \n",
       "\n",
       "   spike_interface_mPFC  spike_interface_vHPC  spike_interface_BLA  \\\n",
       "0                  21.0                  15.0                 14.0   \n",
       "1                   NaN                   NaN                  NaN   \n",
       "2                   NaN                   NaN                  NaN   \n",
       "3                   NaN                   NaN                  NaN   \n",
       "4                   5.0                  31.0                 30.0   \n",
       "\n",
       "   spike_interface_LH  spike_interface_MD  \n",
       "0                13.0                16.0  \n",
       "1                 NaN                 NaN  \n",
       "2                 NaN                 NaN  \n",
       "3                 NaN                 NaN  \n",
       "4                29.0                28.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHANNEL_MAPPING_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: Change based on individual project data location\n",
    "# Where all the recording files are being saved\n",
    "ALL_SESSION_DIR = glob.glob(\"/scratch/back_up/reward_competition_extention/data/standard/2023_06_16/*.rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/back_up/reward_competition_extention/data/standard/2023_06_16/20230616_111904_standard_comp_to_training_D4_subj_1-4_and_1-2.rec']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_SESSION_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TONE_TIMESTAMPS_CSV = \"rce_tone_timestamps.csv\"\n",
    "TONE_TIMESTAMPS_PKL = \"rce_tone_timestamps.pkl\"\n",
    "FULL_LFP_TRACES_PKL = \"full_baseline_and_trial_lfp_traces.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred: stream_id trodes is not in ['ECU']\n",
      "20230616_111904_standard_comp_to_training_D4_subj_1-4_t4b3L_box1_merged\n",
      "20230616_111904_standard_comp_to_training_D4_subj_1-2_t2b2L_box2_merged\n"
     ]
    }
   ],
   "source": [
    "recording_name_to_all_ch_lfp = {}\n",
    "# Going through all the recording sessions \n",
    "for session_dir in ALL_SESSION_DIR:\n",
    "    # Going through all the recordings in each session\n",
    "    for recording_path in glob.glob(os.path.join(session_dir, RECORDING_EXTENTION)):\n",
    "        try:\n",
    "            recording_basename = os.path.splitext(os.path.basename(recording_path))[0]\n",
    "            # checking to see if the recording has an ECU component\n",
    "            # if it doesn't, then the next one be extracted\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=ECU_STREAM_ID)\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=TRODES_STREAM_ID)\n",
    "            print(recording_basename)\n",
    "            # Preprocessing the LFP\n",
    "            current_recording = sp.bandpass_filter(current_recording, freq_min=LFP_FREQ_MIN, freq_max=LFP_FREQ_MAX)\n",
    "            current_recording = sp.notch_filter(current_recording, freq=ELECTRIC_NOISE_FREQ)\n",
    "            current_recording = sp.resample(current_recording, resample_rate=LFP_SAMPLING_RATE)\n",
    "            current_recording = sp.zscore(current_recording)\n",
    "            recording_name_to_all_ch_lfp[recording_basename] = current_recording\n",
    "        except Exception as error:\n",
    "            # handle the exception\n",
    "            print(\"An exception occurred:\", error) # An exception occurred: division by zero\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the channel mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF = CHANNEL_MAPPING_DF.drop(columns=[col for col in CHANNEL_MAPPING_DF.columns if \"eib\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in CHANNEL_MAPPING_DF.columns:\n",
    "    if \"spike_interface\" in col:\n",
    "        CHANNEL_MAPPING_DF[col] = CHANNEL_MAPPING_DF[col].fillna(0)\n",
    "        CHANNEL_MAPPING_DF[col] = CHANNEL_MAPPING_DF[col].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cohort  Subject spike_interface_mPFC spike_interface_vHPC  \\\n",
       "0       1      6.1                   21                   15   \n",
       "1       1      6.2                    0                    0   \n",
       "2       1      6.3                    0                    0   \n",
       "3       1      6.4                    0                    0   \n",
       "4       2      1.1                    5                   31   \n",
       "5       2      1.2                   10                   31   \n",
       "6       2      1.3                    9                   31   \n",
       "7       2      1.4                   15                   31   \n",
       "\n",
       "  spike_interface_BLA spike_interface_LH spike_interface_MD  \n",
       "0                  14                 13                 16  \n",
       "1                   0                  0                  0  \n",
       "2                   0                  0                  0  \n",
       "3                   0                  0                  0  \n",
       "4                  30                 29                 28  \n",
       "5                  30                 29                 28  \n",
       "6                  30                 29                 28  \n",
       "7                  30                 29                 28  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHANNEL_MAPPING_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding all the brain region to ch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF[SUBJECT_COL] = CHANNEL_MAPPING_DF[SUBJECT_COL].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merging the recording and the channel dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_dir</th>\n",
       "      <th>recording</th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "      <th>description</th>\n",
       "      <th>byte_order</th>\n",
       "      <th>original_file</th>\n",
       "      <th>clockrate</th>\n",
       "      <th>trodes_version</th>\n",
       "      <th>compile_date</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>display_order</th>\n",
       "      <th>clock rate</th>\n",
       "      <th>session_path</th>\n",
       "      <th>first_dtype_name</th>\n",
       "      <th>first_item_data</th>\n",
       "      <th>last_dtype_name</th>\n",
       "      <th>last_item_data</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>time</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>systime</td>\n",
       "      <td>[1686928758076131800, 1686928758076134800, 168...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Raw timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>coordinates</td>\n",
       "      <td>Pad locations in microns</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>ml</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>ap</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>analog</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Analog IO timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Dout3</td>\n",
       "      <td>State change data for one digital channel. Dis...</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>ECU_Dout3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664]</td>\n",
       "      <td>state</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         session_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "2  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "3  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "4  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                           recording metadata_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...         time   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "2  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "3  20230616_111904_standard_comp_to_training_D4_s...       analog   \n",
       "4  20230616_111904_standard_comp_to_training_D4_s...          DIO   \n",
       "\n",
       "   metadata_file                                        description  \\\n",
       "0     timestamps                                         Timestamps   \n",
       "1     timestamps                                     Raw timestamps   \n",
       "2    coordinates                           Pad locations in microns   \n",
       "3     timestamps                               Analog IO timestamps   \n",
       "4  dio_ECU_Dout3  State change data for one digital channel. Dis...   \n",
       "\n",
       "      byte_order                                      original_file clockrate  \\\n",
       "0  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "1  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "2  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "3  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "4  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "\n",
       "  trodes_version compile_date  ...         id display_order clock rate  \\\n",
       "0          2.4.0  May 24 2023  ...        NaN           NaN        NaN   \n",
       "1          2.4.0  May 24 2023  ...        NaN           NaN        NaN   \n",
       "2          2.4.0  May 24 2023  ...        NaN           NaN        NaN   \n",
       "3          2.4.0  May 24 2023  ...        NaN           NaN        NaN   \n",
       "4          2.4.0  May 24 2023  ...  ECU_Dout3             4        NaN   \n",
       "\n",
       "                                        session_path first_dtype_name  \\\n",
       "0  /scratch/back_up/reward_competition_extention/...             time   \n",
       "1  /scratch/back_up/reward_competition_extention/...             time   \n",
       "2  /scratch/back_up/reward_competition_extention/...               ml   \n",
       "3  /scratch/back_up/reward_competition_extention/...             time   \n",
       "4  /scratch/back_up/reward_competition_extention/...             time   \n",
       "\n",
       "                                     first_item_data last_dtype_name  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...         systime   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...              ap   \n",
       "3  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "4                                           [307664]           state   \n",
       "\n",
       "                                      last_item_data all_subjects  \\\n",
       "0  [1686928758076131800, 1686928758076134800, 168...        [1.4]   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        [1.4]   \n",
       "3  [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "4                                                [0]        [1.4]   \n",
       "\n",
       "  current_subject  \n",
       "0             1.4  \n",
       "1             1.4  \n",
       "2             1.4  \n",
       "3             1.4  \n",
       "4             1.4  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF = pd.merge(SPIKEGADGETS_EXTRACTED_DF, CHANNEL_MAPPING_DF, left_on=CURRENT_SUBJECT_COL, right_on=SUBJECT_COL, how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_dir</th>\n",
       "      <th>recording</th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "      <th>description</th>\n",
       "      <th>byte_order</th>\n",
       "      <th>original_file</th>\n",
       "      <th>clockrate</th>\n",
       "      <th>trodes_version</th>\n",
       "      <th>compile_date</th>\n",
       "      <th>...</th>\n",
       "      <th>last_item_data</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>time</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[1686928758076131800, 1686928758076134800, 168...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Raw timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>coordinates</td>\n",
       "      <td>Pad locations in microns</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>analog</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Analog IO timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Dout3</td>\n",
       "      <td>State change data for one digital channel. Dis...</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         session_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "2  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "3  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "4  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                           recording metadata_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...         time   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "2  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "3  20230616_111904_standard_comp_to_training_D4_s...       analog   \n",
       "4  20230616_111904_standard_comp_to_training_D4_s...          DIO   \n",
       "\n",
       "   metadata_file                                        description  \\\n",
       "0     timestamps                                         Timestamps   \n",
       "1     timestamps                                     Raw timestamps   \n",
       "2    coordinates                           Pad locations in microns   \n",
       "3     timestamps                               Analog IO timestamps   \n",
       "4  dio_ECU_Dout3  State change data for one digital channel. Dis...   \n",
       "\n",
       "      byte_order                                      original_file clockrate  \\\n",
       "0  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "1  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "2  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "3  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "4  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "\n",
       "  trodes_version compile_date  ...  \\\n",
       "0          2.4.0  May 24 2023  ...   \n",
       "1          2.4.0  May 24 2023  ...   \n",
       "2          2.4.0  May 24 2023  ...   \n",
       "3          2.4.0  May 24 2023  ...   \n",
       "4          2.4.0  May 24 2023  ...   \n",
       "\n",
       "                                      last_item_data all_subjects  \\\n",
       "0  [1686928758076131800, 1686928758076134800, 168...        [1.4]   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        [1.4]   \n",
       "3  [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "4                                                [0]        [1.4]   \n",
       "\n",
       "  current_subject Cohort Subject spike_interface_mPFC spike_interface_vHPC  \\\n",
       "0             1.4    2.0     1.4                   15                   31   \n",
       "1             1.4    2.0     1.4                   15                   31   \n",
       "2             1.4    2.0     1.4                   15                   31   \n",
       "3             1.4    2.0     1.4                   15                   31   \n",
       "4             1.4    2.0     1.4                   15                   31   \n",
       "\n",
       "  spike_interface_BLA spike_interface_LH spike_interface_MD  \n",
       "0                  30                 29                 28  \n",
       "1                  30                 29                 28  \n",
       "2                  30                 29                 28  \n",
       "3                  30                 29                 28  \n",
       "4                  30                 29                 28  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time</td>\n",
       "      <td>timestamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raw</td>\n",
       "      <td>coordinates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analog</td>\n",
       "      <td>timestamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Dout3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Dout2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Dout4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Dout1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>time</td>\n",
       "      <td>timestamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Dout3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Dout1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Dout4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Dout2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>raw</td>\n",
       "      <td>coordinates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>analog</td>\n",
       "      <td>timestamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>video_timestamps</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        metadata_dir  metadata_file\n",
       "0               time     timestamps\n",
       "1                raw     timestamps\n",
       "2                raw    coordinates\n",
       "3             analog     timestamps\n",
       "4                DIO  dio_ECU_Dout3\n",
       "5                DIO   dio_ECU_Din3\n",
       "6                DIO   dio_ECU_Din2\n",
       "7                DIO   dio_ECU_Din1\n",
       "8                DIO  dio_ECU_Dout2\n",
       "9                DIO  dio_ECU_Dout4\n",
       "10               DIO  dio_ECU_Dout1\n",
       "11               DIO   dio_ECU_Din4\n",
       "12              time     timestamps\n",
       "13               DIO   dio_ECU_Din4\n",
       "14               DIO   dio_ECU_Din3\n",
       "15               DIO  dio_ECU_Dout3\n",
       "16               DIO   dio_ECU_Din1\n",
       "17               DIO  dio_ECU_Dout1\n",
       "18               DIO  dio_ECU_Dout4\n",
       "19               DIO  dio_ECU_Dout2\n",
       "20               DIO   dio_ECU_Din2\n",
       "21               raw    coordinates\n",
       "22               raw     timestamps\n",
       "23            analog     timestamps\n",
       "24  video_timestamps              2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF[[\"metadata_dir\", \"metadata_file\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the channel specific LFP traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linking up all LFP calculations with all the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_dir</th>\n",
       "      <th>recording</th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "      <th>description</th>\n",
       "      <th>byte_order</th>\n",
       "      <th>original_file</th>\n",
       "      <th>clockrate</th>\n",
       "      <th>trodes_version</th>\n",
       "      <th>compile_date</th>\n",
       "      <th>...</th>\n",
       "      <th>last_item_data</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>time</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[1686928758076131800, 1686928758076134800, 168...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Raw timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>analog</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Analog IO timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>time</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[1686928758076131800, 1686928758076134800, 168...</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Raw timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>analog</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Analog IO timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          session_dir  \\\n",
       "0   20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1   20230616_111904_standard_comp_to_training_D4_s...   \n",
       "3   20230616_111904_standard_comp_to_training_D4_s...   \n",
       "12  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "22  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "23  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                            recording metadata_dir  \\\n",
       "0   20230616_111904_standard_comp_to_training_D4_s...         time   \n",
       "1   20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "3   20230616_111904_standard_comp_to_training_D4_s...       analog   \n",
       "12  20230616_111904_standard_comp_to_training_D4_s...         time   \n",
       "22  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "23  20230616_111904_standard_comp_to_training_D4_s...       analog   \n",
       "\n",
       "   metadata_file           description     byte_order  \\\n",
       "0     timestamps            Timestamps  little endian   \n",
       "1     timestamps        Raw timestamps  little endian   \n",
       "3     timestamps  Analog IO timestamps  little endian   \n",
       "12    timestamps            Timestamps  little endian   \n",
       "22    timestamps        Raw timestamps  little endian   \n",
       "23    timestamps  Analog IO timestamps  little endian   \n",
       "\n",
       "                                        original_file clockrate  \\\n",
       "0   20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "1   20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "3   20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "12  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "22  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "23  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "\n",
       "   trodes_version compile_date  ...  \\\n",
       "0           2.4.0  May 24 2023  ...   \n",
       "1           2.4.0  May 24 2023  ...   \n",
       "3           2.4.0  May 24 2023  ...   \n",
       "12          2.4.0  May 24 2023  ...   \n",
       "22          2.4.0  May 24 2023  ...   \n",
       "23          2.4.0  May 24 2023  ...   \n",
       "\n",
       "                                       last_item_data all_subjects  \\\n",
       "0   [1686928758076131800, 1686928758076134800, 168...        [1.4]   \n",
       "1   [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "3   [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "12  [1686928758076131800, 1686928758076134800, 168...        [1.2]   \n",
       "22  [307664, 307665, 307666, 307667, 307668, 30766...        [1.2]   \n",
       "23  [307664, 307665, 307666, 307667, 307668, 30766...        [1.2]   \n",
       "\n",
       "   current_subject Cohort Subject spike_interface_mPFC spike_interface_vHPC  \\\n",
       "0              1.4    2.0     1.4                   15                   31   \n",
       "1              1.4    2.0     1.4                   15                   31   \n",
       "3              1.4    2.0     1.4                   15                   31   \n",
       "12             1.2    2.0     1.2                   10                   31   \n",
       "22             1.2    2.0     1.2                   10                   31   \n",
       "23             1.2    2.0     1.2                   10                   31   \n",
       "\n",
       "   spike_interface_BLA spike_interface_LH spike_interface_MD  \n",
       "0                   30                 29                 28  \n",
       "1                   30                 29                 28  \n",
       "3                   30                 29                 28  \n",
       "12                  30                 29                 28  \n",
       "22                  30                 29                 28  \n",
       "23                  30                 29                 28  \n",
       "\n",
       "[6 rows x 47 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF[SPIKEGADGETS_EXTRACTED_DF[\"metadata_file\"] == \"timestamps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (SPIKEGADGETS_EXTRACTED_DF['metadata_dir'] == 'raw') & (SPIKEGADGETS_EXTRACTED_DF['metadata_file'] == 'timestamps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1      True\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19    False\n",
       "20    False\n",
       "21    False\n",
       "22     True\n",
       "23    False\n",
       "24    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF[ALL_CH_LFP_COL] = SPIKEGADGETS_EXTRACTED_DF[\"recording\"].where(condition).map(recording_name_to_all_ch_lfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   NaN\n",
       "1     ZScoreRecording: 32 channels - 1.0kHz - 1 segm...\n",
       "2                                                   NaN\n",
       "3                                                   NaN\n",
       "4                                                   NaN\n",
       "5                                                   NaN\n",
       "6                                                   NaN\n",
       "7                                                   NaN\n",
       "8                                                   NaN\n",
       "9                                                   NaN\n",
       "10                                                  NaN\n",
       "11                                                  NaN\n",
       "12                                                  NaN\n",
       "13                                                  NaN\n",
       "14                                                  NaN\n",
       "15                                                  NaN\n",
       "16                                                  NaN\n",
       "17                                                  NaN\n",
       "18                                                  NaN\n",
       "19                                                  NaN\n",
       "20                                                  NaN\n",
       "21                                                  NaN\n",
       "22    ZScoreRecording: 32 channels - 1.0kHz - 1 segm...\n",
       "23                                                  NaN\n",
       "24                                                  NaN\n",
       "Name: all_ch_lfp, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF[ALL_CH_LFP_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "stop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/nancy/projects/reward_competition_extention/notebooks/export/01_extract_zscored_lfp.ipynb Cell 51\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/nancy/projects/reward_competition_extention/notebooks/export/01_extract_zscored_lfp.ipynb#Y614sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: stop"
     ]
    }
   ],
   "source": [
    "raise ValueError(\"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF[ALL_CH_LFP_COL] = SPIKEGADGETS_EXTRACTED_DF[RECORDING_FILE_COL].map(recording_name_to_all_ch_lfp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extracting the traces for each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_convert:\n",
    "    print(col)\n",
    "    brain_region = col.strip(SPIKE_INTERFACE_COL).strip(\"_\")\n",
    "    trace_column = \"{}_lfp_trace\".format(brain_region)\n",
    "    SPIKEGADGETS_EXTRACTED_DF[trace_column] = SPIKEGADGETS_EXTRACTED_DF.apply(lambda row: row[ALL_CH_LFP_COL].get_traces(channel_ids=[row[col]]).T[0], axis=1)\n",
    "                                                                                                                                                       \n",
    "                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF = SPIKEGADGETS_EXTRACTED_DF.drop(columns=[ALL_CH_LFP_COL], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF = SPIKEGADGETS_EXTRACTED_DF.drop(columns=[col for col in SPIKEGADGETS_EXTRACTED_DF if SPIKE_INTERFACE_COL in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.to_pickle(os.path.join(OUTPUT_DIR, FULL_LFP_TRACES_PKL))"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "spike_interface_0_99_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
