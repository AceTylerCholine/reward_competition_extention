#!/usr/bin/env python3
"""
"""
import os
import warnings
import re
from collections import defaultdict
import pathlib
import numpy as np

def parse_fields(field_str):
    """Parses field string to np.dtype.

    This function parses a string of fields and returns a np.dtype object
    that can be used to read data from a binary file. The input string is
    expected to be formatted as '<name number*type>' or '<name type>'.

    Args:
        field_str (str): The string specifying the fields.

    Returns:
        dtype: A np.dtype object that describes the structure of the data.

    Raises:
        AttributeError: If the provided field type is not a valid numpy data type.

    """

    # Replace '<', '>', and '><' with spaces, then split on spaces
    field_str = re.sub(r"\>\<|\>|\<", ' ', field_str).strip()
    field_components = field_str.split()

    dtype_spec = []  # List of tuples to specify the np.dtype

    # Iterate over field name and type pairs
    for i in range(0, len(field_components), 2):
        field_name = field_components[i]
        field_type_str = field_components[i+1]

        # Check if the field type string contains a '*', indicating a repeat count
        if '*' in field_type_str:
            # If so, split the string on the '*' and assign the number and type accordingly
            temp_types = field_type_str.split('*')
            field_type = temp_types[0] if temp_types[0].isdigit() else temp_types[1]
            repeat_count = int(temp_types[1] if temp_types[1].isdigit() else temp_types[0])
        else:
            # If not, the field type is the entire string and the repeat count is 1
            field_type = field_type_str
            repeat_count = 1

        # Convert the field type string to an actual np.dtype
        try:
            field_type = getattr(np, field_type)
        except AttributeError:
            print(f"{field_type} is not a valid field type.")
            exit(1)

        # Add the field to the dtype specification
        dtype_spec.append((field_name, field_type, repeat_count))

    # Create and return the np.dtype
    return np.dtype(dtype_spec)

def read_trodes_extracted_data_file(filename):
    """Reads a Trodes .dat file and returns the fields and data.

    This function opens a .dat file, reads the settings block, parses the 
    fields, and then reads the rest of the file using the specified dtype 
    format.

    Args:
        filename (str): The path to the .dat file.

    Returns:
        dict: A dictionary containing the field settings and the data read 
        from the file. The 'data' key in the dictionary maps to a numpy array 
        of the data.

    Raises:
        Exception: If the file does not start with the correct settings block 
        format.

    """
    with open(filename, 'rb') as f:
        # Check if first line is start of settings block
        if f.readline().decode('ascii').strip() != '<Start settings>':
            raise Exception("Settings format not supported")

        fields_text = {}
        fields = True

        # Read through settings block
        for line in f:
            if fields:
                line = line.decode('ascii').strip()
                
                # Continue filling in fields dictionary
                if line != '<End settings>':
                    key, value = line.split(': ')
                    fields_text[key.lower()] = value
                
                # End of settings block, signal end of fields
                else:
                    fields = False
                    dt = parse_fields(fields_text['fields'])
                    break

        # Reads rest of file at once, using dtype format generated by parse_fields
        data = np.fromfile(f, dt)
        fields_text['data'] = data

        return fields_text

##########################
##########################
##########################



def get_key_with_substring(input_dict, substring="", return_first=True):
    """
    Returns keys from a dictionary that contains a specified substring.
    
    Args:
        input_dict (dict): The dictionary to search.
        substring (str, optional): The substring to search for in the keys. Defaults to "".
        return_first (bool, optional): If True, returns the first key that contains the substring.
            If False, returns a list of all keys that contain the substring. Defaults to True.

    Returns:
        str or list: A key or a list of keys from the input dictionary that contains the substring.
            If the substring is an empty string, returns the first key from the dictionary 
            or a list of all keys, depending on the value of 'return_first'. 
            If the substring is itself a key in the dictionary, returns the substring.
            If no keys contain the substring, returns an empty string or list.
    """
    # Find all keys that contain the substring
    keys_with_substring = [key for key in input_dict.keys() if substring in key]

    # If the substring is itself a key in the dictionary, return it
    if substring in keys_with_substring:
        return substring

    # If 'return_first' is True, return the first key that contains the substring
    # If no keys contain the substring, return an empty string
    elif return_first and keys_with_substring:
        return keys_with_substring[0]
    
    # If 'return_first' is False, return a list of all keys that contain the substring
    # If no keys contain the substring, return an empty list
    else:
        return keys_with_substring

def get_all_file_suffixes(file_name):
    """
    Creates a string of the suffixes of a file name that's joined together by ".".
    Suffixes will be all the parts of the file name that follow the first ".".
    Example: If file_name is "file.txt.zip.asc", the output will be "txt.zip.asc".

    Args:
        file_name (str): Name of the file.

    Returns:
        str: A string of all the suffixes joined by ".", or a single "." if no suffixes exist.
    """
    # Extract all the suffixes in the file name using pathlib.Path().suffixes
    # This will return a list of suffixes.
    suffixes = pathlib.Path(file_name).suffixes

    # Strip any periods from the beginning or end of each suffix
    stripped_suffixes = [suffix.strip(".") for suffix in suffixes]
    
    # If there are suffixes, join them together with periods and return the result
    if stripped_suffixes:
        return ".".join(stripped_suffixes)
    
    # If there are no suffixes (i.e., the file name is just "."), return a single period
    else:
        return "."

def update_trodes_file_to_data(file_path, file_to_data=None):
    """
    Extracts the data and metadata from a Trodes recording file and stores it in a dictionary.
    The dictionary keys are file names, and the values are sub-dictionaries of data and metadata points.

    Args:
        file_path (str): Path to the Trodes recording file. The path can be relative or absolute.
        file_to_data (dict, optional): An existing dictionary to which the data will be added. If None, a new dictionary is created. Defaults to None.

    Returns:
        dict: A dictionary where each key is a file name and each value is a sub-dictionary containing data and metadata from the Trodes recording file.

    Raises:
        A warning if the Trodes recording file cannot be processed.
    """
    # Create a new dictionary if none is provided
    if file_to_data is None:
        file_to_data = defaultdict(dict)
    
    # Get just the file name to use as the key
    file_name = os.path.basename(file_path)
    
    # Get the absolute file path as metadata
    absolute_file_path = os.path.abspath(file_path)
    
    try:
        # Read the Trodes recording file data
        trodes_recording = parse_exported_file(absolute_file_path)

        file_prefix = get_all_file_suffixes(file_name)
        print(f"file prefix: {file_prefix}")
        
        # Store the data and metadata in the dictionary
        file_to_data[file_prefix] = trodes_recording
        file_to_data[file_prefix]["absolute_file_path"] = absolute_file_path
        return file_to_data
    except:
        # Issue a warning if the file cannot be processed
        warnings.warn(f"Cannot process {absolute_file_path}")
        return None

def get_all_trodes_data_from_directory(parent_directory_path="."):
    """
    Extracts data and metadata from all Trodes files in a given directory and its subdirectories. 
    The data is organized in a dictionary where the keys are directory names and the values are 
    dictionaries with file names as keys and associated data/metadata as values.

    Args:
        parent_directory_path (str): Path to the parent directory containing the Trodes recording files. 
                                     This can be a relative or absolute path. Defaults to the current directory.

    Returns:
        dict: A dictionary where each key is a directory name and each value is a sub-dictionary containing 
              file names as keys and corresponding data/metadata from Trodes recording files as values.
    """
    directory_to_file_to_data = defaultdict(dict)
    
    # Iterate over all items in the parent directory
    for item in os.listdir(parent_directory_path):
        item_path = os.path.join(parent_directory_path, item)
        
        # If the item is a directory, use its name as a key
        if os.path.isdir(item_path):
            current_directory_name = os.path.basename(item_path)
        # If the item is a file, use the parent directory name as a key
        else:
            current_directory_name = "."
        
        directory_prefix = get_all_file_suffixes(current_directory_name) 
        current_directory_path = os.path.join(parent_directory_path, current_directory_name)
        
        # Iterate over all files in the current directory
        for file_name in os.listdir(current_directory_path):
            file_path = os.path.join(current_directory_path, file_name)
            if os.path.isfile(file_path):
                # Update the dictionary with data/metadata from the current file
                current_directory_to_file_to_data = update_trodes_file_to_data(file_path=file_path, 
                                                                               file_to_data=directory_to_file_to_data[current_directory_name])
                # If the file was processed successfully, update the main dictionary
                if current_directory_to_file_to_data is not None:
                    directory_to_file_to_data[directory_prefix] = current_directory_to_file_to_data
    
    return directory_to_file_to_data

