#!/usr/bin/env python3
"""
"""
import os
import warnings
import re
from collections import defaultdict
import pathlib
import numpy as np

def parse_fields(field_str):
    """Parses field string to np.dtype.

    This function parses a string of fields and returns a np.dtype object
    that can be used to read data from a binary file. The input string is
    expected to be formatted as '<name number*type>' or '<name type>'.

    Args:
        field_str (str): The string specifying the fields.

    Returns:
        dtype: A np.dtype object that describes the structure of the data.

    Raises:
        AttributeError: If the provided field type is not a valid numpy data type.

    """

    # Replace '<', '>', and '><' with spaces, then split on spaces
    field_str = re.sub(r"\>\<|\>|\<", ' ', field_str).strip()
    field_components = field_str.split()

    dtype_spec = []  # List of tuples to specify the np.dtype

    # Iterate over field name and type pairs
    for i in range(0, len(field_components), 2):
        field_name = field_components[i]
        field_type_str = field_components[i+1]

        # Check if the field type string contains a '*', indicating a repeat count
        if '*' in field_type_str:
            # If so, split the string on the '*' and assign the number and type accordingly
            temp_types = field_type_str.split('*')
            field_type = temp_types[0] if temp_types[0].isdigit() else temp_types[1]
            repeat_count = int(temp_types[1] if temp_types[1].isdigit() else temp_types[0])
        else:
            # If not, the field type is the entire string and the repeat count is 1
            field_type = field_type_str
            repeat_count = 1

        # Convert the field type string to an actual np.dtype
        try:
            field_type = getattr(np, field_type)
        except AttributeError:
            print(f"{field_type} is not a valid field type.")
            exit(1)

        # Add the field to the dtype specification
        dtype_spec.append((field_name, field_type, repeat_count))

    # Create and return the np.dtype
    return np.dtype(dtype_spec)

def read_trodes_extracted_data_file(filename):
    """Reads a Trodes .dat file and returns the fields and data.

    This function opens a .dat file, reads the settings block, parses the 
    fields, and then reads the rest of the file using the specified dtype 
    format.

    Args:
        filename (str): The path to the .dat file.

    Returns:
        dict: A dictionary containing the field settings and the data read 
        from the file. The 'data' key in the dictionary maps to a numpy array 
        of the data.

    Raises:
        Exception: If the file does not start with the correct settings block 
        format.

    """
    with open(filename, 'rb') as f:
        # Check if first line is start of settings block
        if f.readline().decode('ascii').strip() != '<Start settings>':
            raise Exception("Settings format not supported")

        fields_text = {}
        fields = True

        # Read through settings block
        for line in f:
            if fields:
                line = line.decode('ascii').strip()
                
                # Continue filling in fields dictionary
                if line != '<End settings>':
                    key, value = line.split(': ')
                    fields_text[key.lower()] = value
                
                # End of settings block, signal end of fields
                else:
                    fields = False
                    dt = parse_fields(fields_text['fields'])
                    break

        # Reads rest of file at once, using dtype format generated by parse_fields
        data = np.fromfile(f, dt)
        fields_text['data'] = data

        return fields_text

def get_key_with_substring(input_dict, substring="", return_first=True):
    """
    """
    keys_with_substring = []
    for key in input_dict.keys():
        if substring in key:
            keys_with_substring.append(key)
    if substring in keys_with_substring:
        return substring
    elif return_first:
        return keys_with_substring[0]
    else:
        return keys_with_substring

def get_all_file_suffixes(file_name):
    """
    Creates a string of the suffixes of a file name that's joined together by "."
    Suffixes will be all the parts of the file name that follows the first "."
    Example: "file.txt.zip.asc" >> "txt.zip.asc"
    
    Args:
        file_name(str): Name of the file

    Returns:
        String of all the suffixes joined by "."
    """
    # Getting all the suffixes in the file name
    # And removing any periods before and after
    stripped_suffixes = [suffix.strip(".") for suffix in pathlib.Path(file_name).suffixes]
    
    if stripped_suffixes:
        return ".".join(stripped_suffixes) 
    # When the file name is just a ".", the stripped suffix is blank
    else:
        return "."

def update_trodes_file_to_data(file_path, file_to_data=None):
    """
    Get the data/metadata froma a Trodes recording file. Save it to a dictionary with the file name as the key. 
    And the name of the data/metadata(sub-key) and the data/metadata point(sub-value) as a subdictionary for the value. 

    Args:
        file_path(str): Path of the Trodes recording file. Can be relative or absolute path.
        file_to_data(dict): Dictionary that had the trodes file name as the key and the 

    Returns:
        Dictionary that has file name keys with a subdictionary of all the different data/metadata from the Trodes recording file.
    """
    # Creating a new dictionary if none is inputted
    if file_to_data is None: 
        file_to_data = defaultdict(dict)
    # Getting just the file name to use as the key
    file_name = os.path.basename(file_path)
    # Getting the absolute file path as metadata
    absolute_file_path = os.path.abspath(file_path)
    try:
        # Reading in the Trodes recording file with the function 
        trodes_recording = parse_exported_file(absolute_file_path)

        file_prefix = get_all_file_suffixes(file_name) 
        print("file prefix: {}".format(file_prefix))
        file_to_data[file_prefix] = trodes_recording
        file_to_data[file_prefix]["absolute_file_path"] = absolute_file_path
        return file_to_data
    except:
        # TODO: Fix format so that file path is included in warning
        warnings.warn("Can not process {}".format(absolute_file_path))
        return None

def get_all_trodes_data_from_directory(parent_directory_path="."):
    """
    Goes through all the files in a directory created by Trodes. 
    Each file is organized into a dictionary that is directory name to the file name to associated data/metadata of the file.
    The structure would look something like: result[current_directory_name][file_name][data_type]

    Args:
        parent_directory_path(str): Path of the directory that contains the Trodes recording files. Can be relative or absolute path.

    Returns:
        Dictionary that has the Trodes directory name as the key and a subdictionary as the values. 
        This subdictionary has all the files as keys with the corresponding data/metadata from the Trodes recording file as values.
    """
    directory_to_file_to_data = defaultdict(dict)
    # Going through each directory
    for item in os.listdir(parent_directory_path):
        item_path = os.path.join(parent_directory_path, item)
        # Getting the directory name to save as the key
        if os.path.isdir(item_path):
            current_directory_name = os.path.basename(item_path)
        # If the item is a file instead of a directory
        else:
            current_directory_name = "."
        directory_prefix = get_all_file_suffixes(current_directory_name) 

        current_directory_path = os.path.join(parent_directory_path, current_directory_name)
        # Going through each file in the directory
        for file_name in os.listdir(current_directory_path):
            file_path = os.path.join(current_directory_path, file_name)
            if os.path.isfile(file_path):
                # Creating a sub dictionary that has file keys and a sub-sub dictionary of data type to data value 
                current_directory_to_file_to_data = update_trodes_file_to_data(file_path=file_path, file_to_data=directory_to_file_to_data[current_directory_name])
                # None will be returned if the file can not be processed
                if current_directory_to_file_to_data is not None:
                    directory_to_file_to_data[directory_prefix] = current_directory_to_file_to_data
    return directory_to_file_to_data

